{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trail_9_resnet18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eHnoL6b4P2uw",
        "ywFnbu3eP5nW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Haq2PI9sBZ4",
        "colab_type": "text"
      },
      "source": [
        "implementation:\n",
        "\n",
        "*   https://www.kaggle.com/daisukelab/cnn-2d-basic-solution-powered-by-fast-ai\n",
        "*   https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHnoL6b4P2uw",
        "colab_type": "text"
      },
      "source": [
        "### Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4fj8QJuPXUJ",
        "colab_type": "code",
        "outputId": "c48c01f0-f075-4053-caca-5080b23e3e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838167&Signature=MIzEcS1L3DIuogUv42vVpG8nkgbUAKG%2F0JjhqwoGd%2B6%2FgM1xqKYdcwu%2Bxcs39PNnbSAj5QNu5NHD5uwCqkaH5yM30eGVIoC0uXybB5p4IqpAhrnOWN33sJ8QATG8SYFGe73B%2Bv%2Bseow2TmJ7OWp9EBX%2BwYW3vQHVXZkaeMoo7epIldBSoBr%2FdG%2FwHdSsyy%2FeXm8LU7BOEq6A1jBCdtejriZdioSYsPVUn1W9jwjgrYQo4KykapKtrYwG4ztysgB9GrqPpv0RIi%2FHSXypZo%2FqUeknTUyy2CdZsmmfb3TjRFuAiDNfX5kzuhcsqwpbHieVdjnW%2Fwu%2BnUdFCp6m6YWlPA%3D%3D\" -O \"sample_submission.csv\" -c"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:30:46--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838167&Signature=MIzEcS1L3DIuogUv42vVpG8nkgbUAKG%2F0JjhqwoGd%2B6%2FgM1xqKYdcwu%2Bxcs39PNnbSAj5QNu5NHD5uwCqkaH5yM30eGVIoC0uXybB5p4IqpAhrnOWN33sJ8QATG8SYFGe73B%2Bv%2Bseow2TmJ7OWp9EBX%2BwYW3vQHVXZkaeMoo7epIldBSoBr%2FdG%2FwHdSsyy%2FeXm8LU7BOEq6A1jBCdtejriZdioSYsPVUn1W9jwjgrYQo4KykapKtrYwG4ztysgB9GrqPpv0RIi%2FHSXypZo%2FqUeknTUyy2CdZsmmfb3TjRFuAiDNfX5kzuhcsqwpbHieVdjnW%2Fwu%2BnUdFCp6m6YWlPA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 194835 (190K) [text/csv]\n",
            "Saving to: ‘sample_submission.csv’\n",
            "\n",
            "\rsample_submission.c   0%[                    ]       0  --.-KB/s               \rsample_submission.c 100%[===================>] 190.27K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2019-05-12 11:30:46 (89.8 MB/s) - ‘sample_submission.csv’ saved [194835/194835]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0mlUkNgPm3a",
        "colab_type": "code",
        "outputId": "b7abcb87-f0d2-4bac-df1f-e46f7b30e356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838179&Signature=NTKEVQouLiWV9DqV1TRCfqzo4Llvj18R7R0epMmR2n%2F18ghJrfBOOBxE%2FyeIcWlD21sSgNI1FZ%2F4Chh3xdQYhunL8XqAJdKYke50w9PiV4GxeJjSppJyqrzOAXUkjMcHp5GrJG5I%2FQT6e%2FRjC4WgQ5Q3F73XhxpfF7kgy%2B%2FH5epJuia1mzjfqutt8TeXHWtxfJrW%2FGrBQsMrd%2Ba%2FMbcgn9f8B4RkBvUtmQ%2B7wuoqD25F68UBe2%2Br6yz%2B12KPT1zHdY%2FwaUoL7IF5Je5rEbmeKyPWMOi32P4S1F82zIi8Lp%2Bwyqp1CVQqiXCCahYkHxfgnMVHJZmOloLmsgg397Bm%2FA%3D%3D\" -O \"train_curated.csv\" -c"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:30:50--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838179&Signature=NTKEVQouLiWV9DqV1TRCfqzo4Llvj18R7R0epMmR2n%2F18ghJrfBOOBxE%2FyeIcWlD21sSgNI1FZ%2F4Chh3xdQYhunL8XqAJdKYke50w9PiV4GxeJjSppJyqrzOAXUkjMcHp5GrJG5I%2FQT6e%2FRjC4WgQ5Q3F73XhxpfF7kgy%2B%2FH5epJuia1mzjfqutt8TeXHWtxfJrW%2FGrBQsMrd%2Ba%2FMbcgn9f8B4RkBvUtmQ%2B7wuoqD25F68UBe2%2Br6yz%2B12KPT1zHdY%2FwaUoL7IF5Je5rEbmeKyPWMOi32P4S1F82zIi8Lp%2Bwyqp1CVQqiXCCahYkHxfgnMVHJZmOloLmsgg397Bm%2FA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143137 (140K) [text/csv]\n",
            "Saving to: ‘train_curated.csv’\n",
            "\n",
            "\rtrain_curated.csv     0%[                    ]       0  --.-KB/s               \rtrain_curated.csv   100%[===================>] 139.78K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-05-12 11:30:51 (91.9 MB/s) - ‘train_curated.csv’ saved [143137/143137]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTXMdoKhPqb9",
        "colab_type": "code",
        "outputId": "a2cf1b5a-6fae-4932-87ff-3d9c2e87a463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838190&Signature=KvC%2FRXp2k6LrlPOcVtvyFDyOYMV2jJN7cLP35sjEdBHzgSZ4GAoZn3m1Oj%2BamVpz39bA%2FeKrvfkEBCoSy%2Bt2o2kJEitQ5mLeJwi7bwiN3y0mwycFWO6rDoW7SpvoHe%2F1%2BPcpAA31vfd0Itc3H1Tgh7zdt7MU6HwtA0oqZO0a7AZMTP64qmHGKDyStPPR6uI9XsPPgLIT5GsA3%2FMDa%2FQpXVe25i7jHmocmYkvXKt5TeovWLiifnHZMFolCNap0DTSq0bceGLaEZ%2BDPGbPRKLAGtc4dTXhwkomD3J79k3lz1%2BKSa13pJ5aLJSi5uIiPUGMkQSPoRweQB7RvJO3vDGcBw%3D%3D\" -O \"train_noisy.csv\" -c"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:30:54--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838190&Signature=KvC%2FRXp2k6LrlPOcVtvyFDyOYMV2jJN7cLP35sjEdBHzgSZ4GAoZn3m1Oj%2BamVpz39bA%2FeKrvfkEBCoSy%2Bt2o2kJEitQ5mLeJwi7bwiN3y0mwycFWO6rDoW7SpvoHe%2F1%2BPcpAA31vfd0Itc3H1Tgh7zdt7MU6HwtA0oqZO0a7AZMTP64qmHGKDyStPPR6uI9XsPPgLIT5GsA3%2FMDa%2FQpXVe25i7jHmocmYkvXKt5TeovWLiifnHZMFolCNap0DTSq0bceGLaEZ%2BDPGbPRKLAGtc4dTXhwkomD3J79k3lz1%2BKSa13pJ5aLJSi5uIiPUGMkQSPoRweQB7RvJO3vDGcBw%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.199.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.199.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 584806 (571K) [text/csv]\n",
            "Saving to: ‘train_noisy.csv’\n",
            "\n",
            "\rtrain_noisy.csv       0%[                    ]       0  --.-KB/s               \rtrain_noisy.csv     100%[===================>] 571.10K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2019-05-12 11:30:54 (110 MB/s) - ‘train_noisy.csv’ saved [584806/584806]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75LDMVcPs52",
        "colab_type": "code",
        "outputId": "d4daf836-cb63-41d3-9ce2-f578968b1f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838202&Signature=LrJ5DBITMPNEATLqU%2Fsmo0%2BxQUa%2FcNDuix8iYhHKb8QpAIdBm1xyc4btf2SRlOrU1DdI9bFuZodE59A1EYhu4EtNY2a61MiKjvsQEJwnMnDwChlIVSMPVkvnNnRgJOsyOFxXYnsFtLtfSrMvmlUdOaoy9S1IAXlUOVIvL2tSuBPXy1%2B9LtfyKAj1SCpRF3zOUG54Ku0JeeendbCPDTJn2pcS2Ff%2Fgpk%2BulxQDItQHe782njoohESv3x1FmwYi8oxe2P%2F9SZg1LBh5YHa2rTlSFm9m5CrqA5Qs7vDT%2BnxTuKHo2MvYfFSBrTnVRKzdu1TIyyc%2BjUhum4OxSnWVlTisg%3D%3D\" -O \"test.zip\" -c"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:30:56--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838202&Signature=LrJ5DBITMPNEATLqU%2Fsmo0%2BxQUa%2FcNDuix8iYhHKb8QpAIdBm1xyc4btf2SRlOrU1DdI9bFuZodE59A1EYhu4EtNY2a61MiKjvsQEJwnMnDwChlIVSMPVkvnNnRgJOsyOFxXYnsFtLtfSrMvmlUdOaoy9S1IAXlUOVIvL2tSuBPXy1%2B9LtfyKAj1SCpRF3zOUG54Ku0JeeendbCPDTJn2pcS2Ff%2Fgpk%2BulxQDItQHe782njoohESv3x1FmwYi8oxe2P%2F9SZg1LBh5YHa2rTlSFm9m5CrqA5Qs7vDT%2BnxTuKHo2MvYfFSBrTnVRKzdu1TIyyc%2BjUhum4OxSnWVlTisg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 698756070 (666M) [application/zip]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>] 666.38M  76.0MB/s    in 9.1s    \n",
            "\n",
            "2019-05-12 11:31:06 (73.0 MB/s) - ‘test.zip’ saved [698756070/698756070]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doLUxbxlPyes",
        "colab_type": "code",
        "outputId": "10cf175d-64da-48fc-cc43-b3f48c11dfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838236&Signature=WFaCAuPlSqPhLfYykFnGOS4Ok92xbcHQmYdO9%2Bsv4WRMzcbnWXIR6p6i8Ow%2BX6t%2FSRWsACKVLIAtXqEjS7f13Iy3sWaw5g38aAWFxjndPl0tP35KQ69OppbNcXbtW49VmyCDNunPUfN48EuULZKg1aaB2SPTTLLKpnLJcBfCUUckd21PcczhgFq11RRDNlqBOSFWv1OrPk2Wz%2BisgOOyGzq3vj6fqBE6ZFVwMovY3gyjq7jzqIzSgcBdhMFlAPDYBCPWfqriB%2BjNF8GSBij1I9w3%2BrvkSHJoKKMKNiGp9HQIxJBzWXt3qUIboqhoGQKv%2FQaIJLhOjYTIf2xrYQ3maA%3D%3D\" -O \"train_curated.zip\" -c"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:31:08--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838236&Signature=WFaCAuPlSqPhLfYykFnGOS4Ok92xbcHQmYdO9%2Bsv4WRMzcbnWXIR6p6i8Ow%2BX6t%2FSRWsACKVLIAtXqEjS7f13Iy3sWaw5g38aAWFxjndPl0tP35KQ69OppbNcXbtW49VmyCDNunPUfN48EuULZKg1aaB2SPTTLLKpnLJcBfCUUckd21PcczhgFq11RRDNlqBOSFWv1OrPk2Wz%2BisgOOyGzq3vj6fqBE6ZFVwMovY3gyjq7jzqIzSgcBdhMFlAPDYBCPWfqriB%2BjNF8GSBij1I9w3%2BrvkSHJoKKMKNiGp9HQIxJBzWXt3qUIboqhoGQKv%2FQaIJLhOjYTIf2xrYQ3maA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2406491583 (2.2G) [application/zip]\n",
            "Saving to: ‘train_curated.zip’\n",
            "\n",
            "train_curated.zip   100%[===================>]   2.24G  80.4MB/s    in 28s     \n",
            "\n",
            "2019-05-12 11:31:37 (81.0 MB/s) - ‘train_curated.zip’ saved [2406491583/2406491583]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNnA16iPy_T",
        "colab_type": "code",
        "outputId": "1ca016f4-d6c7-429b-9fa2-4aa7b52e2d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838250&Signature=YEEpWjFrGSJ8gvjok6TRz0%2FVHRME2o30YX1vb%2Bsor2w2a5qUlZr%2FVnU7A4T3wicTwZrJwWPbPtjh4XTQ3qjIyakKaI0d19HtNr9BXNNkvXROmbw16lNqWTRfO01%2BOhc%2FSpdp6rc6NTEhcSDh5QABAA33fys9nwg2aDdv%2BNLcnmrhgScpbXLdIZhhmOa2Nws9p25YMhVLWsHLta0VGgzqLmjGSMnCxgjDmGzq2dXEX84sCAa0yHHq5gM13GYzMd44Xd2f7PmOQKnIjCAgt8fdtQSIMFkFgWUxiMBy66zP0tqd0w7LMn6u2Dtbdh7qr7R2a2liqkvGiogQDD09LgOZ8A%3D%3D\" -O \"train_noisy.zip\" -c"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:31:40--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838250&Signature=YEEpWjFrGSJ8gvjok6TRz0%2FVHRME2o30YX1vb%2Bsor2w2a5qUlZr%2FVnU7A4T3wicTwZrJwWPbPtjh4XTQ3qjIyakKaI0d19HtNr9BXNNkvXROmbw16lNqWTRfO01%2BOhc%2FSpdp6rc6NTEhcSDh5QABAA33fys9nwg2aDdv%2BNLcnmrhgScpbXLdIZhhmOa2Nws9p25YMhVLWsHLta0VGgzqLmjGSMnCxgjDmGzq2dXEX84sCAa0yHHq5gM13GYzMd44Xd2f7PmOQKnIjCAgt8fdtQSIMFkFgWUxiMBy66zP0tqd0w7LMn6u2Dtbdh7qr7R2a2liqkvGiogQDD09LgOZ8A%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21504922116 (20G) [application/zip]\n",
            "Saving to: ‘train_noisy.zip’\n",
            "\n",
            "train_noisy.zip     100%[===================>]  20.03G  76.4MB/s    in 3m 57s  \n",
            "\n",
            "2019-05-12 11:35:38 (86.6 MB/s) - ‘train_noisy.zip’ saved [21504922116/21504922116]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fJaLfzGynqy",
        "colab_type": "text"
      },
      "source": [
        "***Preprocessed data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bZWNGSWypWV",
        "colab_type": "code",
        "outputId": "ba24cbad-0539-476a-a50a-b7c95e6cd6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838149&Signature=DvpGKn5On8bg%2BdsrHS3YF0es3qVaXzA8BkLhpi1xAiYoJzJZ7oF6qvVn%2BEGt1NS%2BvP0vn%2FJt35sxl6AyxxkJT0Jpuea2oEyaACL8%2BC1dBMEarSg%2FLp7hA%2FhZvAx4If7%2FYa69118IIh%2B89xsHeDB9xh2Zfear38udfqJTXtuK7vrvm6dXGlhXfd0SUAOkjNt7OmNzOT7NX1brN9U832LvMjSksKDXjC%2BLvct712HBgOY7JIHeyu7uWJMHLk4avq8tKe33d%2BrO5Jsla%2FLRa6LVyKj4BnTP65h9dzLGcyqhIwGabKjBiEDnSd7go3jaaxVc8iXUr0OyjatiJ8q7%2Bat9jA%3D%3D\" -O \"fat2019_prep_mels1.zip\" -c"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-12 11:35:40--  https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838149&Signature=DvpGKn5On8bg%2BdsrHS3YF0es3qVaXzA8BkLhpi1xAiYoJzJZ7oF6qvVn%2BEGt1NS%2BvP0vn%2FJt35sxl6AyxxkJT0Jpuea2oEyaACL8%2BC1dBMEarSg%2FLp7hA%2FhZvAx4If7%2FYa69118IIh%2B89xsHeDB9xh2Zfear38udfqJTXtuK7vrvm6dXGlhXfd0SUAOkjNt7OmNzOT7NX1brN9U832LvMjSksKDXjC%2BLvct712HBgOY7JIHeyu7uWJMHLk4avq8tKe33d%2BrO5Jsla%2FLRa6LVyKj4BnTP65h9dzLGcyqhIwGabKjBiEDnSd7go3jaaxVc8iXUr0OyjatiJ8q7%2Bat9jA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2865032102 (2.7G) [application/zip]\n",
            "Saving to: ‘fat2019_prep_mels1.zip’\n",
            "\n",
            "fat2019_prep_mels1. 100%[===================>]   2.67G  84.8MB/s    in 34s     \n",
            "\n",
            "2019-05-12 11:36:15 (79.7 MB/s) - ‘fat2019_prep_mels1.zip’ saved [2865032102/2865032102]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywFnbu3eP5nW",
        "colab_type": "text"
      },
      "source": [
        "### Exploring dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0tOhnVcACC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test\n",
        "!mkdir train_curated\n",
        "!mkdir train_noisy\n",
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pokwjdG2zCjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq fat2019_prep_mels1.zip -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1Wq71PP43o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLZZ6nuWQMqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_curated.zip -d train_curated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpYGeV7mQMkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_noisy.zip -d train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK-JmCd_QMWx",
        "colab_type": "text"
      },
      "source": [
        "To apply deep learning technique, we first have to come up with a way to provide effective converse from audio data to any other form which will make it effective for deep learning technique for multilabeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l5HQ4X5SmxC",
        "colab_type": "text"
      },
      "source": [
        "Audio conversion to 2D\n",
        "Almost copyed from my repository: https://github.com/daisukelab/ml-sound-classifier\n",
        "\n",
        "Handle sampling rate 44.1kHz as is, no information loss.\n",
        "Size of each file will be 128 x L, L is audio seconds x 128; [128, 256] if sound is 2s long.\n",
        "Convert to Mel-spectrogram, not MFCC. We are handling general sound rather than human voice. https://en.wikipedia.org/wiki/Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PZG8p-dchS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv -t data test train_curated train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPW_sIidU0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_submission.csv train_curated.csv train_noisy.csv data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFndQ6_MhLb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "21859aa5-9d88-4994-c718-b77b512b8fbd"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mels_test.pkl\t\t    sample_submission.csv  train_noisy\n",
            "mels_train_curated.pkl\t    test\t\t   train_noisy.csv\n",
            "mels_train_noisy.pkl\t    train_curated\t   trn_noisy_best50s.csv\n",
            "mels_trn_noisy_best50s.pkl  train_curated.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTCWqn31MKk",
        "colab_type": "text"
      },
      "source": [
        "## Testing different dL techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti-PQPO2uNQC",
        "colab_type": "text"
      },
      "source": [
        "### 2. Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODeTKQbJwFuJ",
        "colab_type": "text"
      },
      "source": [
        "***Simple changes, significant improvement in lb***\n",
        "\n",
        "Now with different convolution architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcCNIj42060g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from psutil import cpu_count\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3lWLSN7xAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 520\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_bwTu3xCHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_JOBS = cpu_count()\n",
        "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
        "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
        "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jhnnjifxCD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UthfHLBOxCA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gdnVV-xB-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK4Xhj0IxB7S",
        "colab_type": "code",
        "outputId": "ff982100-b6c1-4bf0-b038-20b00ea8bf68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>labels</th>\n",
              "      <th>singled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0006ae4e.wav</td>\n",
              "      <td>Bark</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0019ef41.wav</td>\n",
              "      <td>Raindrop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ec0ad.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0026c7cb.wav</td>\n",
              "      <td>Run</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0026f116.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname           labels singled\n",
              "0  0006ae4e.wav             Bark     NaN\n",
              "1  0019ef41.wav         Raindrop     NaN\n",
              "2  001ec0ad.wav  Finger_snapping     NaN\n",
              "3  0026c7cb.wav              Run     NaN\n",
              "4  0026f116.wav  Finger_snapping     NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySDLo2fTxB4x",
        "colab_type": "code",
        "outputId": "5fa09426-0fc0-4024-a2c3-a29a5e2ce809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>...</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
              "0  000ccb97.wav                                   0          0   \n",
              "1  0012633b.wav                                   0          0   \n",
              "2  001ed5f1.wav                                   0          0   \n",
              "3  00294be0.wav                                   0          0   \n",
              "4  003fde7a.wav                                   0          0   \n",
              "\n",
              "   Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
              "0                0         0     0          0            0   \n",
              "1                0         0     0          0            0   \n",
              "2                0         0     0          0            0   \n",
              "3                0         0     0          0            0   \n",
              "4                0         0     0          0            0   \n",
              "\n",
              "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
              "0                             0             0  ...             0   \n",
              "1                             0             0  ...             0   \n",
              "2                             0             0  ...             0   \n",
              "3                             0             0  ...             0   \n",
              "4                             0             0  ...             0   \n",
              "\n",
              "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
              "0                                0                    0                   0   \n",
              "1                                0                    0                   0   \n",
              "2                                0                    0                   0   \n",
              "3                                0                    0                   0   \n",
              "4                                0                    0                   0   \n",
              "\n",
              "   Water_tap_and_faucet  Waves_and_surf  Whispering  Writing  Yell  \\\n",
              "0                     0               0           0        0     0   \n",
              "1                     0               0           0        0     0   \n",
              "2                     0               0           0        0     0   \n",
              "3                     0               0           0        0     0   \n",
              "4                     0               0           0        0     0   \n",
              "\n",
              "   Zipper_(clothing)  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  0  \n",
              "4                  0  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK8cx8TbxTKI",
        "colab_type": "code",
        "outputId": "e2a09c24-4e21-46f5-dec1-3e53b29d1bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accelerating_and_revving_and_vroom',\n",
              " 'Accordion',\n",
              " 'Acoustic_guitar',\n",
              " 'Applause',\n",
              " 'Bark',\n",
              " 'Bass_drum',\n",
              " 'Bass_guitar',\n",
              " 'Bathtub_(filling_or_washing)',\n",
              " 'Bicycle_bell',\n",
              " 'Burping_and_eructation',\n",
              " 'Bus',\n",
              " 'Buzz',\n",
              " 'Car_passing_by',\n",
              " 'Cheering',\n",
              " 'Chewing_and_mastication',\n",
              " 'Child_speech_and_kid_speaking',\n",
              " 'Chink_and_clink',\n",
              " 'Chirp_and_tweet',\n",
              " 'Church_bell',\n",
              " 'Clapping',\n",
              " 'Computer_keyboard',\n",
              " 'Crackle',\n",
              " 'Cricket',\n",
              " 'Crowd',\n",
              " 'Cupboard_open_or_close',\n",
              " 'Cutlery_and_silverware',\n",
              " 'Dishes_and_pots_and_pans',\n",
              " 'Drawer_open_or_close',\n",
              " 'Drip',\n",
              " 'Electric_guitar',\n",
              " 'Fart',\n",
              " 'Female_singing',\n",
              " 'Female_speech_and_woman_speaking',\n",
              " 'Fill_(with_liquid)',\n",
              " 'Finger_snapping',\n",
              " 'Frying_(food)',\n",
              " 'Gasp',\n",
              " 'Glockenspiel',\n",
              " 'Gong',\n",
              " 'Gurgling',\n",
              " 'Harmonica',\n",
              " 'Hi-hat',\n",
              " 'Hiss',\n",
              " 'Keys_jangling',\n",
              " 'Knock',\n",
              " 'Male_singing',\n",
              " 'Male_speech_and_man_speaking',\n",
              " 'Marimba_and_xylophone',\n",
              " 'Mechanical_fan',\n",
              " 'Meow',\n",
              " 'Microwave_oven',\n",
              " 'Motorcycle',\n",
              " 'Printer',\n",
              " 'Purr',\n",
              " 'Race_car_and_auto_racing',\n",
              " 'Raindrop',\n",
              " 'Run',\n",
              " 'Scissors',\n",
              " 'Screaming',\n",
              " 'Shatter',\n",
              " 'Sigh',\n",
              " 'Sink_(filling_or_washing)',\n",
              " 'Skateboard',\n",
              " 'Slam',\n",
              " 'Sneeze',\n",
              " 'Squeak',\n",
              " 'Stream',\n",
              " 'Strum',\n",
              " 'Tap',\n",
              " 'Tick-tock',\n",
              " 'Toilet_flush',\n",
              " 'Traffic_noise_and_roadway_noise',\n",
              " 'Trickle_and_dribble',\n",
              " 'Walk_and_footsteps',\n",
              " 'Water_tap_and_faucet',\n",
              " 'Waves_and_surf',\n",
              " 'Whispering',\n",
              " 'Writing',\n",
              " 'Yell',\n",
              " 'Zipper_(clothing)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4t9AiIxTG-",
        "colab_type": "code",
        "outputId": "cdcaf5e9-b59a-48f6-e0e7-f6cab106e43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9s5PMk_xTEM",
        "colab_type": "code",
        "outputId": "11c53d42-6eee-4a44-b218-881cc2849dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dc941ZJxS_4",
        "colab_type": "code",
        "outputId": "77a56912-151e-4f54-b7a8-cea49894804f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 1120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDgnY7xmxbAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUzFIqazxa3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlYwSC7oxaw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9lQ9pXH1h5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "29971e88-5075-4cc6-f69d-9b53ac352830"
      },
      "source": [
        "#pretrained models:\n",
        "!pip install pretrainedmodels"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.1.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (2.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.2.2.post3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.16.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->pretrainedmodels) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wygwRmh61nwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "848258b1-69d6-4f2e-b35b-5cee503ef499"
      },
      "source": [
        "import pretrainedmodels\n",
        "print(pretrainedmodels.model_names)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-umZzHM1qkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to load a pretrained models\n",
        "model_name = 'resnet18' # could be fbresnet152 or inceptionresnetv2\n",
        "model_ft = pretrainedmodels.__dict__[model_name](num_classes=1000)\n",
        "#model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXnKbF-J-fPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1482
        },
        "outputId": "7556f249-e070-42b0-cb19-e583eb3eb88b"
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): None\n",
              "  (last_linear): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpA9R-jA-wM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "model_ft.last_linear = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7oC-SOdEqLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "\n",
        "model_ft.last_linear = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=num_ftrs, out_features=1024, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=512, out_features=80, bias=True)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiI2wZ3SGBJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgPz2pJyAKxp",
        "colab_type": "code",
        "outputId": "c3fb47f8-b599-41be-c895-e3d9bc1fdaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncriterion = nn.CrossEntropyLoss()\\n\\n# Observe that all parameters are being optimized\\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\\n\\n# Decay LR by a factor of 0.1 every 7 epochs\\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzlvwtgK7Oy",
        "colab_type": "code",
        "outputId": "3e25a959-49a9-45bd-b9ca-3425cc20cb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ft.classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.5)\n",
              "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (2): ReLU(inplace)\n",
              "  (3): Dropout(p=0.5)\n",
              "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (5): ReLU(inplace)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy1pGvd8MbSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as defined in the link:\n",
        "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OtydueIxiiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUSz8mScyVsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(511, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(127, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nVtMd4xidL",
        "colab_type": "code",
        "outputId": "66d2f716-c45c-4b94-bf6c-b3057883adad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.2)\n",
              "    (1): Linear(in_features=511, out_features=128, bias=True)\n",
              "    (2): PReLU(num_parameters=1)\n",
              "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Dropout(p=0.1)\n",
              "    (5): Linear(in_features=127, out_features=80, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeyzYJM7xk9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 128\n",
        "    test_batch_size = 256\n",
        "    lr = 1e-3\n",
        "    eta_min = 1e-5\n",
        "    t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    #model = Classifier(num_classes=num_classes).cuda()\n",
        "    model = model_ft\n",
        "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmVih93Dxk5x",
        "colab_type": "code",
        "outputId": "10659efe-b01d-454b-abae-9b24ac33f9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2731
        }
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Epoch 1 - avg_train_loss: 0.1036  avg_val_loss: 0.0746  val_lwlrap: 0.076185  time: 12s<p>Epoch 2 - avg_train_loss: 0.0574  avg_val_loss: 0.0598  val_lwlrap: 0.277426  time: 12s<p>Epoch 3 - avg_train_loss: 0.0492  avg_val_loss: 0.0494  val_lwlrap: 0.415907  time: 12s<p>Epoch 4 - avg_train_loss: 0.0427  avg_val_loss: 0.0474  val_lwlrap: 0.418458  time: 12s<p>Epoch 5 - avg_train_loss: 0.0381  avg_val_loss: 0.0393  val_lwlrap: 0.573864  time: 12s<p>Epoch 6 - avg_train_loss: 0.0356  avg_val_loss: 0.0376  val_lwlrap: 0.586423  time: 12s<p>Epoch 7 - avg_train_loss: 0.0358  avg_val_loss: 0.0371  val_lwlrap: 0.588970  time: 13s<p>Epoch 8 - avg_train_loss: 0.0365  avg_val_loss: 0.0408  val_lwlrap: 0.555424  time: 13s<p>Epoch 9 - avg_train_loss: 0.0391  avg_val_loss: 0.0544  val_lwlrap: 0.371138  time: 13s<p>Epoch 10 - avg_train_loss: 0.0381  avg_val_loss: 0.0599  val_lwlrap: 0.362761  time: 13s<p>Epoch 11 - avg_train_loss: 0.0365  avg_val_loss: 0.0491  val_lwlrap: 0.462083  time: 13s<p>Epoch 12 - avg_train_loss: 0.0330  avg_val_loss: 0.0523  val_lwlrap: 0.460844  time: 13s<p>Epoch 13 - avg_train_loss: 0.0287  avg_val_loss: 0.0386  val_lwlrap: 0.571228  time: 13s<p>Epoch 14 - avg_train_loss: 0.0243  avg_val_loss: 0.0376  val_lwlrap: 0.590298  time: 13s<p>Epoch 15 - avg_train_loss: 0.0210  avg_val_loss: 0.0324  val_lwlrap: 0.656260  time: 13s<p>Epoch 16 - avg_train_loss: 0.0196  avg_val_loss: 0.0350  val_lwlrap: 0.660816  time: 13s<p>Epoch 17 - avg_train_loss: 0.0195  avg_val_loss: 0.0321  val_lwlrap: 0.663512  time: 13s<p>Epoch 18 - avg_train_loss: 0.0202  avg_val_loss: 0.0347  val_lwlrap: 0.640159  time: 13s<p>Epoch 19 - avg_train_loss: 0.0226  avg_val_loss: 0.0516  val_lwlrap: 0.469080  time: 13s<p>Epoch 20 - avg_train_loss: 0.0258  avg_val_loss: 0.0543  val_lwlrap: 0.459024  time: 13s<p>Epoch 21 - avg_train_loss: 0.0265  avg_val_loss: 0.0437  val_lwlrap: 0.554705  time: 13s<p>Epoch 22 - avg_train_loss: 0.0228  avg_val_loss: 0.0551  val_lwlrap: 0.430489  time: 13s<p>Epoch 23 - avg_train_loss: 0.0190  avg_val_loss: 0.0403  val_lwlrap: 0.608123  time: 13s<p>Epoch 24 - avg_train_loss: 0.0147  avg_val_loss: 0.0376  val_lwlrap: 0.656711  time: 13s<p>Epoch 25 - avg_train_loss: 0.0118  avg_val_loss: 0.0327  val_lwlrap: 0.672536  time: 13s<p>Epoch 26 - avg_train_loss: 0.0107  avg_val_loss: 0.0376  val_lwlrap: 0.671113  time: 13s<p>Epoch 27 - avg_train_loss: 0.0109  avg_val_loss: 0.0344  val_lwlrap: 0.664991  time: 13s<p>Epoch 28 - avg_train_loss: 0.0114  avg_val_loss: 0.0383  val_lwlrap: 0.643220  time: 13s<p>Epoch 29 - avg_train_loss: 0.0129  avg_val_loss: 0.0442  val_lwlrap: 0.629488  time: 13s<p>Epoch 30 - avg_train_loss: 0.0155  avg_val_loss: 0.0424  val_lwlrap: 0.561003  time: 13s<p>Epoch 31 - avg_train_loss: 0.0184  avg_val_loss: 0.0553  val_lwlrap: 0.536198  time: 13s<p>Epoch 32 - avg_train_loss: 0.0166  avg_val_loss: 0.0489  val_lwlrap: 0.569010  time: 13s<p>Epoch 33 - avg_train_loss: 0.0132  avg_val_loss: 0.0380  val_lwlrap: 0.661687  time: 13s<p>Epoch 34 - avg_train_loss: 0.0092  avg_val_loss: 0.0393  val_lwlrap: 0.654586  time: 13s<p>Epoch 35 - avg_train_loss: 0.0076  avg_val_loss: 0.0375  val_lwlrap: 0.669048  time: 13s<p>Epoch 36 - avg_train_loss: 0.0063  avg_val_loss: 0.0383  val_lwlrap: 0.671102  time: 13s<p>Epoch 37 - avg_train_loss: 0.0065  avg_val_loss: 0.0372  val_lwlrap: 0.668351  time: 13s<p>Epoch 38 - avg_train_loss: 0.0074  avg_val_loss: 0.0399  val_lwlrap: 0.649998  time: 13s<p>Epoch 39 - avg_train_loss: 0.0099  avg_val_loss: 0.0426  val_lwlrap: 0.643651  time: 13s<p>Epoch 40 - avg_train_loss: 0.0122  avg_val_loss: 0.0551  val_lwlrap: 0.566517  time: 13s<p>Epoch 41 - avg_train_loss: 0.0149  avg_val_loss: 0.0474  val_lwlrap: 0.565653  time: 13s<p>Epoch 42 - avg_train_loss: 0.0129  avg_val_loss: 0.0502  val_lwlrap: 0.582666  time: 13s<p>Epoch 43 - avg_train_loss: 0.0099  avg_val_loss: 0.0436  val_lwlrap: 0.611363  time: 13s<p>Epoch 44 - avg_train_loss: 0.0066  avg_val_loss: 0.0428  val_lwlrap: 0.660244  time: 13s<p>Epoch 45 - avg_train_loss: 0.0051  avg_val_loss: 0.0438  val_lwlrap: 0.655156  time: 13s<p>Epoch 46 - avg_train_loss: 0.0046  avg_val_loss: 0.0398  val_lwlrap: 0.659330  time: 13s<p>Epoch 47 - avg_train_loss: 0.0046  avg_val_loss: 0.0421  val_lwlrap: 0.659120  time: 13s<p>Epoch 48 - avg_train_loss: 0.0048  avg_val_loss: 0.0467  val_lwlrap: 0.648804  time: 13s<p>Epoch 49 - avg_train_loss: 0.0064  avg_val_loss: 0.0462  val_lwlrap: 0.631529  time: 13s<p>Epoch 50 - avg_train_loss: 0.0082  avg_val_loss: 0.0655  val_lwlrap: 0.508183  time: 13s<p>Epoch 51 - avg_train_loss: 0.0095  avg_val_loss: 0.0573  val_lwlrap: 0.570587  time: 13s<p>Epoch 52 - avg_train_loss: 0.0104  avg_val_loss: 0.0507  val_lwlrap: 0.610018  time: 13s<p>Epoch 53 - avg_train_loss: 0.0076  avg_val_loss: 0.0471  val_lwlrap: 0.611425  time: 13s<p>Epoch 54 - avg_train_loss: 0.0050  avg_val_loss: 0.0470  val_lwlrap: 0.652445  time: 13s<p>Epoch 55 - avg_train_loss: 0.0039  avg_val_loss: 0.0403  val_lwlrap: 0.654845  time: 13s<p>Epoch 56 - avg_train_loss: 0.0033  avg_val_loss: 0.0391  val_lwlrap: 0.654047  time: 13s<p>Epoch 57 - avg_train_loss: 0.0032  avg_val_loss: 0.0424  val_lwlrap: 0.660959  time: 13s<p>Epoch 58 - avg_train_loss: 0.0032  avg_val_loss: 0.0452  val_lwlrap: 0.645624  time: 13s<p>Epoch 59 - avg_train_loss: 0.0037  avg_val_loss: 0.0491  val_lwlrap: 0.635445  time: 13s<p>Epoch 60 - avg_train_loss: 0.0057  avg_val_loss: 0.0475  val_lwlrap: 0.630644  time: 13s<p>Epoch 61 - avg_train_loss: 0.0099  avg_val_loss: 0.0662  val_lwlrap: 0.465217  time: 13s<p>Epoch 62 - avg_train_loss: 0.0106  avg_val_loss: 0.0596  val_lwlrap: 0.587657  time: 13s<p>Epoch 63 - avg_train_loss: 0.0070  avg_val_loss: 0.0533  val_lwlrap: 0.617459  time: 13s<p>Epoch 64 - avg_train_loss: 0.0047  avg_val_loss: 0.0504  val_lwlrap: 0.643747  time: 13s<p>Epoch 65 - avg_train_loss: 0.0032  avg_val_loss: 0.0398  val_lwlrap: 0.655576  time: 13s<p>Epoch 66 - avg_train_loss: 0.0029  avg_val_loss: 0.0435  val_lwlrap: 0.646153  time: 13s<p>Epoch 67 - avg_train_loss: 0.0032  avg_val_loss: 0.0439  val_lwlrap: 0.647033  time: 13s<p>Epoch 68 - avg_train_loss: 0.0034  avg_val_loss: 0.0442  val_lwlrap: 0.645510  time: 13s<p>Epoch 69 - avg_train_loss: 0.0041  avg_val_loss: 0.0526  val_lwlrap: 0.611892  time: 13s<p>Epoch 70 - avg_train_loss: 0.0045  avg_val_loss: 0.0522  val_lwlrap: 0.609057  time: 13s<p>Epoch 71 - avg_train_loss: 0.0080  avg_val_loss: 0.0538  val_lwlrap: 0.561155  time: 13s<p>Epoch 72 - avg_train_loss: 0.0080  avg_val_loss: 0.0589  val_lwlrap: 0.585603  time: 13s<p>Epoch 73 - avg_train_loss: 0.0067  avg_val_loss: 0.0512  val_lwlrap: 0.621744  time: 13s<p>Epoch 74 - avg_train_loss: 0.0038  avg_val_loss: 0.0511  val_lwlrap: 0.646166  time: 13s<p>Epoch 75 - avg_train_loss: 0.0028  avg_val_loss: 0.0513  val_lwlrap: 0.648386  time: 13s<p>Epoch 76 - avg_train_loss: 0.0025  avg_val_loss: 0.0518  val_lwlrap: 0.639329  time: 13s<p>Epoch 77 - avg_train_loss: 0.0026  avg_val_loss: 0.0541  val_lwlrap: 0.653429  time: 13s<p>Epoch 78 - avg_train_loss: 0.0027  avg_val_loss: 0.0528  val_lwlrap: 0.639406  time: 13s<p>Epoch 79 - avg_train_loss: 0.0035  avg_val_loss: 0.0517  val_lwlrap: 0.645396  time: 13s<p>Epoch 80 - avg_train_loss: 0.0039  avg_val_loss: 0.0600  val_lwlrap: 0.569823  time: 13s<p>Epoch 81 - avg_train_loss: 0.0061  avg_val_loss: 0.0658  val_lwlrap: 0.554841  time: 13s<p>Epoch 82 - avg_train_loss: 0.0064  avg_val_loss: 0.0565  val_lwlrap: 0.611911  time: 13s<p>Epoch 83 - avg_train_loss: 0.0049  avg_val_loss: 0.0491  val_lwlrap: 0.631993  time: 13s<p>Epoch 84 - avg_train_loss: 0.0034  avg_val_loss: 0.0526  val_lwlrap: 0.632664  time: 13s<p>Epoch 85 - avg_train_loss: 0.0021  avg_val_loss: 0.0436  val_lwlrap: 0.650326  time: 13s<p>Epoch 86 - avg_train_loss: 0.0020  avg_val_loss: 0.0453  val_lwlrap: 0.648354  time: 13s<p>Epoch 87 - avg_train_loss: 0.0019  avg_val_loss: 0.0526  val_lwlrap: 0.647560  time: 13s<p>Epoch 88 - avg_train_loss: 0.0020  avg_val_loss: 0.0475  val_lwlrap: 0.652323  time: 13s<p>Epoch 89 - avg_train_loss: 0.0033  avg_val_loss: 0.0529  val_lwlrap: 0.642974  time: 13s<p>Epoch 90 - avg_train_loss: 0.0049  avg_val_loss: 0.0568  val_lwlrap: 0.615012  time: 13s<p>Epoch 91 - avg_train_loss: 0.0048  avg_val_loss: 0.0550  val_lwlrap: 0.602224  time: 13s<p>Epoch 92 - avg_train_loss: 0.0049  avg_val_loss: 0.0511  val_lwlrap: 0.622352  time: 13s<p>Epoch 93 - avg_train_loss: 0.0042  avg_val_loss: 0.0540  val_lwlrap: 0.622646  time: 13s<p>Epoch 94 - avg_train_loss: 0.0024  avg_val_loss: 0.0478  val_lwlrap: 0.640329  time: 13s<p>Epoch 95 - avg_train_loss: 0.0018  avg_val_loss: 0.0495  val_lwlrap: 0.640128  time: 13s<p>Epoch 96 - avg_train_loss: 0.0016  avg_val_loss: 0.0515  val_lwlrap: 0.646396  time: 13s<p>Epoch 97 - avg_train_loss: 0.0014  avg_val_loss: 0.0534  val_lwlrap: 0.642730  time: 13s<p>Epoch 98 - avg_train_loss: 0.0016  avg_val_loss: 0.0552  val_lwlrap: 0.642417  time: 13s<p>Epoch 99 - avg_train_loss: 0.0019  avg_val_loss: 0.0551  val_lwlrap: 0.618885  time: 13s<p>Epoch 100 - avg_train_loss: 0.0039  avg_val_loss: 0.0528  val_lwlrap: 0.633381  time: 13s<p>Epoch 101 - avg_train_loss: 0.0062  avg_val_loss: 0.0581  val_lwlrap: 0.581640  time: 13s<p>Epoch 102 - avg_train_loss: 0.0048  avg_val_loss: 0.0515  val_lwlrap: 0.608397  time: 13s<p>Epoch 103 - avg_train_loss: 0.0034  avg_val_loss: 0.0489  val_lwlrap: 0.640967  time: 13s<p>Epoch 104 - avg_train_loss: 0.0025  avg_val_loss: 0.0485  val_lwlrap: 0.641825  time: 13s<p>Epoch 105 - avg_train_loss: 0.0016  avg_val_loss: 0.0481  val_lwlrap: 0.637959  time: 13s<p>Epoch 106 - avg_train_loss: 0.0014  avg_val_loss: 0.0513  val_lwlrap: 0.647551  time: 13s<p>Epoch 107 - avg_train_loss: 0.0017  avg_val_loss: 0.0473  val_lwlrap: 0.646519  time: 13s<p>Epoch 108 - avg_train_loss: 0.0017  avg_val_loss: 0.0509  val_lwlrap: 0.640427  time: 13s<p>Epoch 109 - avg_train_loss: 0.0020  avg_val_loss: 0.0629  val_lwlrap: 0.600415  time: 13s<p>Epoch 110 - avg_train_loss: 0.0030  avg_val_loss: 0.0583  val_lwlrap: 0.609933  time: 13s<p>Epoch 111 - avg_train_loss: 0.0041  avg_val_loss: 0.0539  val_lwlrap: 0.611268  time: 13s<p>Epoch 112 - avg_train_loss: 0.0040  avg_val_loss: 0.0723  val_lwlrap: 0.581824  time: 13s<p>Epoch 113 - avg_train_loss: 0.0038  avg_val_loss: 0.0575  val_lwlrap: 0.602739  time: 13s<p>Epoch 114 - avg_train_loss: 0.0025  avg_val_loss: 0.0622  val_lwlrap: 0.629263  time: 13s<p>Epoch 115 - avg_train_loss: 0.0022  avg_val_loss: 0.0560  val_lwlrap: 0.630917  time: 13s<p>Epoch 116 - avg_train_loss: 0.0015  avg_val_loss: 0.0546  val_lwlrap: 0.643381  time: 13s<p>Epoch 117 - avg_train_loss: 0.0013  avg_val_loss: 0.0525  val_lwlrap: 0.634093  time: 13s<p>Epoch 118 - avg_train_loss: 0.0016  avg_val_loss: 0.0552  val_lwlrap: 0.634405  time: 13s"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yVDzyb-xk1m",
        "colab_type": "code",
        "outputId": "93f08c84-6a4f-4f69-95e7-2741200f1a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 25, 'best_lwlrap': 0.6725361465385692}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g215CpOVytIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
        "    batch_size = 256\n",
        "\n",
        "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_ft\n",
        "    model.load_state_dict(torch.load('weight_best.pt'))\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs, all_fnames = [], []\n",
        "\n",
        "    pb = progress_bar(test_loader)\n",
        "    for images, fnames in pb:\n",
        "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
        "        all_outputs.append(preds.cpu().numpy())\n",
        "        all_fnames.extend(fnames)\n",
        "\n",
        "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
        "                              index=all_fnames,\n",
        "                              columns=map(str, range(num_classes)))\n",
        "    test_preds = test_preds.groupby(level=0).mean()\n",
        "\n",
        "    return test_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwIX8CeyyBY",
        "colab_type": "code",
        "outputId": "d221ef82-228d-4701-9a7e-c7b455613ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=35)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='154' class='' max='154', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [154/154 00:22<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK7pYQk_yt3r",
        "colab_type": "code",
        "outputId": "276a403d-6baf-480e-db63-e45bff1890d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>...</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>1.430308e-04</td>\n",
              "      <td>2.706857e-04</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.001022</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.008839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000420</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.002138</td>\n",
              "      <td>0.001782</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>0.000339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0.070699</td>\n",
              "      <td>4.755019e-04</td>\n",
              "      <td>4.782900e-04</td>\n",
              "      <td>0.005118</td>\n",
              "      <td>0.007681</td>\n",
              "      <td>0.014335</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.002934</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003076</td>\n",
              "      <td>0.044882</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.020746</td>\n",
              "      <td>0.001630</td>\n",
              "      <td>0.003247</td>\n",
              "      <td>0.006137</td>\n",
              "      <td>0.002955</td>\n",
              "      <td>0.010037</td>\n",
              "      <td>0.104788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0.001043</td>\n",
              "      <td>9.696604e-04</td>\n",
              "      <td>4.355594e-04</td>\n",
              "      <td>0.002295</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.019617</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.002048</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.001763</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.024719</td>\n",
              "      <td>0.000451</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.001754</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.003748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>1.270120e-07</td>\n",
              "      <td>6.599020e-07</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.001230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>4.389402e-04</td>\n",
              "      <td>1.663254e-04</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.000675</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.711358</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.001825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom     Accordion  \\\n",
              "0  000ccb97.wav                            0.001116  1.430308e-04   \n",
              "1  0012633b.wav                            0.070699  4.755019e-04   \n",
              "2  001ed5f1.wav                            0.001043  9.696604e-04   \n",
              "3  00294be0.wav                            0.000021  1.270120e-07   \n",
              "4  003fde7a.wav                            0.000092  4.389402e-04   \n",
              "\n",
              "   Acoustic_guitar  Applause      Bark  Bass_drum  Bass_guitar  \\\n",
              "0     2.706857e-04  0.000392  0.001022   0.000811     0.000198   \n",
              "1     4.782900e-04  0.005118  0.007681   0.014335     0.001944   \n",
              "2     4.355594e-04  0.002295  0.001402   0.019617     0.000844   \n",
              "3     6.599020e-07  0.000032  0.000277   0.000003     0.000010   \n",
              "4     1.663254e-04  0.000846  0.000675   0.000204     0.000149   \n",
              "\n",
              "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
              "0                      0.000528      0.008839  ...      0.001400   \n",
              "1                      0.002934      0.002725  ...      0.003076   \n",
              "2                      0.002048      0.001816  ...      0.000349   \n",
              "3                      0.000064      0.000006  ...      0.000002   \n",
              "4                      0.000074      0.711358  ...      0.000216   \n",
              "\n",
              "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
              "0                         0.000488             0.000048            0.000420   \n",
              "1                         0.044882             0.000690            0.020746   \n",
              "2                         0.001763             0.000070            0.024719   \n",
              "3                         0.000013             0.000009            0.000027   \n",
              "4                         0.000095             0.000106            0.000282   \n",
              "\n",
              "   Water_tap_and_faucet  Waves_and_surf  Whispering   Writing      Yell  \\\n",
              "0              0.000072        0.000164    0.002138  0.001782  0.000207   \n",
              "1              0.001630        0.003247    0.006137  0.002955  0.010037   \n",
              "2              0.000451        0.000753    0.000268  0.001754  0.000213   \n",
              "3              0.000013        0.000032    0.000172  0.000023  0.000007   \n",
              "4              0.000063        0.000098    0.000192  0.000831  0.000101   \n",
              "\n",
              "   Zipper_(clothing)  \n",
              "0           0.000339  \n",
              "1           0.104788  \n",
              "2           0.003748  \n",
              "3           0.001230  \n",
              "4           0.001825  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkZp04mwNia9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}