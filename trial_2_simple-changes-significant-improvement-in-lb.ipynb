{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel was forked from [https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch](http://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch) simple changes in it significantly improved LB score to 0.630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from psutil import cpu_count\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 520\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = cpu_count()\n",
    "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
    "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
    "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dataset_dir = Path('../input/freesound-audio-tagging-2019')\n",
    "preprocessed_dir = Path('../input/fat2019_prep_mels1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / 'train_curated.csv',\n",
    "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
    "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
    "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    'train_curated': dataset_dir / 'train_curated',\n",
    "    'train_noisy': dataset_dir / 'train_noisy',\n",
    "    'test': dataset_dir / 'test',\n",
    "}\n",
    "\n",
    "mels = {\n",
    "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
    "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
    "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>singled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname           labels singled\n",
       "0  0006ae4e.wav             Bark     NaN\n",
       "1  0019ef41.wav         Raindrop     NaN\n",
       "2  001ec0ad.wav  Finger_snapping     NaN\n",
       "3  0026c7cb.wav              Run     NaN\n",
       "4  0026f116.wav  Finger_snapping     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_curated = pd.read_csv(csvs['train_curated'])\n",
    "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
    "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...                          0\n",
       "1  0012633b.wav        ...                          0\n",
       "2  001ed5f1.wav        ...                          0\n",
       "3  00294be0.wav        ...                          0\n",
       "4  003fde7a.wav        ...                          0\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(csvs['sample_submission'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accelerating_and_revving_and_vroom',\n",
       " 'Accordion',\n",
       " 'Acoustic_guitar',\n",
       " 'Applause',\n",
       " 'Bark',\n",
       " 'Bass_drum',\n",
       " 'Bass_guitar',\n",
       " 'Bathtub_(filling_or_washing)',\n",
       " 'Bicycle_bell',\n",
       " 'Burping_and_eructation',\n",
       " 'Bus',\n",
       " 'Buzz',\n",
       " 'Car_passing_by',\n",
       " 'Cheering',\n",
       " 'Chewing_and_mastication',\n",
       " 'Child_speech_and_kid_speaking',\n",
       " 'Chink_and_clink',\n",
       " 'Chirp_and_tweet',\n",
       " 'Church_bell',\n",
       " 'Clapping',\n",
       " 'Computer_keyboard',\n",
       " 'Crackle',\n",
       " 'Cricket',\n",
       " 'Crowd',\n",
       " 'Cupboard_open_or_close',\n",
       " 'Cutlery_and_silverware',\n",
       " 'Dishes_and_pots_and_pans',\n",
       " 'Drawer_open_or_close',\n",
       " 'Drip',\n",
       " 'Electric_guitar',\n",
       " 'Fart',\n",
       " 'Female_singing',\n",
       " 'Female_speech_and_woman_speaking',\n",
       " 'Fill_(with_liquid)',\n",
       " 'Finger_snapping',\n",
       " 'Frying_(food)',\n",
       " 'Gasp',\n",
       " 'Glockenspiel',\n",
       " 'Gong',\n",
       " 'Gurgling',\n",
       " 'Harmonica',\n",
       " 'Hi-hat',\n",
       " 'Hiss',\n",
       " 'Keys_jangling',\n",
       " 'Knock',\n",
       " 'Male_singing',\n",
       " 'Male_speech_and_man_speaking',\n",
       " 'Marimba_and_xylophone',\n",
       " 'Mechanical_fan',\n",
       " 'Meow',\n",
       " 'Microwave_oven',\n",
       " 'Motorcycle',\n",
       " 'Printer',\n",
       " 'Purr',\n",
       " 'Race_car_and_auto_racing',\n",
       " 'Raindrop',\n",
       " 'Run',\n",
       " 'Scissors',\n",
       " 'Screaming',\n",
       " 'Shatter',\n",
       " 'Sigh',\n",
       " 'Sink_(filling_or_washing)',\n",
       " 'Skateboard',\n",
       " 'Slam',\n",
       " 'Sneeze',\n",
       " 'Squeak',\n",
       " 'Stream',\n",
       " 'Strum',\n",
       " 'Tap',\n",
       " 'Tick-tock',\n",
       " 'Toilet_flush',\n",
       " 'Traffic_noise_and_roadway_noise',\n",
       " 'Trickle_and_dribble',\n",
       " 'Walk_and_footsteps',\n",
       " 'Water_tap_and_faucet',\n",
       " 'Waves_and_surf',\n",
       " 'Whispering',\n",
       " 'Writing',\n",
       " 'Yell',\n",
       " 'Zipper_(clothing)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = test_df.columns[1:].tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(labels)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
    "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
    "    for label in row:\n",
    "        idx = labels.index(label)\n",
    "        y_train[i, idx] = 1\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, 1120)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
    "    x_train = pickle.load(curated)\n",
    "    x_train.extend(pickle.load(noisy))\n",
    "\n",
    "with open(mels['test'], 'rb') as test:\n",
    "    x_test = pickle.load(test)\n",
    "    \n",
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FATTrainDataset(Dataset):\n",
    "    def __init__(self, mels, labels, transforms):\n",
    "        super().__init__()\n",
    "        self.mels = mels\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # crop 1sec\n",
    "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = self.transforms(image).div_(255)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        label = torch.from_numpy(label).float()\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FATTestDataset(Dataset):\n",
    "    def __init__(self, fnames, mels, transforms, tta=5):\n",
    "        super().__init__()\n",
    "        self.fnames = fnames\n",
    "        self.mels = mels\n",
    "        self.transforms = transforms\n",
    "        self.tta = tta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames) * self.tta\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        new_idx = idx % len(self.fnames)\n",
    "        \n",
    "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = self.transforms(image).div_(255)\n",
    "\n",
    "        fname = self.fnames[new_idx]\n",
    "        \n",
    "        return image, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=3, out_channels=64),\n",
    "            ConvBlock(in_channels=64, out_channels=128),\n",
    "            ConvBlock(in_channels=128, out_channels=256),\n",
    "            ConvBlock(in_channels=256, out_channels=512),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.2)\n",
       "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout(p=0.1)\n",
       "    (5): Linear(in_features=128, out_features=80, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, train_transforms):\n",
    "    num_epochs = 118\n",
    "    batch_size = 128\n",
    "    test_batch_size = 256\n",
    "    lr = 1e-3\n",
    "    eta_min = 1e-5\n",
    "    t_max = 5\n",
    "    \n",
    "    num_classes = y_train.shape[1]\n",
    "\n",
    "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
    "    \n",
    "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
    "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(num_classes=num_classes).cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "\n",
    "    best_epoch = -1\n",
    "    best_lwlrap = 0.\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    for epoch in mb:\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            preds = model(x_batch.cuda())\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        valid_preds = np.zeros((len(x_val), num_classes))\n",
    "        avg_val_loss = 0.\n",
    "\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            preds = model(x_batch.cuda()).detach()\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            preds = torch.sigmoid(preds)\n",
    "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
    "\n",
    "            avg_val_loss += loss.item() / len(valid_loader)\n",
    "            \n",
    "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
    "        lwlrap = (score * weight).sum()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
    "    \n",
    "        if lwlrap > best_lwlrap:\n",
    "            best_epoch = epoch + 1\n",
    "            best_lwlrap = lwlrap\n",
    "            torch.save(model.state_dict(), 'weight_best.pt')\n",
    "            \n",
    "    return {\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_lwlrap': best_lwlrap,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1 - avg_train_loss: 0.6403  avg_val_loss: 0.5197  val_lwlrap: 0.066899  time: 29s<p>Epoch 2 - avg_train_loss: 0.3149  avg_val_loss: 0.1505  val_lwlrap: 0.068460  time: 29s<p>Epoch 3 - avg_train_loss: 0.1133  avg_val_loss: 0.0908  val_lwlrap: 0.084628  time: 29s<p>Epoch 4 - avg_train_loss: 0.0818  avg_val_loss: 0.0754  val_lwlrap: 0.104461  time: 29s<p>Epoch 5 - avg_train_loss: 0.0760  avg_val_loss: 0.0724  val_lwlrap: 0.120252  time: 29s<p>Epoch 6 - avg_train_loss: 0.0744  avg_val_loss: 0.0719  val_lwlrap: 0.134617  time: 29s<p>Epoch 7 - avg_train_loss: 0.0737  avg_val_loss: 0.0721  val_lwlrap: 0.128639  time: 29s<p>Epoch 8 - avg_train_loss: 0.0734  avg_val_loss: 0.0713  val_lwlrap: 0.124508  time: 29s<p>Epoch 9 - avg_train_loss: 0.0721  avg_val_loss: 0.0720  val_lwlrap: 0.082326  time: 29s<p>Epoch 10 - avg_train_loss: 0.0702  avg_val_loss: 0.1097  val_lwlrap: 0.068173  time: 29s<p>Epoch 11 - avg_train_loss: 0.0678  avg_val_loss: 0.0796  val_lwlrap: 0.068559  time: 29s<p>Epoch 12 - avg_train_loss: 0.0660  avg_val_loss: 0.0736  val_lwlrap: 0.086521  time: 29s<p>Epoch 13 - avg_train_loss: 0.0644  avg_val_loss: 0.0953  val_lwlrap: 0.069359  time: 29s<p>Epoch 14 - avg_train_loss: 0.0629  avg_val_loss: 0.0897  val_lwlrap: 0.081290  time: 29s<p>Epoch 15 - avg_train_loss: 0.0618  avg_val_loss: 0.0876  val_lwlrap: 0.077618  time: 29s<p>Epoch 16 - avg_train_loss: 0.0608  avg_val_loss: 0.0641  val_lwlrap: 0.212175  time: 29s<p>Epoch 17 - avg_train_loss: 0.0606  avg_val_loss: 0.0592  val_lwlrap: 0.298778  time: 29s<p>Epoch 18 - avg_train_loss: 0.0605  avg_val_loss: 0.0617  val_lwlrap: 0.240188  time: 29s<p>Epoch 19 - avg_train_loss: 0.0605  avg_val_loss: 0.0714  val_lwlrap: 0.109029  time: 29s<p>Epoch 20 - avg_train_loss: 0.0604  avg_val_loss: 0.0917  val_lwlrap: 0.076874  time: 29s<p>Epoch 21 - avg_train_loss: 0.0601  avg_val_loss: 0.1032  val_lwlrap: 0.072024  time: 29s<p>Epoch 22 - avg_train_loss: 0.0588  avg_val_loss: 0.0782  val_lwlrap: 0.096072  time: 29s<p>Epoch 23 - avg_train_loss: 0.0572  avg_val_loss: 0.4014  val_lwlrap: 0.068609  time: 29s<p>Epoch 24 - avg_train_loss: 0.0561  avg_val_loss: 0.1182  val_lwlrap: 0.069868  time: 29s<p>Epoch 25 - avg_train_loss: 0.0549  avg_val_loss: 0.0961  val_lwlrap: 0.106761  time: 29s<p>Epoch 26 - avg_train_loss: 0.0537  avg_val_loss: 0.0572  val_lwlrap: 0.329492  time: 29s<p>Epoch 27 - avg_train_loss: 0.0533  avg_val_loss: 0.0520  val_lwlrap: 0.411931  time: 29s<p>Epoch 28 - avg_train_loss: 0.0535  avg_val_loss: 0.0831  val_lwlrap: 0.115486  time: 29s<p>Epoch 29 - avg_train_loss: 0.0537  avg_val_loss: 0.1544  val_lwlrap: 0.090290  time: 29s<p>Epoch 30 - avg_train_loss: 0.0537  avg_val_loss: 0.0934  val_lwlrap: 0.113236  time: 29s<p>Epoch 31 - avg_train_loss: 0.0536  avg_val_loss: 0.1391  val_lwlrap: 0.070839  time: 29s<p>Epoch 32 - avg_train_loss: 0.0530  avg_val_loss: 0.1231  val_lwlrap: 0.081184  time: 29s<p>Epoch 33 - avg_train_loss: 0.0527  avg_val_loss: 0.1164  val_lwlrap: 0.089350  time: 29s<p>Epoch 34 - avg_train_loss: 0.0512  avg_val_loss: 0.1015  val_lwlrap: 0.079567  time: 29s<p>Epoch 35 - avg_train_loss: 0.0494  avg_val_loss: 0.0673  val_lwlrap: 0.196885  time: 29s<p>Epoch 36 - avg_train_loss: 0.0482  avg_val_loss: 0.0491  val_lwlrap: 0.450457  time: 29s<p>Epoch 37 - avg_train_loss: 0.0479  avg_val_loss: 0.0468  val_lwlrap: 0.483748  time: 29s<p>Epoch 38 - avg_train_loss: 0.0478  avg_val_loss: 0.0531  val_lwlrap: 0.356149  time: 29s<p>Epoch 39 - avg_train_loss: 0.0482  avg_val_loss: 0.1075  val_lwlrap: 0.093170  time: 29s<p>Epoch 40 - avg_train_loss: 0.0486  avg_val_loss: 0.3054  val_lwlrap: 0.072893  time: 29s<p>Epoch 41 - avg_train_loss: 0.0489  avg_val_loss: 0.1798  val_lwlrap: 0.078755  time: 29s<p>Epoch 42 - avg_train_loss: 0.0489  avg_val_loss: 0.0836  val_lwlrap: 0.097078  time: 29s<p>Epoch 43 - avg_train_loss: 0.0488  avg_val_loss: 0.1602  val_lwlrap: 0.075844  time: 29s<p>Epoch 44 - avg_train_loss: 0.0469  avg_val_loss: 0.1109  val_lwlrap: 0.088811  time: 29s<p>Epoch 45 - avg_train_loss: 0.0449  avg_val_loss: 0.0917  val_lwlrap: 0.084760  time: 29s<p>Epoch 46 - avg_train_loss: 0.0438  avg_val_loss: 0.0575  val_lwlrap: 0.326488  time: 29s<p>Epoch 47 - avg_train_loss: 0.0437  avg_val_loss: 0.0433  val_lwlrap: 0.530165  time: 29s<p>Epoch 48 - avg_train_loss: 0.0436  avg_val_loss: 0.0602  val_lwlrap: 0.301685  time: 29s<p>Epoch 49 - avg_train_loss: 0.0436  avg_val_loss: 0.1043  val_lwlrap: 0.103552  time: 29s<p>Epoch 50 - avg_train_loss: 0.0449  avg_val_loss: 0.0932  val_lwlrap: 0.112456  time: 29s<p>Epoch 51 - avg_train_loss: 0.0452  avg_val_loss: 0.1383  val_lwlrap: 0.081633  time: 29s<p>Epoch 52 - avg_train_loss: 0.0453  avg_val_loss: 0.1762  val_lwlrap: 0.075946  time: 29s<p>Epoch 53 - avg_train_loss: 0.0440  avg_val_loss: 0.0880  val_lwlrap: 0.076263  time: 29s<p>Epoch 54 - avg_train_loss: 0.0427  avg_val_loss: 0.0896  val_lwlrap: 0.088090  time: 29s<p>Epoch 55 - avg_train_loss: 0.0413  avg_val_loss: 0.0799  val_lwlrap: 0.187141  time: 29s<p>Epoch 56 - avg_train_loss: 0.0397  avg_val_loss: 0.0556  val_lwlrap: 0.339404  time: 29s<p>Epoch 57 - avg_train_loss: 0.0395  avg_val_loss: 0.0396  val_lwlrap: 0.564209  time: 29s<p>Epoch 58 - avg_train_loss: 0.0396  avg_val_loss: 0.0583  val_lwlrap: 0.364164  time: 29s<p>Epoch 59 - avg_train_loss: 0.0400  avg_val_loss: 0.1411  val_lwlrap: 0.098535  time: 29s<p>Epoch 60 - avg_train_loss: 0.0411  avg_val_loss: 0.0892  val_lwlrap: 0.110332  time: 29s<p>Epoch 61 - avg_train_loss: 0.0416  avg_val_loss: 0.1299  val_lwlrap: 0.092064  time: 29s<p>Epoch 62 - avg_train_loss: 0.0417  avg_val_loss: 0.1067  val_lwlrap: 0.080287  time: 29s<p>Epoch 63 - avg_train_loss: 0.0405  avg_val_loss: 0.2459  val_lwlrap: 0.090142  time: 29s<p>Epoch 64 - avg_train_loss: 0.0404  avg_val_loss: 0.1309  val_lwlrap: 0.078475  time: 29s<p>Epoch 65 - avg_train_loss: 0.0384  avg_val_loss: 0.0876  val_lwlrap: 0.192604  time: 29s<p>Epoch 66 - avg_train_loss: 0.0370  avg_val_loss: 0.0821  val_lwlrap: 0.219831  time: 29s<p>Epoch 67 - avg_train_loss: 0.0364  avg_val_loss: 0.0380  val_lwlrap: 0.588530  time: 29s<p>Epoch 68 - avg_train_loss: 0.0364  avg_val_loss: 0.0553  val_lwlrap: 0.350653  time: 29s<p>Epoch 69 - avg_train_loss: 0.0367  avg_val_loss: 0.1012  val_lwlrap: 0.103611  time: 29s<p>Epoch 70 - avg_train_loss: 0.0377  avg_val_loss: 0.1151  val_lwlrap: 0.129492  time: 29s<p>Epoch 71 - avg_train_loss: 0.0383  avg_val_loss: 0.1650  val_lwlrap: 0.064836  time: 29s<p>Epoch 72 - avg_train_loss: 0.0380  avg_val_loss: 0.1199  val_lwlrap: 0.069419  time: 29s<p>Epoch 73 - avg_train_loss: 0.0378  avg_val_loss: 0.1449  val_lwlrap: 0.085477  time: 29s<p>Epoch 74 - avg_train_loss: 0.0365  avg_val_loss: 0.1052  val_lwlrap: 0.119102  time: 29s<p>Epoch 75 - avg_train_loss: 0.0350  avg_val_loss: 0.0855  val_lwlrap: 0.124555  time: 29s<p>Epoch 76 - avg_train_loss: 0.0334  avg_val_loss: 0.0413  val_lwlrap: 0.557671  time: 29s<p>Epoch 77 - avg_train_loss: 0.0330  avg_val_loss: 0.0372  val_lwlrap: 0.598532  time: 29s<p>Epoch 78 - avg_train_loss: 0.0331  avg_val_loss: 0.0816  val_lwlrap: 0.246452  time: 29s<p>Epoch 79 - avg_train_loss: 0.0336  avg_val_loss: 0.1245  val_lwlrap: 0.094964  time: 29s<p>Epoch 80 - avg_train_loss: 0.0344  avg_val_loss: 0.5558  val_lwlrap: 0.068723  time: 29s<p>Epoch 81 - avg_train_loss: 0.0352  avg_val_loss: 0.4462  val_lwlrap: 0.061855  time: 29s<p>Epoch 82 - avg_train_loss: 0.0353  avg_val_loss: 0.1191  val_lwlrap: 0.123287  time: 29s<p>Epoch 83 - avg_train_loss: 0.0345  avg_val_loss: 0.1230  val_lwlrap: 0.078109  time: 29s<p>Epoch 84 - avg_train_loss: 0.0334  avg_val_loss: 0.1310  val_lwlrap: 0.083885  time: 29s<p>Epoch 85 - avg_train_loss: 0.0317  avg_val_loss: 0.1248  val_lwlrap: 0.114683  time: 29s<p>Epoch 86 - avg_train_loss: 0.0305  avg_val_loss: 0.0884  val_lwlrap: 0.264472  time: 29s<p>Epoch 87 - avg_train_loss: 0.0299  avg_val_loss: 0.0361  val_lwlrap: 0.619100  time: 29s<p>Epoch 88 - avg_train_loss: 0.0298  avg_val_loss: 0.1109  val_lwlrap: 0.164803  time: 29s<p>Epoch 89 - avg_train_loss: 0.0306  avg_val_loss: 0.1512  val_lwlrap: 0.103445  time: 29s<p>Epoch 90 - avg_train_loss: 0.0316  avg_val_loss: 0.4115  val_lwlrap: 0.075332  time: 29s<p>Epoch 91 - avg_train_loss: 0.0345  avg_val_loss: 0.1260  val_lwlrap: 0.089917  time: 29s<p>Epoch 92 - avg_train_loss: 0.0341  avg_val_loss: 0.1450  val_lwlrap: 0.067490  time: 29s<p>Epoch 93 - avg_train_loss: 0.0325  avg_val_loss: 0.1350  val_lwlrap: 0.087961  time: 29s<p>Epoch 94 - avg_train_loss: 0.0317  avg_val_loss: 0.0948  val_lwlrap: 0.110010  time: 29s<p>Epoch 95 - avg_train_loss: 0.0309  avg_val_loss: 0.0714  val_lwlrap: 0.319036  time: 29s<p>Epoch 96 - avg_train_loss: 0.0287  avg_val_loss: 0.0389  val_lwlrap: 0.548149  time: 29s<p>Epoch 97 - avg_train_loss: 0.0281  avg_val_loss: 0.0360  val_lwlrap: 0.633893  time: 29s<p>Epoch 98 - avg_train_loss: 0.0284  avg_val_loss: 0.0584  val_lwlrap: 0.423279  time: 29s<p>Epoch 99 - avg_train_loss: 0.0289  avg_val_loss: 0.1584  val_lwlrap: 0.094623  time: 29s<p>Epoch 100 - avg_train_loss: 0.0300  avg_val_loss: 0.1616  val_lwlrap: 0.069342  time: 29s<p>Epoch 101 - avg_train_loss: 0.0310  avg_val_loss: 0.2015  val_lwlrap: 0.092347  time: 29s<p>Epoch 102 - avg_train_loss: 0.0330  avg_val_loss: 0.1801  val_lwlrap: 0.091938  time: 29s<p>Epoch 103 - avg_train_loss: 0.0316  avg_val_loss: 0.1554  val_lwlrap: 0.077320  time: 29s<p>Epoch 104 - avg_train_loss: 0.0300  avg_val_loss: 0.1726  val_lwlrap: 0.111753  time: 29s<p>Epoch 105 - avg_train_loss: 0.0277  avg_val_loss: 0.1104  val_lwlrap: 0.235090  time: 29s<p>Epoch 106 - avg_train_loss: 0.0266  avg_val_loss: 0.0676  val_lwlrap: 0.256839  time: 29s<p>Epoch 107 - avg_train_loss: 0.0261  avg_val_loss: 0.0350  val_lwlrap: 0.647116  time: 29s<p>Epoch 108 - avg_train_loss: 0.0260  avg_val_loss: 0.0739  val_lwlrap: 0.381364  time: 29s<p>Epoch 109 - avg_train_loss: 0.0262  avg_val_loss: 0.1584  val_lwlrap: 0.161228  time: 29s<p>Epoch 110 - avg_train_loss: 0.0276  avg_val_loss: 0.1181  val_lwlrap: 0.090748  time: 29s<p>Epoch 111 - avg_train_loss: 0.0303  avg_val_loss: 0.1776  val_lwlrap: 0.085013  time: 29s<p>Epoch 112 - avg_train_loss: 0.0302  avg_val_loss: 0.1884  val_lwlrap: 0.100206  time: 29s<p>Epoch 113 - avg_train_loss: 0.0287  avg_val_loss: 0.2173  val_lwlrap: 0.078378  time: 29s<p>Epoch 114 - avg_train_loss: 0.0288  avg_val_loss: 0.1817  val_lwlrap: 0.092926  time: 29s<p>Epoch 115 - avg_train_loss: 0.0266  avg_val_loss: 0.1180  val_lwlrap: 0.165772  time: 29s<p>Epoch 116 - avg_train_loss: 0.0243  avg_val_loss: 0.0473  val_lwlrap: 0.519615  time: 29s<p>Epoch 117 - avg_train_loss: 0.0242  avg_val_loss: 0.0358  val_lwlrap: 0.643399  time: 29s<p>Epoch 118 - avg_train_loss: 0.0245  avg_val_loss: 0.0402  val_lwlrap: 0.566400  time: 29s"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = train_model(x_train, y_train, transforms_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 107, 'best_lwlrap': 0.6471161461420796}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
    "    batch_size = 256\n",
    "\n",
    "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load('weight_best.pt'))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs, all_fnames = [], []\n",
    "\n",
    "    pb = progress_bar(test_loader)\n",
    "    for images, fnames in pb:\n",
    "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
    "        all_outputs.append(preds.cpu().numpy())\n",
    "        all_fnames.extend(fnames)\n",
    "\n",
    "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                              index=all_fnames,\n",
    "                              columns=map(str, range(num_classes)))\n",
    "    test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='154' class='' max='154', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [154/154 00:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>3.287491e-06</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>5.276774e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.441914e-04</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>3.693046e-04</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>4.129527e-07</td>\n",
       "      <td>1.939518e-06</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>2.798732e-06</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>2.471655e-05</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>2.532927e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>8.151841e-04</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1.066537e-05</td>\n",
       "      <td>2.415684e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>3.892663e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.040156</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>1.797018e-04</td>\n",
       "      <td>1.108660e-02</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>5.529006e-02</td>\n",
       "      <td>0.018625</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>2.046373e-04</td>\n",
       "      <td>3.911147e-05</td>\n",
       "      <td>1.404323e-05</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>5.096712e-07</td>\n",
       "      <td>5.656731e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.299820e-05</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.060407</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.226297e-04</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.386490e-04</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>7.428721e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>5.286192e-06</td>\n",
       "      <td>2.065161e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0.117928</td>\n",
       "      <td>1.767256e-04</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>5.168794e-03</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>2.132208e-03</td>\n",
       "      <td>0.036993</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>7.369064e-04</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.185147</td>\n",
       "      <td>1.196213e-03</td>\n",
       "      <td>2.385559e-03</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>1.056071e-02</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>1.937947e-03</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>4.767527e-03</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>3.707767e-04</td>\n",
       "      <td>0.022710</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>9.997061e-03</td>\n",
       "      <td>1.122725e-02</td>\n",
       "      <td>0.013644</td>\n",
       "      <td>1.354540e-02</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>1.311454e-02</td>\n",
       "      <td>1.275687e-03</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>3.547962e-02</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>8.847233e-03</td>\n",
       "      <td>9.573084e-03</td>\n",
       "      <td>6.306160e-04</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>5.822891e-03</td>\n",
       "      <td>3.920632e-03</td>\n",
       "      <td>0.142471</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>1.046029e-02</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>6.749173e-03</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>6.206869e-03</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>7.217503e-04</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>3.635038e-03</td>\n",
       "      <td>2.402800e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>1.152448e-04</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.708944e-05</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>2.448616e-02</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>4.475451e-03</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>4.373672e-04</td>\n",
       "      <td>3.509085e-04</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>2.284902e-04</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>8.629473e-03</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.518677e-04</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.664457e-03</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>5.810190e-04</td>\n",
       "      <td>1.220739e-04</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>8.546601e-05</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.128137e-05</td>\n",
       "      <td>6.594335e-04</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>3.868054e-04</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>4.452228e-04</td>\n",
       "      <td>1.946269e-04</td>\n",
       "      <td>4.288235e-03</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.310266e-04</td>\n",
       "      <td>5.657205e-03</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.534339e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.372382</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>4.092097e-04</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.146096</td>\n",
       "      <td>2.336361e-04</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>4.556657e-02</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>5.217469e-05</td>\n",
       "      <td>2.679311e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>6.686710e-08</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>9.728378e-08</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>2.489633e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>4.338166e-07</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>1.664495e-04</td>\n",
       "      <td>3.077663e-08</td>\n",
       "      <td>0.094936</td>\n",
       "      <td>9.673671e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5.961541e-08</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.248063e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.515831e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>5.349171e-08</td>\n",
       "      <td>2.344220e-03</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>9.281410e-07</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.173003e-03</td>\n",
       "      <td>1.236457e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.147218e-09</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>4.918168e-07</td>\n",
       "      <td>3.060003e-05</td>\n",
       "      <td>4.125517e-08</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>8.489729e-02</td>\n",
       "      <td>9.490743e-07</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.961974</td>\n",
       "      <td>4.024679e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.652350e-08</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.817959e-04</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3.773219e-08</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>2.006490e-08</td>\n",
       "      <td>2.409246e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>3.437413e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.670279e-04</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>2.333719e-05</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>8.025169e-01</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.636016e-05</td>\n",
       "      <td>1.289648e-04</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.171895e-06</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>9.304669e-07</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>3.327210e-05</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>2.680193e-03</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.009449e-04</td>\n",
       "      <td>4.352136e-08</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2.458340e-06</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>9.840305e-07</td>\n",
       "      <td>2.890868e-01</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>4.787795e-05</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.662614e-05</td>\n",
       "      <td>7.393506e-07</td>\n",
       "      <td>1.318035e-02</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.613244e-04</td>\n",
       "      <td>3.693204e-03</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.215415e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>7.973961e-04</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>3.264478e-07</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.952888e-04</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.380693e-05</td>\n",
       "      <td>2.524118e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...               2.065161e-05\n",
       "1  0012633b.wav        ...               2.402800e-01\n",
       "2  001ed5f1.wav        ...               2.679311e-04\n",
       "3  00294be0.wav        ...               2.409246e-02\n",
       "4  003fde7a.wav        ...               2.524118e-07\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[labels] = test_preds.values\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
