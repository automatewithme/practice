{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trail_8_resnet_18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eHnoL6b4P2uw",
        "ywFnbu3eP5nW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Haq2PI9sBZ4",
        "colab_type": "text"
      },
      "source": [
        "implementation:\n",
        "\n",
        "*   https://www.kaggle.com/daisukelab/cnn-2d-basic-solution-powered-by-fast-ai\n",
        "*   https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHnoL6b4P2uw",
        "colab_type": "text"
      },
      "source": [
        "### Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4fj8QJuPXUJ",
        "colab_type": "code",
        "outputId": "7d2679f7-86a7-4beb-bee8-2d69bc34e240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838167&Signature=MIzEcS1L3DIuogUv42vVpG8nkgbUAKG%2F0JjhqwoGd%2B6%2FgM1xqKYdcwu%2Bxcs39PNnbSAj5QNu5NHD5uwCqkaH5yM30eGVIoC0uXybB5p4IqpAhrnOWN33sJ8QATG8SYFGe73B%2Bv%2Bseow2TmJ7OWp9EBX%2BwYW3vQHVXZkaeMoo7epIldBSoBr%2FdG%2FwHdSsyy%2FeXm8LU7BOEq6A1jBCdtejriZdioSYsPVUn1W9jwjgrYQo4KykapKtrYwG4ztysgB9GrqPpv0RIi%2FHSXypZo%2FqUeknTUyy2CdZsmmfb3TjRFuAiDNfX5kzuhcsqwpbHieVdjnW%2Fwu%2BnUdFCp6m6YWlPA%3D%3D\" -O \"sample_submission.csv\" -c"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 12:58:08--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838167&Signature=MIzEcS1L3DIuogUv42vVpG8nkgbUAKG%2F0JjhqwoGd%2B6%2FgM1xqKYdcwu%2Bxcs39PNnbSAj5QNu5NHD5uwCqkaH5yM30eGVIoC0uXybB5p4IqpAhrnOWN33sJ8QATG8SYFGe73B%2Bv%2Bseow2TmJ7OWp9EBX%2BwYW3vQHVXZkaeMoo7epIldBSoBr%2FdG%2FwHdSsyy%2FeXm8LU7BOEq6A1jBCdtejriZdioSYsPVUn1W9jwjgrYQo4KykapKtrYwG4ztysgB9GrqPpv0RIi%2FHSXypZo%2FqUeknTUyy2CdZsmmfb3TjRFuAiDNfX5kzuhcsqwpbHieVdjnW%2Fwu%2BnUdFCp6m6YWlPA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 2607:f8b0:4001:c1b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 194835 (190K) [text/csv]\n",
            "Saving to: ‘sample_submission.csv’\n",
            "\n",
            "\rsample_submission.c   0%[                    ]       0  --.-KB/s               \rsample_submission.c 100%[===================>] 190.27K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2019-05-11 12:58:09 (97.0 MB/s) - ‘sample_submission.csv’ saved [194835/194835]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0mlUkNgPm3a",
        "colab_type": "code",
        "outputId": "95b2ca48-d3ce-4196-e8f8-7e5eb15252c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838179&Signature=NTKEVQouLiWV9DqV1TRCfqzo4Llvj18R7R0epMmR2n%2F18ghJrfBOOBxE%2FyeIcWlD21sSgNI1FZ%2F4Chh3xdQYhunL8XqAJdKYke50w9PiV4GxeJjSppJyqrzOAXUkjMcHp5GrJG5I%2FQT6e%2FRjC4WgQ5Q3F73XhxpfF7kgy%2B%2FH5epJuia1mzjfqutt8TeXHWtxfJrW%2FGrBQsMrd%2Ba%2FMbcgn9f8B4RkBvUtmQ%2B7wuoqD25F68UBe2%2Br6yz%2B12KPT1zHdY%2FwaUoL7IF5Je5rEbmeKyPWMOi32P4S1F82zIi8Lp%2Bwyqp1CVQqiXCCahYkHxfgnMVHJZmOloLmsgg397Bm%2FA%3D%3D\" -O \"train_curated.csv\" -c"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 12:58:12--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838179&Signature=NTKEVQouLiWV9DqV1TRCfqzo4Llvj18R7R0epMmR2n%2F18ghJrfBOOBxE%2FyeIcWlD21sSgNI1FZ%2F4Chh3xdQYhunL8XqAJdKYke50w9PiV4GxeJjSppJyqrzOAXUkjMcHp5GrJG5I%2FQT6e%2FRjC4WgQ5Q3F73XhxpfF7kgy%2B%2FH5epJuia1mzjfqutt8TeXHWtxfJrW%2FGrBQsMrd%2Ba%2FMbcgn9f8B4RkBvUtmQ%2B7wuoqD25F68UBe2%2Br6yz%2B12KPT1zHdY%2FwaUoL7IF5Je5rEbmeKyPWMOi32P4S1F82zIi8Lp%2Bwyqp1CVQqiXCCahYkHxfgnMVHJZmOloLmsgg397Bm%2FA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143137 (140K) [text/csv]\n",
            "Saving to: ‘train_curated.csv’\n",
            "\n",
            "\rtrain_curated.csv     0%[                    ]       0  --.-KB/s               \rtrain_curated.csv   100%[===================>] 139.78K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-05-11 12:58:12 (98.1 MB/s) - ‘train_curated.csv’ saved [143137/143137]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTXMdoKhPqb9",
        "colab_type": "code",
        "outputId": "cea14cf6-4e4d-4618-c358-53f5125189fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838190&Signature=KvC%2FRXp2k6LrlPOcVtvyFDyOYMV2jJN7cLP35sjEdBHzgSZ4GAoZn3m1Oj%2BamVpz39bA%2FeKrvfkEBCoSy%2Bt2o2kJEitQ5mLeJwi7bwiN3y0mwycFWO6rDoW7SpvoHe%2F1%2BPcpAA31vfd0Itc3H1Tgh7zdt7MU6HwtA0oqZO0a7AZMTP64qmHGKDyStPPR6uI9XsPPgLIT5GsA3%2FMDa%2FQpXVe25i7jHmocmYkvXKt5TeovWLiifnHZMFolCNap0DTSq0bceGLaEZ%2BDPGbPRKLAGtc4dTXhwkomD3J79k3lz1%2BKSa13pJ5aLJSi5uIiPUGMkQSPoRweQB7RvJO3vDGcBw%3D%3D\" -O \"train_noisy.csv\" -c"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 12:58:15--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838190&Signature=KvC%2FRXp2k6LrlPOcVtvyFDyOYMV2jJN7cLP35sjEdBHzgSZ4GAoZn3m1Oj%2BamVpz39bA%2FeKrvfkEBCoSy%2Bt2o2kJEitQ5mLeJwi7bwiN3y0mwycFWO6rDoW7SpvoHe%2F1%2BPcpAA31vfd0Itc3H1Tgh7zdt7MU6HwtA0oqZO0a7AZMTP64qmHGKDyStPPR6uI9XsPPgLIT5GsA3%2FMDa%2FQpXVe25i7jHmocmYkvXKt5TeovWLiifnHZMFolCNap0DTSq0bceGLaEZ%2BDPGbPRKLAGtc4dTXhwkomD3J79k3lz1%2BKSa13pJ5aLJSi5uIiPUGMkQSPoRweQB7RvJO3vDGcBw%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.191.128, 2607:f8b0:4001:c1b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.191.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 584806 (571K) [text/csv]\n",
            "Saving to: ‘train_noisy.csv’\n",
            "\n",
            "\rtrain_noisy.csv       0%[                    ]       0  --.-KB/s               \rtrain_noisy.csv     100%[===================>] 571.10K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2019-05-11 12:58:15 (78.2 MB/s) - ‘train_noisy.csv’ saved [584806/584806]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75LDMVcPs52",
        "colab_type": "code",
        "outputId": "a10dc335-f049-4c38-9092-67a88062b5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838202&Signature=LrJ5DBITMPNEATLqU%2Fsmo0%2BxQUa%2FcNDuix8iYhHKb8QpAIdBm1xyc4btf2SRlOrU1DdI9bFuZodE59A1EYhu4EtNY2a61MiKjvsQEJwnMnDwChlIVSMPVkvnNnRgJOsyOFxXYnsFtLtfSrMvmlUdOaoy9S1IAXlUOVIvL2tSuBPXy1%2B9LtfyKAj1SCpRF3zOUG54Ku0JeeendbCPDTJn2pcS2Ff%2Fgpk%2BulxQDItQHe782njoohESv3x1FmwYi8oxe2P%2F9SZg1LBh5YHa2rTlSFm9m5CrqA5Qs7vDT%2BnxTuKHo2MvYfFSBrTnVRKzdu1TIyyc%2BjUhum4OxSnWVlTisg%3D%3D\" -O \"test.zip\" -c"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 12:58:18--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838202&Signature=LrJ5DBITMPNEATLqU%2Fsmo0%2BxQUa%2FcNDuix8iYhHKb8QpAIdBm1xyc4btf2SRlOrU1DdI9bFuZodE59A1EYhu4EtNY2a61MiKjvsQEJwnMnDwChlIVSMPVkvnNnRgJOsyOFxXYnsFtLtfSrMvmlUdOaoy9S1IAXlUOVIvL2tSuBPXy1%2B9LtfyKAj1SCpRF3zOUG54Ku0JeeendbCPDTJn2pcS2Ff%2Fgpk%2BulxQDItQHe782njoohESv3x1FmwYi8oxe2P%2F9SZg1LBh5YHa2rTlSFm9m5CrqA5Qs7vDT%2BnxTuKHo2MvYfFSBrTnVRKzdu1TIyyc%2BjUhum4OxSnWVlTisg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c1d::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 698756070 (666M) [application/zip]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>] 666.38M   127MB/s    in 5.9s    \n",
            "\n",
            "2019-05-11 12:58:24 (113 MB/s) - ‘test.zip’ saved [698756070/698756070]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doLUxbxlPyes",
        "colab_type": "code",
        "outputId": "f97d750b-c333-4f9a-b378-7e1b6751c9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838236&Signature=WFaCAuPlSqPhLfYykFnGOS4Ok92xbcHQmYdO9%2Bsv4WRMzcbnWXIR6p6i8Ow%2BX6t%2FSRWsACKVLIAtXqEjS7f13Iy3sWaw5g38aAWFxjndPl0tP35KQ69OppbNcXbtW49VmyCDNunPUfN48EuULZKg1aaB2SPTTLLKpnLJcBfCUUckd21PcczhgFq11RRDNlqBOSFWv1OrPk2Wz%2BisgOOyGzq3vj6fqBE6ZFVwMovY3gyjq7jzqIzSgcBdhMFlAPDYBCPWfqriB%2BjNF8GSBij1I9w3%2BrvkSHJoKKMKNiGp9HQIxJBzWXt3qUIboqhoGQKv%2FQaIJLhOjYTIf2xrYQ3maA%3D%3D\" -O \"train_curated.zip\" -c"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 12:58:27--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838236&Signature=WFaCAuPlSqPhLfYykFnGOS4Ok92xbcHQmYdO9%2Bsv4WRMzcbnWXIR6p6i8Ow%2BX6t%2FSRWsACKVLIAtXqEjS7f13Iy3sWaw5g38aAWFxjndPl0tP35KQ69OppbNcXbtW49VmyCDNunPUfN48EuULZKg1aaB2SPTTLLKpnLJcBfCUUckd21PcczhgFq11RRDNlqBOSFWv1OrPk2Wz%2BisgOOyGzq3vj6fqBE6ZFVwMovY3gyjq7jzqIzSgcBdhMFlAPDYBCPWfqriB%2BjNF8GSBij1I9w3%2BrvkSHJoKKMKNiGp9HQIxJBzWXt3qUIboqhoGQKv%2FQaIJLhOjYTIf2xrYQ3maA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.202.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2406491583 (2.2G) [application/zip]\n",
            "Saving to: ‘train_curated.zip’\n",
            "\n",
            "train_curated.zip   100%[===================>]   2.24G   137MB/s    in 20s     \n",
            "\n",
            "2019-05-11 12:58:47 (113 MB/s) - ‘train_curated.zip’ saved [2406491583/2406491583]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNnA16iPy_T",
        "colab_type": "code",
        "outputId": "02640cc2-4aeb-46cb-8bc8-45546e254ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838250&Signature=YEEpWjFrGSJ8gvjok6TRz0%2FVHRME2o30YX1vb%2Bsor2w2a5qUlZr%2FVnU7A4T3wicTwZrJwWPbPtjh4XTQ3qjIyakKaI0d19HtNr9BXNNkvXROmbw16lNqWTRfO01%2BOhc%2FSpdp6rc6NTEhcSDh5QABAA33fys9nwg2aDdv%2BNLcnmrhgScpbXLdIZhhmOa2Nws9p25YMhVLWsHLta0VGgzqLmjGSMnCxgjDmGzq2dXEX84sCAa0yHHq5gM13GYzMd44Xd2f7PmOQKnIjCAgt8fdtQSIMFkFgWUxiMBy66zP0tqd0w7LMn6u2Dtbdh7qr7R2a2liqkvGiogQDD09LgOZ8A%3D%3D\" -O \"train_noisy.zip\" -c"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 12:58:50--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838250&Signature=YEEpWjFrGSJ8gvjok6TRz0%2FVHRME2o30YX1vb%2Bsor2w2a5qUlZr%2FVnU7A4T3wicTwZrJwWPbPtjh4XTQ3qjIyakKaI0d19HtNr9BXNNkvXROmbw16lNqWTRfO01%2BOhc%2FSpdp6rc6NTEhcSDh5QABAA33fys9nwg2aDdv%2BNLcnmrhgScpbXLdIZhhmOa2Nws9p25YMhVLWsHLta0VGgzqLmjGSMnCxgjDmGzq2dXEX84sCAa0yHHq5gM13GYzMd44Xd2f7PmOQKnIjCAgt8fdtQSIMFkFgWUxiMBy66zP0tqd0w7LMn6u2Dtbdh7qr7R2a2liqkvGiogQDD09LgOZ8A%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.234.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.234.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21504922116 (20G) [application/zip]\n",
            "Saving to: ‘train_noisy.zip’\n",
            "\n",
            "train_noisy.zip     100%[===================>]  20.03G   103MB/s    in 3m 18s  \n",
            "\n",
            "2019-05-11 13:02:08 (104 MB/s) - ‘train_noisy.zip’ saved [21504922116/21504922116]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fJaLfzGynqy",
        "colab_type": "text"
      },
      "source": [
        "***Preprocessed data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bZWNGSWypWV",
        "colab_type": "code",
        "outputId": "4e2c4b1b-867d-44f1-9341-c2e256b19555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838149&Signature=DvpGKn5On8bg%2BdsrHS3YF0es3qVaXzA8BkLhpi1xAiYoJzJZ7oF6qvVn%2BEGt1NS%2BvP0vn%2FJt35sxl6AyxxkJT0Jpuea2oEyaACL8%2BC1dBMEarSg%2FLp7hA%2FhZvAx4If7%2FYa69118IIh%2B89xsHeDB9xh2Zfear38udfqJTXtuK7vrvm6dXGlhXfd0SUAOkjNt7OmNzOT7NX1brN9U832LvMjSksKDXjC%2BLvct712HBgOY7JIHeyu7uWJMHLk4avq8tKe33d%2BrO5Jsla%2FLRa6LVyKj4BnTP65h9dzLGcyqhIwGabKjBiEDnSd7go3jaaxVc8iXUr0OyjatiJ8q7%2Bat9jA%3D%3D\" -O \"fat2019_prep_mels1.zip\" -c"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 13:02:11--  https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557838149&Signature=DvpGKn5On8bg%2BdsrHS3YF0es3qVaXzA8BkLhpi1xAiYoJzJZ7oF6qvVn%2BEGt1NS%2BvP0vn%2FJt35sxl6AyxxkJT0Jpuea2oEyaACL8%2BC1dBMEarSg%2FLp7hA%2FhZvAx4If7%2FYa69118IIh%2B89xsHeDB9xh2Zfear38udfqJTXtuK7vrvm6dXGlhXfd0SUAOkjNt7OmNzOT7NX1brN9U832LvMjSksKDXjC%2BLvct712HBgOY7JIHeyu7uWJMHLk4avq8tKe33d%2BrO5Jsla%2FLRa6LVyKj4BnTP65h9dzLGcyqhIwGabKjBiEDnSd7go3jaaxVc8iXUr0OyjatiJ8q7%2Bat9jA%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 2607:f8b0:4001:c14::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2865032102 (2.7G) [application/zip]\n",
            "Saving to: ‘fat2019_prep_mels1.zip’\n",
            "\n",
            "fat2019_prep_mels1. 100%[===================>]   2.67G   107MB/s    in 27s     \n",
            "\n",
            "2019-05-11 13:02:38 (102 MB/s) - ‘fat2019_prep_mels1.zip’ saved [2865032102/2865032102]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywFnbu3eP5nW",
        "colab_type": "text"
      },
      "source": [
        "### Exploring dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0tOhnVcACC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test\n",
        "!mkdir train_curated\n",
        "!mkdir train_noisy\n",
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pokwjdG2zCjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq fat2019_prep_mels1.zip -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1Wq71PP43o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLZZ6nuWQMqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_curated.zip -d train_curated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpYGeV7mQMkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_noisy.zip -d train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK-JmCd_QMWx",
        "colab_type": "text"
      },
      "source": [
        "To apply deep learning technique, we first have to come up with a way to provide effective converse from audio data to any other form which will make it effective for deep learning technique for multilabeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l5HQ4X5SmxC",
        "colab_type": "text"
      },
      "source": [
        "Audio conversion to 2D\n",
        "Almost copyed from my repository: https://github.com/daisukelab/ml-sound-classifier\n",
        "\n",
        "Handle sampling rate 44.1kHz as is, no information loss.\n",
        "Size of each file will be 128 x L, L is audio seconds x 128; [128, 256] if sound is 2s long.\n",
        "Convert to Mel-spectrogram, not MFCC. We are handling general sound rather than human voice. https://en.wikipedia.org/wiki/Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PZG8p-dchS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv -t data test train_curated train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPW_sIidU0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_submission.csv train_curated.csv train_noisy.csv data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFndQ6_MhLb7",
        "colab_type": "code",
        "outputId": "c20c4924-3e5c-4361-f685-dd4d9591faa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mels_test.pkl\t\t    sample_submission.csv  train_noisy\n",
            "mels_train_curated.pkl\t    test\t\t   train_noisy.csv\n",
            "mels_train_noisy.pkl\t    train_curated\t   trn_noisy_best50s.csv\n",
            "mels_trn_noisy_best50s.pkl  train_curated.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTCWqn31MKk",
        "colab_type": "text"
      },
      "source": [
        "## Testing different dL techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti-PQPO2uNQC",
        "colab_type": "text"
      },
      "source": [
        "### 2. Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODeTKQbJwFuJ",
        "colab_type": "text"
      },
      "source": [
        "***Simple changes, significant improvement in lb***\n",
        "\n",
        "Now with different convolution architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcCNIj42060g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from psutil import cpu_count\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3lWLSN7xAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 520\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_bwTu3xCHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_JOBS = cpu_count()\n",
        "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
        "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
        "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jhnnjifxCD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UthfHLBOxCA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gdnVV-xB-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK4Xhj0IxB7S",
        "colab_type": "code",
        "outputId": "6d2ba04c-ab68-4945-84f3-e7e0fe50d557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>labels</th>\n",
              "      <th>singled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0006ae4e.wav</td>\n",
              "      <td>Bark</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0019ef41.wav</td>\n",
              "      <td>Raindrop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ec0ad.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0026c7cb.wav</td>\n",
              "      <td>Run</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0026f116.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname           labels singled\n",
              "0  0006ae4e.wav             Bark     NaN\n",
              "1  0019ef41.wav         Raindrop     NaN\n",
              "2  001ec0ad.wav  Finger_snapping     NaN\n",
              "3  0026c7cb.wav              Run     NaN\n",
              "4  0026f116.wav  Finger_snapping     NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySDLo2fTxB4x",
        "colab_type": "code",
        "outputId": "d65a7721-2098-47c9-e49a-9abcb261ad13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>...</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
              "0  000ccb97.wav                                   0          0   \n",
              "1  0012633b.wav                                   0          0   \n",
              "2  001ed5f1.wav                                   0          0   \n",
              "3  00294be0.wav                                   0          0   \n",
              "4  003fde7a.wav                                   0          0   \n",
              "\n",
              "   Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
              "0                0         0     0          0            0   \n",
              "1                0         0     0          0            0   \n",
              "2                0         0     0          0            0   \n",
              "3                0         0     0          0            0   \n",
              "4                0         0     0          0            0   \n",
              "\n",
              "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
              "0                             0             0  ...             0   \n",
              "1                             0             0  ...             0   \n",
              "2                             0             0  ...             0   \n",
              "3                             0             0  ...             0   \n",
              "4                             0             0  ...             0   \n",
              "\n",
              "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
              "0                                0                    0                   0   \n",
              "1                                0                    0                   0   \n",
              "2                                0                    0                   0   \n",
              "3                                0                    0                   0   \n",
              "4                                0                    0                   0   \n",
              "\n",
              "   Water_tap_and_faucet  Waves_and_surf  Whispering  Writing  Yell  \\\n",
              "0                     0               0           0        0     0   \n",
              "1                     0               0           0        0     0   \n",
              "2                     0               0           0        0     0   \n",
              "3                     0               0           0        0     0   \n",
              "4                     0               0           0        0     0   \n",
              "\n",
              "   Zipper_(clothing)  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  0  \n",
              "4                  0  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK8cx8TbxTKI",
        "colab_type": "code",
        "outputId": "8079563a-4ff7-489a-9b91-ceab8a702ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accelerating_and_revving_and_vroom',\n",
              " 'Accordion',\n",
              " 'Acoustic_guitar',\n",
              " 'Applause',\n",
              " 'Bark',\n",
              " 'Bass_drum',\n",
              " 'Bass_guitar',\n",
              " 'Bathtub_(filling_or_washing)',\n",
              " 'Bicycle_bell',\n",
              " 'Burping_and_eructation',\n",
              " 'Bus',\n",
              " 'Buzz',\n",
              " 'Car_passing_by',\n",
              " 'Cheering',\n",
              " 'Chewing_and_mastication',\n",
              " 'Child_speech_and_kid_speaking',\n",
              " 'Chink_and_clink',\n",
              " 'Chirp_and_tweet',\n",
              " 'Church_bell',\n",
              " 'Clapping',\n",
              " 'Computer_keyboard',\n",
              " 'Crackle',\n",
              " 'Cricket',\n",
              " 'Crowd',\n",
              " 'Cupboard_open_or_close',\n",
              " 'Cutlery_and_silverware',\n",
              " 'Dishes_and_pots_and_pans',\n",
              " 'Drawer_open_or_close',\n",
              " 'Drip',\n",
              " 'Electric_guitar',\n",
              " 'Fart',\n",
              " 'Female_singing',\n",
              " 'Female_speech_and_woman_speaking',\n",
              " 'Fill_(with_liquid)',\n",
              " 'Finger_snapping',\n",
              " 'Frying_(food)',\n",
              " 'Gasp',\n",
              " 'Glockenspiel',\n",
              " 'Gong',\n",
              " 'Gurgling',\n",
              " 'Harmonica',\n",
              " 'Hi-hat',\n",
              " 'Hiss',\n",
              " 'Keys_jangling',\n",
              " 'Knock',\n",
              " 'Male_singing',\n",
              " 'Male_speech_and_man_speaking',\n",
              " 'Marimba_and_xylophone',\n",
              " 'Mechanical_fan',\n",
              " 'Meow',\n",
              " 'Microwave_oven',\n",
              " 'Motorcycle',\n",
              " 'Printer',\n",
              " 'Purr',\n",
              " 'Race_car_and_auto_racing',\n",
              " 'Raindrop',\n",
              " 'Run',\n",
              " 'Scissors',\n",
              " 'Screaming',\n",
              " 'Shatter',\n",
              " 'Sigh',\n",
              " 'Sink_(filling_or_washing)',\n",
              " 'Skateboard',\n",
              " 'Slam',\n",
              " 'Sneeze',\n",
              " 'Squeak',\n",
              " 'Stream',\n",
              " 'Strum',\n",
              " 'Tap',\n",
              " 'Tick-tock',\n",
              " 'Toilet_flush',\n",
              " 'Traffic_noise_and_roadway_noise',\n",
              " 'Trickle_and_dribble',\n",
              " 'Walk_and_footsteps',\n",
              " 'Water_tap_and_faucet',\n",
              " 'Waves_and_surf',\n",
              " 'Whispering',\n",
              " 'Writing',\n",
              " 'Yell',\n",
              " 'Zipper_(clothing)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4t9AiIxTG-",
        "colab_type": "code",
        "outputId": "b1eeecc7-5d6c-4de4-da2a-fab68832e5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9s5PMk_xTEM",
        "colab_type": "code",
        "outputId": "3b00af0f-9795-47c8-8f07-14041dddae69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dc941ZJxS_4",
        "colab_type": "code",
        "outputId": "f934109d-a38e-4275-a47e-21b4e33368cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 1120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDgnY7xmxbAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUzFIqazxa3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlYwSC7oxaw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkIkfB9qAHJ0",
        "colab_type": "text"
      },
      "source": [
        "### Exploration of different architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgPz2pJyAKxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3fb47f8-b599-41be-c895-e3d9bc1fdaec"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncriterion = nn.CrossEntropyLoss()\\n\\n# Observe that all parameters are being optimized\\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\\n\\n# Decay LR by a factor of 0.1 every 7 epochs\\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzlvwtgK7Oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3e25a959-49a9-45bd-b9ca-3425cc20cb8b"
      },
      "source": [
        "model_ft.classifier"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.5)\n",
              "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (2): ReLU(inplace)\n",
              "  (3): Dropout(p=0.5)\n",
              "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (5): ReLU(inplace)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy1pGvd8MbSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as defined in the link:\n",
        "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OtydueIxiiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUSz8mScyVsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(511, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(127, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nVtMd4xidL",
        "colab_type": "code",
        "outputId": "66d2f716-c45c-4b94-bf6c-b3057883adad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.2)\n",
              "    (1): Linear(in_features=511, out_features=128, bias=True)\n",
              "    (2): PReLU(num_parameters=1)\n",
              "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Dropout(p=0.1)\n",
              "    (5): Linear(in_features=127, out_features=80, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeyzYJM7xk9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 128\n",
        "    test_batch_size = 256\n",
        "    lr = 1e-3\n",
        "    eta_min = 1e-5\n",
        "    t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    #model = Classifier(num_classes=num_classes).cuda()\n",
        "    model = model_ft\n",
        "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmVih93Dxk5x",
        "colab_type": "code",
        "outputId": "a056989d-6a98-4675-ccc8-efea4aaa5113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2731
        }
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Epoch 1 - avg_train_loss: 0.0931  avg_val_loss: 0.0731  val_lwlrap: 0.065711  time: 33s<p>Epoch 2 - avg_train_loss: 0.0677  avg_val_loss: 0.0668  val_lwlrap: 0.142413  time: 33s<p>Epoch 3 - avg_train_loss: 0.0623  avg_val_loss: 0.0603  val_lwlrap: 0.236051  time: 32s<p>Epoch 4 - avg_train_loss: 0.0586  avg_val_loss: 0.0579  val_lwlrap: 0.277778  time: 32s<p>Epoch 5 - avg_train_loss: 0.0552  avg_val_loss: 0.0557  val_lwlrap: 0.331627  time: 33s<p>Epoch 6 - avg_train_loss: 0.0540  avg_val_loss: 0.0548  val_lwlrap: 0.350965  time: 32s<p>Epoch 7 - avg_train_loss: 0.0539  avg_val_loss: 0.0546  val_lwlrap: 0.354135  time: 32s<p>Epoch 8 - avg_train_loss: 0.0553  avg_val_loss: 0.0575  val_lwlrap: 0.284408  time: 32s<p>Epoch 9 - avg_train_loss: 0.0559  avg_val_loss: 0.0552  val_lwlrap: 0.346758  time: 32s<p>Epoch 10 - avg_train_loss: 0.0550  avg_val_loss: 0.0601  val_lwlrap: 0.275456  time: 32s<p>Epoch 11 - avg_train_loss: 0.0536  avg_val_loss: 0.0582  val_lwlrap: 0.333921  time: 33s<p>Epoch 12 - avg_train_loss: 0.0509  avg_val_loss: 0.0670  val_lwlrap: 0.263236  time: 32s<p>Epoch 13 - avg_train_loss: 0.0498  avg_val_loss: 0.0498  val_lwlrap: 0.408743  time: 32s<p>Epoch 14 - avg_train_loss: 0.0452  avg_val_loss: 0.0461  val_lwlrap: 0.461330  time: 32s<p>Epoch 15 - avg_train_loss: 0.0414  avg_val_loss: 0.0435  val_lwlrap: 0.514513  time: 33s<p>Epoch 16 - avg_train_loss: 0.0394  avg_val_loss: 0.0432  val_lwlrap: 0.514778  time: 32s<p>Epoch 17 - avg_train_loss: 0.0397  avg_val_loss: 0.0433  val_lwlrap: 0.503819  time: 32s<p>Epoch 18 - avg_train_loss: 0.0418  avg_val_loss: 0.0592  val_lwlrap: 0.358985  time: 32s<p>Epoch 19 - avg_train_loss: 0.0447  avg_val_loss: 0.0513  val_lwlrap: 0.428132  time: 32s<p>Epoch 20 - avg_train_loss: 0.0451  avg_val_loss: 0.0797  val_lwlrap: 0.251710  time: 33s<p>Epoch 21 - avg_train_loss: 0.0439  avg_val_loss: 0.0598  val_lwlrap: 0.319184  time: 33s<p>Epoch 22 - avg_train_loss: 0.0443  avg_val_loss: 0.0551  val_lwlrap: 0.437684  time: 32s<p>Epoch 23 - avg_train_loss: 0.0404  avg_val_loss: 0.0473  val_lwlrap: 0.470671  time: 32s<p>Epoch 24 - avg_train_loss: 0.0355  avg_val_loss: 0.0463  val_lwlrap: 0.502023  time: 33s<p>Epoch 25 - avg_train_loss: 0.0320  avg_val_loss: 0.0398  val_lwlrap: 0.564215  time: 33s<p>Epoch 26 - avg_train_loss: 0.0306  avg_val_loss: 0.0380  val_lwlrap: 0.578099  time: 32s<p>Epoch 27 - avg_train_loss: 0.0300  avg_val_loss: 0.0403  val_lwlrap: 0.560966  time: 33s<p>Epoch 28 - avg_train_loss: 0.0322  avg_val_loss: 0.0449  val_lwlrap: 0.514542  time: 33s<p>Epoch 29 - avg_train_loss: 0.0363  avg_val_loss: 0.0509  val_lwlrap: 0.455473  time: 33s<p>Epoch 30 - avg_train_loss: 0.0381  avg_val_loss: 0.0853  val_lwlrap: 0.294438  time: 32s<p>Epoch 31 - avg_train_loss: 0.0371  avg_val_loss: 0.0514  val_lwlrap: 0.437696  time: 32s<p>Epoch 32 - avg_train_loss: 0.0360  avg_val_loss: 0.0484  val_lwlrap: 0.480392  time: 33s<p>Epoch 33 - avg_train_loss: 0.0334  avg_val_loss: 0.0655  val_lwlrap: 0.409973  time: 33s<p>Epoch 34 - avg_train_loss: 0.0287  avg_val_loss: 0.0432  val_lwlrap: 0.552037  time: 33s<p>Epoch 35 - avg_train_loss: 0.0246  avg_val_loss: 0.0382  val_lwlrap: 0.590911  time: 32s<p>Epoch 36 - avg_train_loss: 0.0228  avg_val_loss: 0.0381  val_lwlrap: 0.594303  time: 33s<p>Epoch 37 - avg_train_loss: 0.0230  avg_val_loss: 0.0396  val_lwlrap: 0.592311  time: 32s<p>Epoch 38 - avg_train_loss: 0.0249  avg_val_loss: 0.0424  val_lwlrap: 0.561311  time: 32s<p>Epoch 39 - avg_train_loss: 0.0291  avg_val_loss: 0.0691  val_lwlrap: 0.346006  time: 33s<p>Epoch 40 - avg_train_loss: 0.0319  avg_val_loss: 0.0544  val_lwlrap: 0.466041  time: 32s<p>Epoch 41 - avg_train_loss: 0.0318  avg_val_loss: 0.0527  val_lwlrap: 0.465605  time: 32s<p>Epoch 42 - avg_train_loss: 0.0304  avg_val_loss: 0.0557  val_lwlrap: 0.453524  time: 32s<p>Epoch 43 - avg_train_loss: 0.0274  avg_val_loss: 0.0475  val_lwlrap: 0.532965  time: 33s<p>Epoch 44 - avg_train_loss: 0.0223  avg_val_loss: 0.0580  val_lwlrap: 0.465627  time: 33s<p>Epoch 45 - avg_train_loss: 0.0190  avg_val_loss: 0.0416  val_lwlrap: 0.598559  time: 32s<p>Epoch 46 - avg_train_loss: 0.0179  avg_val_loss: 0.0421  val_lwlrap: 0.619968  time: 32s<p>Epoch 47 - avg_train_loss: 0.0181  avg_val_loss: 0.0411  val_lwlrap: 0.594325  time: 32s<p>Epoch 48 - avg_train_loss: 0.0194  avg_val_loss: 0.0442  val_lwlrap: 0.589629  time: 32s<p>Epoch 49 - avg_train_loss: 0.0226  avg_val_loss: 0.0455  val_lwlrap: 0.571707  time: 33s<p>Epoch 50 - avg_train_loss: 0.0279  avg_val_loss: 0.0624  val_lwlrap: 0.473808  time: 32s<p>Epoch 51 - avg_train_loss: 0.0289  avg_val_loss: 0.0707  val_lwlrap: 0.381234  time: 32s<p>Epoch 52 - avg_train_loss: 0.0270  avg_val_loss: 0.0810  val_lwlrap: 0.359614  time: 32s<p>Epoch 53 - avg_train_loss: 0.0216  avg_val_loss: 0.0451  val_lwlrap: 0.569869  time: 33s<p>Epoch 54 - avg_train_loss: 0.0184  avg_val_loss: 0.0434  val_lwlrap: 0.574103  time: 33s<p>Epoch 55 - avg_train_loss: 0.0149  avg_val_loss: 0.0412  val_lwlrap: 0.611379  time: 32s<p>Epoch 56 - avg_train_loss: 0.0137  avg_val_loss: 0.0408  val_lwlrap: 0.610393  time: 33s<p>Epoch 57 - avg_train_loss: 0.0142  avg_val_loss: 0.0431  val_lwlrap: 0.603429  time: 33s<p>Epoch 58 - avg_train_loss: 0.0159  avg_val_loss: 0.0583  val_lwlrap: 0.495343  time: 33s<p>Epoch 59 - avg_train_loss: 0.0230  avg_val_loss: 0.0643  val_lwlrap: 0.462659  time: 32s<p>Epoch 60 - avg_train_loss: 0.0263  avg_val_loss: 0.0577  val_lwlrap: 0.489740  time: 32s<p>Epoch 61 - avg_train_loss: 0.0261  avg_val_loss: 0.0656  val_lwlrap: 0.506716  time: 32s<p>Epoch 62 - avg_train_loss: 0.0234  avg_val_loss: 0.0446  val_lwlrap: 0.575120  time: 32s<p>Epoch 63 - avg_train_loss: 0.0189  avg_val_loss: 0.0495  val_lwlrap: 0.571509  time: 32s<p>Epoch 64 - avg_train_loss: 0.0151  avg_val_loss: 0.0452  val_lwlrap: 0.601772  time: 32s<p>Epoch 65 - avg_train_loss: 0.0121  avg_val_loss: 0.0418  val_lwlrap: 0.609293  time: 32s<p>Epoch 66 - avg_train_loss: 0.0109  avg_val_loss: 0.0453  val_lwlrap: 0.611693  time: 33s<p>Epoch 67 - avg_train_loss: 0.0109  avg_val_loss: 0.0446  val_lwlrap: 0.618833  time: 33s<p>Epoch 68 - avg_train_loss: 0.0127  avg_val_loss: 0.0496  val_lwlrap: 0.538194  time: 32s<p>Epoch 69 - avg_train_loss: 0.0201  avg_val_loss: 0.0465  val_lwlrap: 0.572130  time: 33s<p>Epoch 70 - avg_train_loss: 0.0208  avg_val_loss: 0.0778  val_lwlrap: 0.401270  time: 33s<p>Epoch 71 - avg_train_loss: 0.0217  avg_val_loss: 0.0635  val_lwlrap: 0.480372  time: 33s<p>Epoch 72 - avg_train_loss: 0.0190  avg_val_loss: 0.0474  val_lwlrap: 0.569013  time: 32s<p>Epoch 73 - avg_train_loss: 0.0164  avg_val_loss: 0.0500  val_lwlrap: 0.566070  time: 32s<p>Epoch 74 - avg_train_loss: 0.0124  avg_val_loss: 0.0589  val_lwlrap: 0.524891  time: 32s<p>Epoch 75 - avg_train_loss: 0.0097  avg_val_loss: 0.0485  val_lwlrap: 0.613147  time: 33s<p>Epoch 76 - avg_train_loss: 0.0091  avg_val_loss: 0.0474  val_lwlrap: 0.625119  time: 33s<p>Epoch 77 - avg_train_loss: 0.0092  avg_val_loss: 0.0476  val_lwlrap: 0.622437  time: 33s<p>Epoch 78 - avg_train_loss: 0.0102  avg_val_loss: 0.0479  val_lwlrap: 0.613292  time: 33s<p>Epoch 79 - avg_train_loss: 0.0131  avg_val_loss: 0.0593  val_lwlrap: 0.542768  time: 32s<p>Epoch 80 - avg_train_loss: 0.0180  avg_val_loss: 0.0530  val_lwlrap: 0.576808  time: 33s<p>Epoch 81 - avg_train_loss: 0.0150  avg_val_loss: 0.0738  val_lwlrap: 0.443779  time: 33s<p>Epoch 82 - avg_train_loss: 0.0199  avg_val_loss: 0.0615  val_lwlrap: 0.485621  time: 32s<p>Epoch 83 - avg_train_loss: 0.0157  avg_val_loss: 0.0553  val_lwlrap: 0.535277  time: 32s<p>Epoch 84 - avg_train_loss: 0.0107  avg_val_loss: 0.0469  val_lwlrap: 0.598435  time: 32s<p>Epoch 85 - avg_train_loss: 0.0088  avg_val_loss: 0.0456  val_lwlrap: 0.611657  time: 33s<p>Epoch 86 - avg_train_loss: 0.0073  avg_val_loss: 0.0444  val_lwlrap: 0.609428  time: 33s<p>Epoch 87 - avg_train_loss: 0.0078  avg_val_loss: 0.0475  val_lwlrap: 0.614164  time: 33s<p>Epoch 88 - avg_train_loss: 0.0085  avg_val_loss: 0.0494  val_lwlrap: 0.607709  time: 32s<p>Epoch 89 - avg_train_loss: 0.0115  avg_val_loss: 0.0709  val_lwlrap: 0.481312  time: 32s<p>Epoch 90 - avg_train_loss: 0.0140  avg_val_loss: 0.0570  val_lwlrap: 0.557156  time: 32s<p>Epoch 91 - avg_train_loss: 0.0186  avg_val_loss: 0.0643  val_lwlrap: 0.503079  time: 33s<p>Epoch 92 - avg_train_loss: 0.0148  avg_val_loss: 0.0600  val_lwlrap: 0.561525  time: 32s<p>Epoch 93 - avg_train_loss: 0.0119  avg_val_loss: 0.0609  val_lwlrap: 0.520414  time: 32s<p>Epoch 94 - avg_train_loss: 0.0089  avg_val_loss: 0.0525  val_lwlrap: 0.613672  time: 32s<p>Epoch 95 - avg_train_loss: 0.0071  avg_val_loss: 0.0565  val_lwlrap: 0.621552  time: 32s<p>Epoch 96 - avg_train_loss: 0.0060  avg_val_loss: 0.0505  val_lwlrap: 0.616951  time: 33s<p>Epoch 97 - avg_train_loss: 0.0060  avg_val_loss: 0.0494  val_lwlrap: 0.619884  time: 32s<p>Epoch 98 - avg_train_loss: 0.0067  avg_val_loss: 0.0584  val_lwlrap: 0.607368  time: 32s<p>Epoch 99 - avg_train_loss: 0.0082  avg_val_loss: 0.0581  val_lwlrap: 0.582374  time: 32s<p>Epoch 100 - avg_train_loss: 0.0112  avg_val_loss: 0.0806  val_lwlrap: 0.472417  time: 32s<p>Epoch 101 - avg_train_loss: 0.0153  avg_val_loss: 0.0714  val_lwlrap: 0.507959  time: 32s<p>Epoch 102 - avg_train_loss: 0.0122  avg_val_loss: 0.0663  val_lwlrap: 0.535635  time: 33s<p>Epoch 103 - avg_train_loss: 0.0118  avg_val_loss: 0.0556  val_lwlrap: 0.609038  time: 32s<p>Epoch 104 - avg_train_loss: 0.0073  avg_val_loss: 0.0569  val_lwlrap: 0.618542  time: 32s<p>Epoch 105 - avg_train_loss: 0.0059  avg_val_loss: 0.0565  val_lwlrap: 0.610447  time: 32s<p>Epoch 106 - avg_train_loss: 0.0054  avg_val_loss: 0.0530  val_lwlrap: 0.621628  time: 33s<p>Epoch 107 - avg_train_loss: 0.0050  avg_val_loss: 0.0520  val_lwlrap: 0.614824  time: 32s<p>Epoch 108 - avg_train_loss: 0.0054  avg_val_loss: 0.0576  val_lwlrap: 0.613262  time: 32s<p>Epoch 109 - avg_train_loss: 0.0065  avg_val_loss: 0.0830  val_lwlrap: 0.460316  time: 32s<p>Epoch 110 - avg_train_loss: 0.0102  avg_val_loss: 0.0769  val_lwlrap: 0.516524  time: 32s<p>Epoch 111 - avg_train_loss: 0.0111  avg_val_loss: 0.0826  val_lwlrap: 0.465588  time: 32s<p>Epoch 112 - avg_train_loss: 0.0103  avg_val_loss: 0.0643  val_lwlrap: 0.547482  time: 32s<p>Epoch 113 - avg_train_loss: 0.0101  avg_val_loss: 0.0596  val_lwlrap: 0.559167  time: 32s<p>Epoch 114 - avg_train_loss: 0.0070  avg_val_loss: 0.0557  val_lwlrap: 0.604060  time: 32s<p>Epoch 115 - avg_train_loss: 0.0048  avg_val_loss: 0.0587  val_lwlrap: 0.614031  time: 32s<p>Epoch 116 - avg_train_loss: 0.0044  avg_val_loss: 0.0566  val_lwlrap: 0.607845  time: 33s<p>Epoch 117 - avg_train_loss: 0.0044  avg_val_loss: 0.0557  val_lwlrap: 0.613138  time: 32s<p>Epoch 118 - avg_train_loss: 0.0054  avg_val_loss: 0.0590  val_lwlrap: 0.612261  time: 32s"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yVDzyb-xk1m",
        "colab_type": "code",
        "outputId": "0bad78c3-3220-49bc-9e88-87f9db7f1da5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 76, 'best_lwlrap': 0.625119400428441}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g215CpOVytIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
        "    batch_size = 256\n",
        "\n",
        "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_ft\n",
        "    model.load_state_dict(torch.load('weight_best.pt'))\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs, all_fnames = [], []\n",
        "\n",
        "    pb = progress_bar(test_loader)\n",
        "    for images, fnames in pb:\n",
        "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
        "        all_outputs.append(preds.cpu().numpy())\n",
        "        all_fnames.extend(fnames)\n",
        "\n",
        "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
        "                              index=all_fnames,\n",
        "                              columns=map(str, range(num_classes)))\n",
        "    test_preds = test_preds.groupby(level=0).mean()\n",
        "\n",
        "    return test_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwIX8CeyyBY",
        "colab_type": "code",
        "outputId": "7b1beeb8-8e38-4902-eacb-ce625accdd59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=35)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='154' class='' max='154', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [154/154 00:23<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK7pYQk_yt3r",
        "colab_type": "code",
        "outputId": "1ffcfb53-4ebb-4787-a775-eb5e4a22964a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>...</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>3.663605e-06</td>\n",
              "      <td>3.362080e-06</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>5.303701e-05</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.306779e-04</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.854274e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>3.292444e-06</td>\n",
              "      <td>3.441844e-07</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>3.642294e-06</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>2.263819e-04</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>2.232938e-07</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>4.062636e-02</td>\n",
              "      <td>9.152559e-05</td>\n",
              "      <td>0.009294</td>\n",
              "      <td>8.552086e-03</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>3.081399e-03</td>\n",
              "      <td>0.031131</td>\n",
              "      <td>0.002964</td>\n",
              "      <td>4.488021e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>6.205210e-03</td>\n",
              "      <td>2.821672e-04</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>4.399851e-03</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>1.274279e-03</td>\n",
              "      <td>0.001252</td>\n",
              "      <td>3.259080e-04</td>\n",
              "      <td>0.027815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>1.648198e-04</td>\n",
              "      <td>2.224750e-04</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>3.661104e-05</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>2.884484e-03</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>4.445591e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>8.541589e-04</td>\n",
              "      <td>1.796966e-06</td>\n",
              "      <td>0.005389</td>\n",
              "      <td>9.563732e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>1.056531e-04</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>7.122480e-06</td>\n",
              "      <td>0.001246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>5.489107e-06</td>\n",
              "      <td>1.914157e-08</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.240171e-08</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>2.966196e-10</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>5.735528e-08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>1.272076e-08</td>\n",
              "      <td>1.748081e-04</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.005820e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>1.396483e-05</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>4.394507e-08</td>\n",
              "      <td>0.001380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>5.131858e-07</td>\n",
              "      <td>8.631861e-04</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>1.147998e-04</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>4.940420e-05</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>7.116747e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>3.045145e-06</td>\n",
              "      <td>7.325635e-06</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>4.086781e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>8.979614e-07</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>4.462733e-05</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom     Accordion  \\\n",
              "0  000ccb97.wav                        3.663605e-06  3.362080e-06   \n",
              "1  0012633b.wav                        4.062636e-02  9.152559e-05   \n",
              "2  001ed5f1.wav                        1.648198e-04  2.224750e-04   \n",
              "3  00294be0.wav                        5.489107e-06  1.914157e-08   \n",
              "4  003fde7a.wav                        5.131858e-07  8.631861e-04   \n",
              "\n",
              "   Acoustic_guitar      Applause      Bark     Bass_drum  Bass_guitar  \\\n",
              "0         0.000001  5.303701e-05  0.000015  3.306779e-04     0.000186   \n",
              "1         0.009294  8.552086e-03  0.000964  3.081399e-03     0.031131   \n",
              "2         0.000081  3.661104e-05  0.000070  2.884484e-03     0.000376   \n",
              "3         0.000002  2.240171e-08  0.000057  2.966196e-10     0.000010   \n",
              "4         0.000004  1.147998e-04  0.000030  4.940420e-05     0.000163   \n",
              "\n",
              "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
              "0                      0.000001  3.854274e-04  ...      0.000004   \n",
              "1                      0.002964  4.488021e-04  ...      0.002345   \n",
              "2                      0.000670  4.445591e-05  ...      0.000016   \n",
              "3                      0.000002  5.735528e-08  ...      0.000079   \n",
              "4                      0.000004  7.116747e-01  ...      0.000040   \n",
              "\n",
              "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
              "0                     3.292444e-06         3.441844e-07            0.000024   \n",
              "1                     6.205210e-03         2.821672e-04            0.001004   \n",
              "2                     8.541589e-04         1.796966e-06            0.005389   \n",
              "3                     1.272076e-08         1.748081e-04            0.000002   \n",
              "4                     3.045145e-06         7.325635e-06            0.000105   \n",
              "\n",
              "   Water_tap_and_faucet  Waves_and_surf    Whispering   Writing          Yell  \\\n",
              "0          3.642294e-06        0.000004  2.263819e-04  0.000080  2.232938e-07   \n",
              "1          4.399851e-03        0.000681  1.274279e-03  0.001252  3.259080e-04   \n",
              "2          9.563732e-06        0.000002  1.056531e-04  0.000038  7.122480e-06   \n",
              "3          2.005820e-06        0.000002  1.396483e-05  0.000005  4.394507e-08   \n",
              "4          4.086781e-07        0.000003  8.979614e-07  0.000001  4.462733e-05   \n",
              "\n",
              "   Zipper_(clothing)  \n",
              "0           0.000055  \n",
              "1           0.027815  \n",
              "2           0.001246  \n",
              "3           0.001380  \n",
              "4           0.000007  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}