{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FAT2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eHnoL6b4P2uw",
        "ywFnbu3eP5nW",
        "V1K6xYZSAIDF",
        "pZQBID-xxKkf",
        "g33BekqOh2qj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Haq2PI9sBZ4",
        "colab_type": "text"
      },
      "source": [
        "implementation:\n",
        "\n",
        "*   https://www.kaggle.com/daisukelab/cnn-2d-basic-solution-powered-by-fast-ai\n",
        "*   https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHnoL6b4P2uw",
        "colab_type": "text"
      },
      "source": [
        "### Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4fj8QJuPXUJ",
        "colab_type": "code",
        "outputId": "76bae85b-6ef8-4b09-c40d-395c41c138de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662823&Signature=kOZmSg0y%2FGPyJd2Ryhl64URRPYWrV%2BFgVe2hndFrqibSwirSdY97IaIkfIrQ%2Bw4LCEaV982d6bJCr%2FG2cG1en8SHcnx4MhN4NNfSosY1Htoi8TL0eNpYjD1gNsdMc7KAsSqrvSawP1B%2BdKyWF6rZ6Fue8rFsMswNomPS9ty4IL48tsKCg%2FufLDn8iTGGi0dtuBrU8SkD6qQdwjYtu7vSMPejWuCI%2FBUNSXXrAKGnFPxnPCr5G5yGBgLaQYUa%2BhuiEo2qqGQFXuO8AZ45I%2F65Fj8WfVumFvfST7jWB8QIdJLMqVVrcwcZuFiOgYyMDC%2Bx%2B%2BsepB%2BmAKriBt17oelYjg%3D%3D\" -O \"sample_submission.csv\" -c"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 07:49:09--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662823&Signature=kOZmSg0y%2FGPyJd2Ryhl64URRPYWrV%2BFgVe2hndFrqibSwirSdY97IaIkfIrQ%2Bw4LCEaV982d6bJCr%2FG2cG1en8SHcnx4MhN4NNfSosY1Htoi8TL0eNpYjD1gNsdMc7KAsSqrvSawP1B%2BdKyWF6rZ6Fue8rFsMswNomPS9ty4IL48tsKCg%2FufLDn8iTGGi0dtuBrU8SkD6qQdwjYtu7vSMPejWuCI%2FBUNSXXrAKGnFPxnPCr5G5yGBgLaQYUa%2BhuiEo2qqGQFXuO8AZ45I%2F65Fj8WfVumFvfST7jWB8QIdJLMqVVrcwcZuFiOgYyMDC%2Bx%2B%2BsepB%2BmAKriBt17oelYjg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 194835 (190K) [text/csv]\n",
            "Saving to: ‘sample_submission.csv’\n",
            "\n",
            "\rsample_submission.c   0%[                    ]       0  --.-KB/s               \rsample_submission.c 100%[===================>] 190.27K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2019-06-02 07:49:09 (96.2 MB/s) - ‘sample_submission.csv’ saved [194835/194835]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0mlUkNgPm3a",
        "colab_type": "code",
        "outputId": "e107dadc-48b1-476d-9365-9fa06a66cafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662836&Signature=XBtC83uKrIB4fLm7lXggoQ8lYzLNzuMZyyTNt1fEd5BLHK7Uo0iE%2BOKhBKKk7RZgm%2FEj31lvnaXpWE0Q%2F5rLvgPlanLidgcNFwZMVh04Rao%2Bi0BkSSNgpeeCDEET4fSw6I0LBbjksWErD5C2ylVfzxn4Ln1dzNLDm%2FqYlrbyyXJ9ehZnUxDDmTVLGaNR7Q%2BwIGuBtazsKlrtYfmHL7o4t9g2WQF%2FLf4reouPDFPj8xXPRatoVWMmf%2FpyB5dqLZGXCX%2BFXbqDiYR7XZEJy0UcIuh3GNS0Tcz9w%2F%2FFEhCwtNvXhEyhdLCcV6%2FTL7S08CRjftI4JcOQkL9o6Id1AhKvrQ%3D%3D\" -O \"train_curated.csv\" -c"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 07:49:13--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662836&Signature=XBtC83uKrIB4fLm7lXggoQ8lYzLNzuMZyyTNt1fEd5BLHK7Uo0iE%2BOKhBKKk7RZgm%2FEj31lvnaXpWE0Q%2F5rLvgPlanLidgcNFwZMVh04Rao%2Bi0BkSSNgpeeCDEET4fSw6I0LBbjksWErD5C2ylVfzxn4Ln1dzNLDm%2FqYlrbyyXJ9ehZnUxDDmTVLGaNR7Q%2BwIGuBtazsKlrtYfmHL7o4t9g2WQF%2FLf4reouPDFPj8xXPRatoVWMmf%2FpyB5dqLZGXCX%2BFXbqDiYR7XZEJy0UcIuh3GNS0Tcz9w%2F%2FFEhCwtNvXhEyhdLCcV6%2FTL7S08CRjftI4JcOQkL9o6Id1AhKvrQ%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143137 (140K) [text/csv]\n",
            "Saving to: ‘train_curated.csv’\n",
            "\n",
            "\rtrain_curated.csv     0%[                    ]       0  --.-KB/s               \rtrain_curated.csv   100%[===================>] 139.78K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-06-02 07:49:13 (98.4 MB/s) - ‘train_curated.csv’ saved [143137/143137]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTXMdoKhPqb9",
        "colab_type": "code",
        "outputId": "c952b381-859a-4066-debe-ed50c911580b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662848&Signature=OXjD9mhMniNiC8rnmHBci%2FXcHjKn81t%2Bbwv9m%2BiYuRotLG%2BifJ4%2FnjEN2z3JjDz71B1Db3MnSDWD7rbhU9Hk6MZes8VhLh2Xt1NVjVUX1qRlROVdX5jdS08kVKIOJKh9k7AiNo3MHD2g5M%2Bhq1fJCBVi0GLe6rGTQOU30u8ZRW9v%2FHloUnjVQgrHnSEmRL%2B9spQVkbIS7Iz4qWwc6NBD671ctQ3XaZRJ%2BfheB%2FamYm58FJU2r2sspdTWwaOr0z5zaUSRWwdB%2F%2BI8Z8IwaXFy10R78tIBzmcbfKgMhDx2foOY1QvI0DS2mmveksw6YbKJVYU1uYp%2FdA49xKE2v6qRWg%3D%3D\" -O \"train_noisy.csv\" -c"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 07:49:15--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662848&Signature=OXjD9mhMniNiC8rnmHBci%2FXcHjKn81t%2Bbwv9m%2BiYuRotLG%2BifJ4%2FnjEN2z3JjDz71B1Db3MnSDWD7rbhU9Hk6MZes8VhLh2Xt1NVjVUX1qRlROVdX5jdS08kVKIOJKh9k7AiNo3MHD2g5M%2Bhq1fJCBVi0GLe6rGTQOU30u8ZRW9v%2FHloUnjVQgrHnSEmRL%2B9spQVkbIS7Iz4qWwc6NBD671ctQ3XaZRJ%2BfheB%2FamYm58FJU2r2sspdTWwaOr0z5zaUSRWwdB%2F%2BI8Z8IwaXFy10R78tIBzmcbfKgMhDx2foOY1QvI0DS2mmveksw6YbKJVYU1uYp%2FdA49xKE2v6qRWg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 584806 (571K) [text/csv]\n",
            "Saving to: ‘train_noisy.csv’\n",
            "\n",
            "\rtrain_noisy.csv       0%[                    ]       0  --.-KB/s               \rtrain_noisy.csv     100%[===================>] 571.10K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2019-06-02 07:49:16 (105 MB/s) - ‘train_noisy.csv’ saved [584806/584806]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75LDMVcPs52",
        "colab_type": "code",
        "outputId": "f4df7359-113a-4ebc-af70-c93002cca93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662870&Signature=Wmb3v2s7vMIFt85zxZv%2BtbpL8nt609varyKLWNHUq6eR5l9MoyiYWvF1ZfNh8bVv4sFIZH9whlRsnf85e4CPZVOIHeLmbgNvLsxc%2B84TrsbgZggAAKPkk%2F%2Bx8XWhLKl%2FskAGJK7tRlWkwHVLHqxJ2C9z7XSR5sX8uoqmy1KSNTCyIONSipzON04JJTAaAhqtlonS6JGfnpZXaFpdihMIlPHPaM8FqwKlqzoIe9WW83wUqDB5Fhl5iaMZ95J6QY8JQJpDv65zNN6GOsT%2B03HoXFtjlFG1V0MyuF%2Be9UL49jq0F2XCrs9kWgrysFkRZmmTAN1PA7wJQXYasH%2FCTkYnkQ%3D%3D\" -O \"test.zip\" -c"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 07:49:18--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662870&Signature=Wmb3v2s7vMIFt85zxZv%2BtbpL8nt609varyKLWNHUq6eR5l9MoyiYWvF1ZfNh8bVv4sFIZH9whlRsnf85e4CPZVOIHeLmbgNvLsxc%2B84TrsbgZggAAKPkk%2F%2Bx8XWhLKl%2FskAGJK7tRlWkwHVLHqxJ2C9z7XSR5sX8uoqmy1KSNTCyIONSipzON04JJTAaAhqtlonS6JGfnpZXaFpdihMIlPHPaM8FqwKlqzoIe9WW83wUqDB5Fhl5iaMZ95J6QY8JQJpDv65zNN6GOsT%2B03HoXFtjlFG1V0MyuF%2Be9UL49jq0F2XCrs9kWgrysFkRZmmTAN1PA7wJQXYasH%2FCTkYnkQ%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 698756070 (666M) [application/zip]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>] 666.38M   180MB/s    in 3.7s    \n",
            "\n",
            "2019-06-02 07:49:22 (180 MB/s) - ‘test.zip’ saved [698756070/698756070]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doLUxbxlPyes",
        "colab_type": "code",
        "outputId": "b97c86d5-caf5-4b27-ec77-f49fe662f27d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662883&Signature=Nq%2BOh5bb5PuHzOkFLfV9qZJMOPdE1h4spb0qRx%2BlJdcvNxxZ3u4K1nmRUgBTR%2Bc9wid%2BgvJa9yBIn7vtnUGbVjG10fR3kLem84MJ8s0zDg5V1Em5Qx4BOaHlrr9JqL3maaBOBgJ07CA0%2BrDZc6pFjmqLK0jZTLbcUp3wGKZIeNMtnh3d0XVehpQsF5C5PkpMjtVsiFzjZJ3IT9%2Bf3dFyiUuCg%2FHTPZqq8gYIbas%2BBIhemI7i4rQmhFzAyRY3zvLH0K4s1zuEUPX4%2BAKv5cE0yKPqdkgFKfPdjdIvQJVz7O6qmfnpFRqLhGTIVE9ysftFxFGMJC4DYyTTkwM7f3KUig%3D%3D\" -O \"train_curated.zip\" -c"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 07:49:24--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662883&Signature=Nq%2BOh5bb5PuHzOkFLfV9qZJMOPdE1h4spb0qRx%2BlJdcvNxxZ3u4K1nmRUgBTR%2Bc9wid%2BgvJa9yBIn7vtnUGbVjG10fR3kLem84MJ8s0zDg5V1Em5Qx4BOaHlrr9JqL3maaBOBgJ07CA0%2BrDZc6pFjmqLK0jZTLbcUp3wGKZIeNMtnh3d0XVehpQsF5C5PkpMjtVsiFzjZJ3IT9%2Bf3dFyiUuCg%2FHTPZqq8gYIbas%2BBIhemI7i4rQmhFzAyRY3zvLH0K4s1zuEUPX4%2BAKv5cE0yKPqdkgFKfPdjdIvQJVz7O6qmfnpFRqLhGTIVE9ysftFxFGMJC4DYyTTkwM7f3KUig%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2406491583 (2.2G) [application/zip]\n",
            "Saving to: ‘train_curated.zip’\n",
            "\n",
            "train_curated.zip   100%[===================>]   2.24G   112MB/s    in 17s     \n",
            "\n",
            "2019-06-02 07:49:42 (132 MB/s) - ‘train_curated.zip’ saved [2406491583/2406491583]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNnA16iPy_T",
        "colab_type": "code",
        "outputId": "dd736454-edb2-494c-8bfb-879f5c20033d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662895&Signature=Wafzt9NBCht63%2BLP%2BjcJB3AfAIc3xRwGAadm26mDoKz8sjRkRfU8gRxlmbp7EXbuVzBZsCvL9aN8WAyC7YGbo%2By3ITb2p%2FSz639yINQBVaOWM1wq126AJxji3TDclImZRToYWpNy3A5IGm1Dq4H9xhtqYVCOgR5faZU7EE4lV%2BWtMtqnhsySH0EvXi1cnvClSUgSSpFPyQF2YamWS9y6Pqqpvxw8PzoW2tf6zB3%2FtVgt0YMn02SwT2sayGCEABbjdpuF8yQg1OnHttIEsBfgqmexYZw3GUMZbipi%2BWzKgO66W1YLUpcBhtcHJ3HQ%2B64EwRJNPOFr4u8LfGaE7V%2FUvQ%3D%3D\" -O \"train_noisy.zip\" -c"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 07:49:44--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559662895&Signature=Wafzt9NBCht63%2BLP%2BjcJB3AfAIc3xRwGAadm26mDoKz8sjRkRfU8gRxlmbp7EXbuVzBZsCvL9aN8WAyC7YGbo%2By3ITb2p%2FSz639yINQBVaOWM1wq126AJxji3TDclImZRToYWpNy3A5IGm1Dq4H9xhtqYVCOgR5faZU7EE4lV%2BWtMtqnhsySH0EvXi1cnvClSUgSSpFPyQF2YamWS9y6Pqqpvxw8PzoW2tf6zB3%2FtVgt0YMn02SwT2sayGCEABbjdpuF8yQg1OnHttIEsBfgqmexYZw3GUMZbipi%2BWzKgO66W1YLUpcBhtcHJ3HQ%2B64EwRJNPOFr4u8LfGaE7V%2FUvQ%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21504922116 (20G) [application/zip]\n",
            "Saving to: ‘train_noisy.zip’\n",
            "\n",
            "train_noisy.zip     100%[===================>]  20.03G   151MB/s    in 2m 33s  \n",
            "\n",
            "2019-06-02 07:52:17 (134 MB/s) - ‘train_noisy.zip’ saved [21504922116/21504922116]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fJaLfzGynqy",
        "colab_type": "text"
      },
      "source": [
        "***Preprocessed data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bZWNGSWypWV",
        "colab_type": "code",
        "outputId": "00e15920-2032-402a-b886-2314888adff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559721200&Signature=AwkWTlfP4rXajDIrhF2lIm5hRw%2B26Q0Ac5s72DKEdqaJH8edrSo8Qd53oc3Q1UcAulkyhGCHROyKsCXaZUTdp1dVlL65mlxKt2yEZxI%2FsHUDnMKD%2FwUm8LPVOQcsyufn4e%2ByKhOTYvssl5Y4nWUcZkX4NYPTifpz9P9rRJCp0i8uuLWQ2jC5Iwsv5oSZAckANQPqmmj9T%2BbHSwV66TyFbKHZIJ6tqAYs5O4XIcG0W9LyI3IdtW1gL%2BMav%2B%2Bn5PxeeMXQoj5tr4mGbO5MHZkzAe1u2l5T00IYnW7r4LyCyX%2F%2BPBR8nWH0rLCDarqXSsd1u80vMbv6FpNR9ZeSUdhvQQ%3D%3D\" -O \"fat2019_prep_mels1.zip\" -c"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-02 08:01:57--  https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559721200&Signature=AwkWTlfP4rXajDIrhF2lIm5hRw%2B26Q0Ac5s72DKEdqaJH8edrSo8Qd53oc3Q1UcAulkyhGCHROyKsCXaZUTdp1dVlL65mlxKt2yEZxI%2FsHUDnMKD%2FwUm8LPVOQcsyufn4e%2ByKhOTYvssl5Y4nWUcZkX4NYPTifpz9P9rRJCp0i8uuLWQ2jC5Iwsv5oSZAckANQPqmmj9T%2BbHSwV66TyFbKHZIJ6tqAYs5O4XIcG0W9LyI3IdtW1gL%2BMav%2B%2Bn5PxeeMXQoj5tr4mGbO5MHZkzAe1u2l5T00IYnW7r4LyCyX%2F%2BPBR8nWH0rLCDarqXSsd1u80vMbv6FpNR9ZeSUdhvQQ%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 2865032102 (2.7G), 2865031507 (2.7G) remaining [application/zip]\n",
            "Saving to: ‘fat2019_prep_mels1.zip’\n",
            "\n",
            "fat2019_prep_mels1. 100%[===================>]   2.67G  95.6MB/s    in 20s     \n",
            "\n",
            "2019-06-02 08:02:17 (135 MB/s) - ‘fat2019_prep_mels1.zip’ saved [2865032102/2865032102]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywFnbu3eP5nW",
        "colab_type": "text"
      },
      "source": [
        "### Exploring dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0tOhnVcACC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test\n",
        "!mkdir train_curated\n",
        "!mkdir train_noisy\n",
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pokwjdG2zCjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ec24794-48b6-452a-b284-ed7bd92e8876"
      },
      "source": [
        "!unzip -qq fat2019_prep_mels1.zip -d data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file #1:  bad zipfile offset (local header sig):  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1Wq71PP43o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLZZ6nuWQMqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_curated.zip -d train_curated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpYGeV7mQMkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_noisy.zip -d train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK-JmCd_QMWx",
        "colab_type": "text"
      },
      "source": [
        "To apply deep learning technique, we first have to come up with a way to provide effective converse from audio data to any other form which will make it effective for deep learning technique for multilabeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l5HQ4X5SmxC",
        "colab_type": "text"
      },
      "source": [
        "Audio conversion to 2D\n",
        "Almost copyed from my repository: https://github.com/daisukelab/ml-sound-classifier\n",
        "\n",
        "Handle sampling rate 44.1kHz as is, no information loss.\n",
        "Size of each file will be 128 x L, L is audio seconds x 128; [128, 256] if sound is 2s long.\n",
        "Convert to Mel-spectrogram, not MFCC. We are handling general sound rather than human voice. https://en.wikipedia.org/wiki/Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PZG8p-dchS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv -t data test train_curated train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPW_sIidU0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_submission.csv train_curated.csv train_noisy.csv data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFndQ6_MhLb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b4c8b48-5be3-4181-9109-af3778857aef"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv  train_curated\t  train_noisy\n",
            "test\t\t       train_curated.csv  train_noisy.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUGBpD9yzVGd",
        "colab_type": "text"
      },
      "source": [
        "## End-2-End pipeline from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F8UkwPI2NMu",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY_VKteYzZti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUMF8Q0zfhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8AfLCTAzkhp",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kgyi-NT7zkh4",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uU4o6eyNzkh4",
        "outputId": "c7d9ff6a-41e9-49f8-a6ca-895d3e411a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_curated.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0006ae4e.wav</td>\n",
              "      <td>Bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0019ef41.wav</td>\n",
              "      <td>Raindrop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ec0ad.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0026c7cb.wav</td>\n",
              "      <td>Run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0026f116.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname           labels\n",
              "0  0006ae4e.wav             Bark\n",
              "1  0019ef41.wav         Raindrop\n",
              "2  001ec0ad.wav  Finger_snapping\n",
              "3  0026c7cb.wav              Run\n",
              "4  0026f116.wav  Finger_snapping"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iEexDS09zkh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "5bd5d47f-d298-4b2a-9d76-dd6e7f476308"
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>Burping_and_eructation</th>\n",
              "      <th>Bus</th>\n",
              "      <th>Buzz</th>\n",
              "      <th>Car_passing_by</th>\n",
              "      <th>Cheering</th>\n",
              "      <th>Chewing_and_mastication</th>\n",
              "      <th>Child_speech_and_kid_speaking</th>\n",
              "      <th>Chink_and_clink</th>\n",
              "      <th>Chirp_and_tweet</th>\n",
              "      <th>Church_bell</th>\n",
              "      <th>Clapping</th>\n",
              "      <th>Computer_keyboard</th>\n",
              "      <th>Crackle</th>\n",
              "      <th>Cricket</th>\n",
              "      <th>Crowd</th>\n",
              "      <th>Cupboard_open_or_close</th>\n",
              "      <th>Cutlery_and_silverware</th>\n",
              "      <th>Dishes_and_pots_and_pans</th>\n",
              "      <th>Drawer_open_or_close</th>\n",
              "      <th>Drip</th>\n",
              "      <th>Electric_guitar</th>\n",
              "      <th>Fart</th>\n",
              "      <th>Female_singing</th>\n",
              "      <th>Female_speech_and_woman_speaking</th>\n",
              "      <th>Fill_(with_liquid)</th>\n",
              "      <th>Finger_snapping</th>\n",
              "      <th>Frying_(food)</th>\n",
              "      <th>Gasp</th>\n",
              "      <th>Glockenspiel</th>\n",
              "      <th>Gong</th>\n",
              "      <th>...</th>\n",
              "      <th>Harmonica</th>\n",
              "      <th>Hi-hat</th>\n",
              "      <th>Hiss</th>\n",
              "      <th>Keys_jangling</th>\n",
              "      <th>Knock</th>\n",
              "      <th>Male_singing</th>\n",
              "      <th>Male_speech_and_man_speaking</th>\n",
              "      <th>Marimba_and_xylophone</th>\n",
              "      <th>Mechanical_fan</th>\n",
              "      <th>Meow</th>\n",
              "      <th>Microwave_oven</th>\n",
              "      <th>Motorcycle</th>\n",
              "      <th>Printer</th>\n",
              "      <th>Purr</th>\n",
              "      <th>Race_car_and_auto_racing</th>\n",
              "      <th>Raindrop</th>\n",
              "      <th>Run</th>\n",
              "      <th>Scissors</th>\n",
              "      <th>Screaming</th>\n",
              "      <th>Shatter</th>\n",
              "      <th>Sigh</th>\n",
              "      <th>Sink_(filling_or_washing)</th>\n",
              "      <th>Skateboard</th>\n",
              "      <th>Slam</th>\n",
              "      <th>Sneeze</th>\n",
              "      <th>Squeak</th>\n",
              "      <th>Stream</th>\n",
              "      <th>Strum</th>\n",
              "      <th>Tap</th>\n",
              "      <th>Tick-tock</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom  ...  Yell  Zipper_(clothing)\n",
              "0  000ccb97.wav                                   0  ...     0                  0\n",
              "1  0012633b.wav                                   0  ...     0                  0\n",
              "2  001ed5f1.wav                                   0  ...     0                  0\n",
              "3  00294be0.wav                                   0  ...     0                  0\n",
              "4  003fde7a.wav                                   0  ...     0                  0\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RbaUiDU2zkh4",
        "outputId": "d1fbc491-c64a-4c41-d872-5a3aa2d5b408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accelerating_and_revving_and_vroom',\n",
              " 'Accordion',\n",
              " 'Acoustic_guitar',\n",
              " 'Applause',\n",
              " 'Bark',\n",
              " 'Bass_drum',\n",
              " 'Bass_guitar',\n",
              " 'Bathtub_(filling_or_washing)',\n",
              " 'Bicycle_bell',\n",
              " 'Burping_and_eructation',\n",
              " 'Bus',\n",
              " 'Buzz',\n",
              " 'Car_passing_by',\n",
              " 'Cheering',\n",
              " 'Chewing_and_mastication',\n",
              " 'Child_speech_and_kid_speaking',\n",
              " 'Chink_and_clink',\n",
              " 'Chirp_and_tweet',\n",
              " 'Church_bell',\n",
              " 'Clapping',\n",
              " 'Computer_keyboard',\n",
              " 'Crackle',\n",
              " 'Cricket',\n",
              " 'Crowd',\n",
              " 'Cupboard_open_or_close',\n",
              " 'Cutlery_and_silverware',\n",
              " 'Dishes_and_pots_and_pans',\n",
              " 'Drawer_open_or_close',\n",
              " 'Drip',\n",
              " 'Electric_guitar',\n",
              " 'Fart',\n",
              " 'Female_singing',\n",
              " 'Female_speech_and_woman_speaking',\n",
              " 'Fill_(with_liquid)',\n",
              " 'Finger_snapping',\n",
              " 'Frying_(food)',\n",
              " 'Gasp',\n",
              " 'Glockenspiel',\n",
              " 'Gong',\n",
              " 'Gurgling',\n",
              " 'Harmonica',\n",
              " 'Hi-hat',\n",
              " 'Hiss',\n",
              " 'Keys_jangling',\n",
              " 'Knock',\n",
              " 'Male_singing',\n",
              " 'Male_speech_and_man_speaking',\n",
              " 'Marimba_and_xylophone',\n",
              " 'Mechanical_fan',\n",
              " 'Meow',\n",
              " 'Microwave_oven',\n",
              " 'Motorcycle',\n",
              " 'Printer',\n",
              " 'Purr',\n",
              " 'Race_car_and_auto_racing',\n",
              " 'Raindrop',\n",
              " 'Run',\n",
              " 'Scissors',\n",
              " 'Screaming',\n",
              " 'Shatter',\n",
              " 'Sigh',\n",
              " 'Sink_(filling_or_washing)',\n",
              " 'Skateboard',\n",
              " 'Slam',\n",
              " 'Sneeze',\n",
              " 'Squeak',\n",
              " 'Stream',\n",
              " 'Strum',\n",
              " 'Tap',\n",
              " 'Tick-tock',\n",
              " 'Toilet_flush',\n",
              " 'Traffic_noise_and_roadway_noise',\n",
              " 'Trickle_and_dribble',\n",
              " 'Walk_and_footsteps',\n",
              " 'Water_tap_and_faucet',\n",
              " 'Waves_and_surf',\n",
              " 'Whispering',\n",
              " 'Writing',\n",
              " 'Yell',\n",
              " 'Zipper_(clothing)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJv8ICMYzkiI",
        "outputId": "a90b81a0-380e-4e55-ac9e-f8fff07878cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HV3gsJ0MzkiI",
        "outputId": "01c76301-9793-4b52-bb0d-829959dc08b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hJVaPd8KzkiI",
        "outputId": "0dad790d-8ba5-404a-d342-dcbf7226dd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 1120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNgH-6P2UAE",
        "colab_type": "text"
      },
      "source": [
        "### Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyx7eZWdz7NM",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4HbD497z7NM",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7RiI_VR6z7Nb",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        #transforms.RandomResizedCrop(229),\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), \n",
        "            transforms.ColorJitter(0.05, 0.05, 0.05)]),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        #transforms.RandomResizedCrop(229),\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), \n",
        "            transforms.ColorJitter(0.05, 0.05, 0.05)]),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ZeZTa7cz7Nb",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwm-3VUpEDTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "train_dataset = FATTrainDataset(x_train, y_train, train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQY-v8uzF49L",
        "colab_type": "code",
        "outputId": "67e9611c-2f40-4586-864a-132368b78416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_loader.dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8970"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGBRKOZzEZZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = 0\n",
        "std = 0\n",
        "for images, _ in train_loader:\n",
        "  batch_samples = images.size(0)\n",
        "  images = images.view(batch_samples, images.size(1), -1)\n",
        "  mean += images.mean(2).sum(0)\n",
        "  std += images.std(2).sum(0)\n",
        "  \n",
        "mean /= len(train_loader.dataset)\n",
        "std /= len(train_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUTMksduE-vV",
        "colab_type": "code",
        "outputId": "dbcca053-d9ff-4e92-c566-30b0baeff6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(mean, std)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3113, 0.3113, 0.3113]) tensor([0.2032, 0.2032, 0.2032])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mIryFYAKuhNs",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        #transforms.RandomResizedCrop(229),\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), \n",
        "            transforms.ColorJitter(0.05, 0.05, 0.05)]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        #transforms.RandomResizedCrop(229),\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), \n",
        "            transforms.ColorJitter(0.05, 0.05, 0.05)]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VmrGP0JZuhNx",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgoW9uJIz7Nb",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arVLcIFLvjwy",
        "colab_type": "text"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qm_eFE0jAF6m",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vOxWjZbgAF6q",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ibKjyrglAF6w",
        "colab": {}
      },
      "source": [
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uioQvDk23sBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# the GPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "model = model_ft().to(device)\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imGZZGI1Ly1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        \n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "    \n",
        "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TSOmfoXLuKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device) \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3wPv2TrvdIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 80)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRlaWAr22VhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(65536, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024,80)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc_layers(out)\n",
        "        return out\n",
        "     \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lalRsaHv2jff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFCJ0OqL2bKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "model = CNN().to(device)\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "komjhr_GyA0v",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2vQrw9fhyA0z",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUnEKUXUyA02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        },
        "outputId": "d208ff72-f6b8-4607-ba22-bf8efc403a81"
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.2)\n",
              "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (2): PReLU(num_parameters=1)\n",
              "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Dropout(p=0.1)\n",
              "    (5): Linear(in_features=128, out_features=80, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfj55S5jvm9r",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRAkJ5NQ5BhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "lr = 0.01\n",
        "net = Classifier(num_classes=num_classes).cuda()\n",
        "#net = model_ft.cuda()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(params=net.parameters(), lr=lr)\n",
        "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8j8kMfi7soq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "a77d9bea-6743-4f73-ef96-2990d6307aac"
      },
      "source": [
        "import time\n",
        "\n",
        "batch_size = 48\n",
        "\n",
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "  \n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0\n",
        "    start_time = time.time()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        #scheduler.step()\n",
        "        #print(scheduler.get_lr())\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        #optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.cuda())\n",
        "        loss = criterion(outputs, labels.cuda())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    avg_val_loss = 0\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "      with torch.no_grad():\n",
        "            preds = net(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "            avg_val_loss += loss.item() \n",
        "    \n",
        "    #print('Reset scheduler')\n",
        "    #scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader))\n",
        "    score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "    lwlrap = (score * weight).sum()\n",
        "    elapsed = time.time() - start_time\n",
        "    #l_r = scheduler.get_lr()\n",
        "    print(f'Epoch {epoch+1} - avg_train_loss: {running_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f} time: {elapsed:.0f}s')\n",
        "    \"\"\"\n",
        "    if (lwlrap > best_lwlrap):\n",
        "      best_epoch = epoch + 1\n",
        "      best_lwlrap = lwlrap\n",
        "      torch.save(net.state_dict(), 'weight_best.pt')\n",
        "      \"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 15.7549  avg_val_loss: 2.0461  val_lwlrap: 0.118478 time: 43s\n",
            "Epoch 2 - avg_train_loss: 7.7029  avg_val_loss: 1.9627  val_lwlrap: 0.168638 time: 43s\n",
            "Epoch 3 - avg_train_loss: 7.3630  avg_val_loss: 1.9075  val_lwlrap: 0.203203 time: 43s\n",
            "Epoch 4 - avg_train_loss: 7.1569  avg_val_loss: 1.8644  val_lwlrap: 0.222627 time: 43s\n",
            "Epoch 5 - avg_train_loss: 6.9815  avg_val_loss: 1.8205  val_lwlrap: 0.248205 time: 43s\n",
            "Epoch 6 - avg_train_loss: 6.8618  avg_val_loss: 1.7984  val_lwlrap: 0.264731 time: 43s\n",
            "Epoch 7 - avg_train_loss: 6.7388  avg_val_loss: 1.7538  val_lwlrap: 0.290109 time: 43s\n",
            "Epoch 8 - avg_train_loss: 6.6599  avg_val_loss: 1.7391  val_lwlrap: 0.306470 time: 43s\n",
            "Epoch 9 - avg_train_loss: 6.5248  avg_val_loss: 1.7166  val_lwlrap: 0.317058 time: 43s\n",
            "Epoch 10 - avg_train_loss: 6.4027  avg_val_loss: 1.7156  val_lwlrap: 0.312959 time: 43s\n",
            "Epoch 11 - avg_train_loss: 6.3626  avg_val_loss: 1.6871  val_lwlrap: 0.339732 time: 43s\n",
            "Epoch 12 - avg_train_loss: 6.2305  avg_val_loss: 1.6544  val_lwlrap: 0.356400 time: 43s\n",
            "Epoch 13 - avg_train_loss: 6.1306  avg_val_loss: 1.6319  val_lwlrap: 0.365849 time: 43s\n",
            "Epoch 14 - avg_train_loss: 6.0475  avg_val_loss: 1.6059  val_lwlrap: 0.377451 time: 43s\n",
            "Epoch 15 - avg_train_loss: 5.9939  avg_val_loss: 1.5842  val_lwlrap: 0.394249 time: 43s\n",
            "Epoch 16 - avg_train_loss: 5.9077  avg_val_loss: 1.5849  val_lwlrap: 0.396190 time: 43s\n",
            "Epoch 17 - avg_train_loss: 5.7893  avg_val_loss: 1.5314  val_lwlrap: 0.405648 time: 43s\n",
            "Epoch 18 - avg_train_loss: 5.7285  avg_val_loss: 1.5219  val_lwlrap: 0.430748 time: 43s\n",
            "Epoch 19 - avg_train_loss: 5.6293  avg_val_loss: 1.5283  val_lwlrap: 0.434676 time: 43s\n",
            "Epoch 20 - avg_train_loss: 5.5814  avg_val_loss: 1.4931  val_lwlrap: 0.444375 time: 43s\n",
            "Epoch 21 - avg_train_loss: 5.4828  avg_val_loss: 1.4949  val_lwlrap: 0.445351 time: 43s\n",
            "Epoch 22 - avg_train_loss: 5.3749  avg_val_loss: 1.4930  val_lwlrap: 0.445727 time: 43s\n",
            "Epoch 23 - avg_train_loss: 5.3531  avg_val_loss: 1.4563  val_lwlrap: 0.462377 time: 43s\n",
            "Epoch 24 - avg_train_loss: 5.2953  avg_val_loss: 1.4684  val_lwlrap: 0.461399 time: 43s\n",
            "Epoch 25 - avg_train_loss: 5.1950  avg_val_loss: 1.4421  val_lwlrap: 0.481720 time: 43s\n",
            "Epoch 26 - avg_train_loss: 5.1783  avg_val_loss: 1.4289  val_lwlrap: 0.482206 time: 43s\n",
            "Epoch 27 - avg_train_loss: 5.0487  avg_val_loss: 1.4017  val_lwlrap: 0.494572 time: 42s\n",
            "Epoch 28 - avg_train_loss: 5.0634  avg_val_loss: 1.4291  val_lwlrap: 0.482417 time: 43s\n",
            "Epoch 29 - avg_train_loss: 4.9900  avg_val_loss: 1.4012  val_lwlrap: 0.499717 time: 42s\n",
            "Epoch 30 - avg_train_loss: 4.8776  avg_val_loss: 1.3999  val_lwlrap: 0.495895 time: 43s\n",
            "Epoch 31 - avg_train_loss: 4.8736  avg_val_loss: 1.4047  val_lwlrap: 0.497656 time: 42s\n",
            "Epoch 32 - avg_train_loss: 4.7902  avg_val_loss: 1.3811  val_lwlrap: 0.501113 time: 43s\n",
            "Epoch 33 - avg_train_loss: 4.7348  avg_val_loss: 1.4165  val_lwlrap: 0.485473 time: 42s\n",
            "Epoch 34 - avg_train_loss: 4.7405  avg_val_loss: 1.3717  val_lwlrap: 0.520019 time: 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmCKae562tD6",
        "colab_type": "text"
      },
      "source": [
        "### Test Set prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1VN-57t72wb2",
        "colab": {}
      },
      "source": [
        "best_lwlrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GAE3Zcsx2wcG",
        "colab": {}
      },
      "source": [
        "lwlrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U6eupVCh2wcG",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "test_transforms = transforms_dict['test']\n",
        "\n",
        "test_dataset = FATTestDataset(test_df['fname'], x_test, test_transforms, tta=20)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "net.load_state_dict(torch.load('weight_best.pt'))\n",
        "all_outputs, all_fnames = [], []\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, fnames = data\n",
        "    preds = torch.sigmoid(net(images.cuda()).detach())\n",
        "    all_outputs.append(preds.cpu().numpy())\n",
        "    all_fnames.extend(fnames)\n",
        "\n",
        "test_preds = pd.DataFrame(data=np.concatenate(all_outputs), index=all_fnames, columns=map(str, range(num_classes)))\n",
        "test_preds = test_preds.groupby(level=0).mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1GvQC9f2wcG",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K_Uf83pN2wcG",
        "colab": {}
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTCWqn31MKk",
        "colab_type": "text"
      },
      "source": [
        "## Testing different dL techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xjPq65NO5r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtcZVhRkO2RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdrF0ctEO2Oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlJlLLlIO2Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqKJPwB4O2Io",
        "colab_type": "code",
        "outputId": "4d7f1760-7d8b-4954-a097-08f2ce4a11ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_curated.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0006ae4e.wav</td>\n",
              "      <td>Bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0019ef41.wav</td>\n",
              "      <td>Raindrop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ec0ad.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0026c7cb.wav</td>\n",
              "      <td>Run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0026f116.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname           labels\n",
              "0  0006ae4e.wav             Bark\n",
              "1  0019ef41.wav         Raindrop\n",
              "2  001ec0ad.wav  Finger_snapping\n",
              "3  0026c7cb.wav              Run\n",
              "4  0026f116.wav  Finger_snapping"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXCIfc5pRPaw",
        "colab_type": "code",
        "outputId": "d79df183-fa85-4165-aed8-e3f5f86d5d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>Burping_and_eructation</th>\n",
              "      <th>Bus</th>\n",
              "      <th>Buzz</th>\n",
              "      <th>Car_passing_by</th>\n",
              "      <th>Cheering</th>\n",
              "      <th>Chewing_and_mastication</th>\n",
              "      <th>Child_speech_and_kid_speaking</th>\n",
              "      <th>Chink_and_clink</th>\n",
              "      <th>Chirp_and_tweet</th>\n",
              "      <th>Church_bell</th>\n",
              "      <th>Clapping</th>\n",
              "      <th>Computer_keyboard</th>\n",
              "      <th>Crackle</th>\n",
              "      <th>Cricket</th>\n",
              "      <th>Crowd</th>\n",
              "      <th>Cupboard_open_or_close</th>\n",
              "      <th>Cutlery_and_silverware</th>\n",
              "      <th>Dishes_and_pots_and_pans</th>\n",
              "      <th>Drawer_open_or_close</th>\n",
              "      <th>Drip</th>\n",
              "      <th>Electric_guitar</th>\n",
              "      <th>Fart</th>\n",
              "      <th>Female_singing</th>\n",
              "      <th>Female_speech_and_woman_speaking</th>\n",
              "      <th>Fill_(with_liquid)</th>\n",
              "      <th>Finger_snapping</th>\n",
              "      <th>Frying_(food)</th>\n",
              "      <th>Gasp</th>\n",
              "      <th>Glockenspiel</th>\n",
              "      <th>Gong</th>\n",
              "      <th>...</th>\n",
              "      <th>Harmonica</th>\n",
              "      <th>Hi-hat</th>\n",
              "      <th>Hiss</th>\n",
              "      <th>Keys_jangling</th>\n",
              "      <th>Knock</th>\n",
              "      <th>Male_singing</th>\n",
              "      <th>Male_speech_and_man_speaking</th>\n",
              "      <th>Marimba_and_xylophone</th>\n",
              "      <th>Mechanical_fan</th>\n",
              "      <th>Meow</th>\n",
              "      <th>Microwave_oven</th>\n",
              "      <th>Motorcycle</th>\n",
              "      <th>Printer</th>\n",
              "      <th>Purr</th>\n",
              "      <th>Race_car_and_auto_racing</th>\n",
              "      <th>Raindrop</th>\n",
              "      <th>Run</th>\n",
              "      <th>Scissors</th>\n",
              "      <th>Screaming</th>\n",
              "      <th>Shatter</th>\n",
              "      <th>Sigh</th>\n",
              "      <th>Sink_(filling_or_washing)</th>\n",
              "      <th>Skateboard</th>\n",
              "      <th>Slam</th>\n",
              "      <th>Sneeze</th>\n",
              "      <th>Squeak</th>\n",
              "      <th>Stream</th>\n",
              "      <th>Strum</th>\n",
              "      <th>Tap</th>\n",
              "      <th>Tick-tock</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom  ...  Yell  Zipper_(clothing)\n",
              "0  000ccb97.wav                                   0  ...     0                  0\n",
              "1  0012633b.wav                                   0  ...     0                  0\n",
              "2  001ed5f1.wav                                   0  ...     0                  0\n",
              "3  00294be0.wav                                   0  ...     0                  0\n",
              "4  003fde7a.wav                                   0  ...     0                  0\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSFd9vK-O2Gm",
        "colab_type": "code",
        "outputId": "5c7446ce-7336-46bc-8486-52ad9b2c85ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accelerating_and_revving_and_vroom',\n",
              " 'Accordion',\n",
              " 'Acoustic_guitar',\n",
              " 'Applause',\n",
              " 'Bark',\n",
              " 'Bass_drum',\n",
              " 'Bass_guitar',\n",
              " 'Bathtub_(filling_or_washing)',\n",
              " 'Bicycle_bell',\n",
              " 'Burping_and_eructation',\n",
              " 'Bus',\n",
              " 'Buzz',\n",
              " 'Car_passing_by',\n",
              " 'Cheering',\n",
              " 'Chewing_and_mastication',\n",
              " 'Child_speech_and_kid_speaking',\n",
              " 'Chink_and_clink',\n",
              " 'Chirp_and_tweet',\n",
              " 'Church_bell',\n",
              " 'Clapping',\n",
              " 'Computer_keyboard',\n",
              " 'Crackle',\n",
              " 'Cricket',\n",
              " 'Crowd',\n",
              " 'Cupboard_open_or_close',\n",
              " 'Cutlery_and_silverware',\n",
              " 'Dishes_and_pots_and_pans',\n",
              " 'Drawer_open_or_close',\n",
              " 'Drip',\n",
              " 'Electric_guitar',\n",
              " 'Fart',\n",
              " 'Female_singing',\n",
              " 'Female_speech_and_woman_speaking',\n",
              " 'Fill_(with_liquid)',\n",
              " 'Finger_snapping',\n",
              " 'Frying_(food)',\n",
              " 'Gasp',\n",
              " 'Glockenspiel',\n",
              " 'Gong',\n",
              " 'Gurgling',\n",
              " 'Harmonica',\n",
              " 'Hi-hat',\n",
              " 'Hiss',\n",
              " 'Keys_jangling',\n",
              " 'Knock',\n",
              " 'Male_singing',\n",
              " 'Male_speech_and_man_speaking',\n",
              " 'Marimba_and_xylophone',\n",
              " 'Mechanical_fan',\n",
              " 'Meow',\n",
              " 'Microwave_oven',\n",
              " 'Motorcycle',\n",
              " 'Printer',\n",
              " 'Purr',\n",
              " 'Race_car_and_auto_racing',\n",
              " 'Raindrop',\n",
              " 'Run',\n",
              " 'Scissors',\n",
              " 'Screaming',\n",
              " 'Shatter',\n",
              " 'Sigh',\n",
              " 'Sink_(filling_or_washing)',\n",
              " 'Skateboard',\n",
              " 'Slam',\n",
              " 'Sneeze',\n",
              " 'Squeak',\n",
              " 'Stream',\n",
              " 'Strum',\n",
              " 'Tap',\n",
              " 'Tick-tock',\n",
              " 'Toilet_flush',\n",
              " 'Traffic_noise_and_roadway_noise',\n",
              " 'Trickle_and_dribble',\n",
              " 'Walk_and_footsteps',\n",
              " 'Water_tap_and_faucet',\n",
              " 'Waves_and_surf',\n",
              " 'Whispering',\n",
              " 'Writing',\n",
              " 'Yell',\n",
              " 'Zipper_(clothing)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EppdZH2QO2Ei",
        "colab_type": "code",
        "outputId": "49659d2c-46c1-4b86-8395-108f8ea28bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppgxLjGcO2De",
        "colab_type": "code",
        "outputId": "9c451f5a-c436-4ff0-c9f0-0f9d51dc5336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X74Ir0wrO2A7",
        "colab_type": "code",
        "outputId": "028deab4-6a15-4d17-a0fc-2a70ff058950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 1120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ7yc7TMO1-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHp-S3wSO18i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH8GkWlXQBsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), \n",
        "            transforms.ColorJitter(0.05, 0.05, 0.05)]),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), \n",
        "            transforms.ColorJitter(0.05, 0.05, 0.05)]),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8rNOgeXO12T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfISihE2Um4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKU_VKLiWgdH",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwHs2dLbWgdO",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnWZZQURWgdS",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_BXrufHWjHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "lr = 0.0002\n",
        "#net = Classifier(num_classes=num_classes).cuda()\n",
        "net = model_ft.cuda()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(params=net.parameters(), lr=lr)\n",
        "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8fAxlAWkhT",
        "colab_type": "code",
        "outputId": "1978b164-6a3b-4f09-9c10-17d4b93f7f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51122
        }
      },
      "source": [
        "import time\n",
        "\n",
        "batch_size = 48\n",
        "\n",
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "  \n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0\n",
        "    start_time = time.time()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        scheduler.step()\n",
        "        print(scheduler.get_lr())\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        #optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.cuda())\n",
        "        loss = criterion(outputs, labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    avg_val_loss = 0\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "      with torch.no_grad():\n",
        "            preds = net(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "            avg_val_loss += loss.item() \n",
        "    \n",
        "    print('Reset scheduler')\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader))\n",
        "    score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "    lwlrap = (score * weight).sum()\n",
        "    elapsed = time.time() - start_time\n",
        "    #l_r = scheduler.get_lr()\n",
        "    print(f'Epoch {epoch+1} - avg_train_loss: {running_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f} time: {elapsed:.0f}s')\n",
        "    \n",
        "    if (lwlrap > best_lwlrap):\n",
        "      best_epoch = epoch + 1\n",
        "      best_lwlrap = lwlrap\n",
        "      torch.save(net.state_dict(), 'weight_best.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 1 - avg_train_loss: 16.4065  avg_val_loss: 2.2686  val_lwlrap: 0.106185 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 2 - avg_train_loss: 11.7661  avg_val_loss: 2.9745  val_lwlrap: 0.105705 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 3 - avg_train_loss: 10.1236  avg_val_loss: 2.5555  val_lwlrap: 0.072799 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 4 - avg_train_loss: 9.3355  avg_val_loss: 2.3924  val_lwlrap: 0.083456 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 5 - avg_train_loss: 9.1515  avg_val_loss: 2.4083  val_lwlrap: 0.076263 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 6 - avg_train_loss: 9.9449  avg_val_loss: 2.4467  val_lwlrap: 0.081547 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 7 - avg_train_loss: 9.6614  avg_val_loss: 2.6378  val_lwlrap: 0.050936 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 8 - avg_train_loss: 9.3665  avg_val_loss: 2.5505  val_lwlrap: 0.057576 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 9 - avg_train_loss: 9.3568  avg_val_loss: 2.4973  val_lwlrap: 0.066828 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 10 - avg_train_loss: 9.0772  avg_val_loss: 2.5089  val_lwlrap: 0.063970 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 11 - avg_train_loss: 8.9977  avg_val_loss: 2.4714  val_lwlrap: 0.072103 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 12 - avg_train_loss: 8.9403  avg_val_loss: 2.4482  val_lwlrap: 0.074353 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n",
            "0.00018187088444278674\n",
            "[0.0001786297917004481]\n",
            "0.00018024305313767646\n",
            "[0.0001768791962336098]\n",
            "0.00017855320317956784\n",
            "[0.0001750692408562112]\n",
            "0.0001768026406281642\n",
            "[0.0001732013244128006]\n",
            "0.00017499271846702213\n",
            "[0.00017127689054434144]\n",
            "0.0001731248355578509\n",
            "[0.00016929742657238899]\n",
            "0.000171200435559353\n",
            "[0.0001672644623495046]\n",
            "0.0001692210058114423\n",
            "[0.00016517956907679458]\n",
            "0.00016718807618570108\n",
            "[0.00016304435808948788]\n",
            "0.00016510321790296525\n",
            "[0.0001608604796114912]\n",
            "0.0001629680423189514\n",
            "[0.00015862962147988302]\n",
            "0.00016078419967886402\n",
            "[0.0001563535078403323]\n",
            "0.00015855337784194577\n",
            "[0.00015403389781445034]\n",
            "0.00015627730097695638\n",
            "[0.00015167258414010426]\n",
            "0.00015395772822958845\n",
            "[0.00014927139178574325]\n",
            "0.0001515964523628501\n",
            "[0.00014683217653980768]\n",
            "0.00014919529837146528\n",
            "[0.00014435682357631134]\n",
            "0.0001467561220713628\n",
            "[0.00014184724599770342]\n",
            "0.00014428080866534396\n",
            "[0.0001393053833561373]\n",
            "0.00014177127128603748\n",
            "[0.00013673320015428715]\n",
            "0.0001392294495172681\n",
            "[0.00013413268432687083]\n",
            "0.0001366573078949813\n",
            "[0.00013150584570405065]\n",
            "0.00013405683438888282\n",
            "[0.00012885471445790025]\n",
            "0.0001314300388659667\n",
            "[0.00012618133953313555]\n",
            "0.0001287789515371194\n",
            "[0.0001234877870633211]\n",
            "0.00012610562138799978\n",
            "[0.00012077613877377716]\n",
            "0.0001234121145954094\n",
            "[0.00011804849037241538]\n",
            "0.00012070051293037495\n",
            "[0.0001153069499297498]\n",
            "0.00011797291214917881\n",
            "[0.0001125536362493299]\n",
            "0.0001152314203735805\n",
            "[0.00010979067722985373]\n",
            "0.00011247815646148086\n",
            "[0.00010702020822022462]\n",
            "0.0001097152483692886\n",
            "[0.00010424437036881893]\n",
            "0.00010694483150725461\n",
            "[0.00010146530896823827]\n",
            "0.00010416904708904547\n",
            "[9.868517179682048e-05]\n",
            "0.00010139004047683153\n",
            "[9.590610745818699e-05]\n",
            "9.860995952316851e-05\n",
            "[9.313026372010521e-05]\n",
            "9.583095291095453e-05\n",
            "[9.035978585394399e-05]\n",
            "9.305516849274543e-05\n",
            "[8.759681497599703e-05]\n",
            "9.028475163071142e-05\n",
            "[8.48434863919519e-05]\n",
            "8.752184353851912e-05\n",
            "[8.210192794577193e-05]\n",
            "8.476857962641949e-05\n",
            "[7.937425837425861e-05]\n",
            "8.202708785082117e-05\n",
            "[7.666258566855457e-05]\n",
            "7.929948706962504e-05\n",
            "[7.396900544383861e-05]\n",
            "7.658788540459062e-05\n",
            "[7.129559931845753e-05]\n",
            "7.389437861200021e-05\n",
            "[6.864443330372962e-05]\n",
            "7.122104846288064e-05\n",
            "[6.601755620564e-05]\n",
            "6.856996113403327e-05\n",
            "[6.341699803964072e-05]\n",
            "6.594316561111719e-05\n",
            "[6.0844768459747335e-05]\n",
            "6.33426921050187e-05\n",
            "[5.8302855203112826e-05]\n",
            "6.0770550482731877e-05\n",
            "[5.5793222551237014e-05]\n",
            "5.822872871396252e-05\n",
            "[5.331780980895014e-05]\n",
            "5.571919133465603e-05\n",
            "[5.087852980228678e-05]\n",
            "5.324387792863717e-05\n",
            "[4.8477267396336386e-05]\n",
            "5.080470162853471e-05\n",
            "[4.611587803412935e-05]\n",
            "4.84035476371499e-05\n",
            "[4.379618629758063e-05]\n",
            "4.6042271770411545e-05\n",
            "[4.151998449147272e-05]\n",
            "4.372269902304362e-05\n",
            "[3.928903125141357e-05]\n",
            "4.144662215805421e-05\n",
            "[3.710505017664893e-05]\n",
            "3.9215800321136006e-05\n",
            "[3.496972848854127e-05]\n",
            "3.703195768104862e-05\n",
            "[3.288471571545183e-05]\n",
            "3.489678209703477e-05\n",
            "[3.085162240465831e-05]\n",
            "3.2811923814298925e-05\n",
            "[2.8872018861826998e-05]\n",
            "3.077899418855771e-05\n",
            "[2.694743391840013e-05]\n",
            "2.8799564440647023e-05\n",
            "[2.5079353727070833e-05]\n",
            "2.687516444214914e-05\n",
            "[2.3269220585264153e-05]\n",
            "2.500728153297787e-05\n",
            "[2.1518431786216587e-05]\n",
            "2.3197359371835795e-05\n",
            "[1.9828338496809555e-05]\n",
            "2.1446796820432127e-05\n",
            "[1.8200244660722747e-05]\n",
            "1.9756946862323525e-05\n",
            "[1.6635405924665164e-05]\n",
            "1.8129115557213252e-05\n",
            "[1.5135028584319924e-05]\n",
            "1.6564561031517304e-05\n",
            "[1.3700268545049228e-05]\n",
            "1.506449250597725e-05\n",
            "[1.233223029012866e-05]\n",
            "1.3630069361071823e-05\n",
            "[1.1031965845946526e-05]\n",
            "1.2262400240949018e-05\n",
            "[9.800473728650103e-06]\n",
            "1.0962542196571631e-05\n",
            "[8.638697849197151e-06]\n",
            "9.731499868738445e-06\n",
            "[7.547526342108819e-06]\n",
            "8.570224711612405e-06\n",
            "[6.527790264710254e-06]\n",
            "7.47961425735597e-06\n",
            "[5.580262083496496e-06]\n",
            "6.460511422441982e-06\n",
            "[4.705653813722372e-06]\n",
            "5.513703856176088e-06\n",
            "[3.904614590809883e-06]\n",
            "4.63992333193447e-06\n",
            "[3.1777272949918415e-06]\n",
            "3.839845181587098e-06\n",
            "[2.525503556194824e-06]\n",
            "3.1140877735439277e-06\n",
            "[1.9483758871743674e-06]\n",
            "2.463212034827189e-06\n",
            "[1.4466844874398217e-06]\n",
            "1.8877210175392898e-06\n",
            "[1.0206535741088473e-06]\n",
            "1.38805951006139e-06\n",
            "[6.703455943529063e-07]\n",
            "9.646136932831227e-07\n",
            "[3.955642420804874e-07]\n",
            "6.177108421292265e-07\n",
            "[1.9562392531138125e-07]\n",
            "3.4761907261356966e-07\n",
            "[6.8709742070716e-08]\n",
            "1.5454713461640067e-07\n",
            "[9.66292971953263e-09]\n",
            "3.864425054459496e-08\n",
            "[0.0]\n",
            "0.0\n",
            "Reset scheduler\n",
            "Epoch 13 - avg_train_loss: 9.3626  avg_val_loss: 2.7029  val_lwlrap: 0.079135 time: 42s\n",
            "[0.00019992271896580136]\n",
            "0.00019996135574945544\n",
            "[0.00019972961716168514]\n",
            "0.0001998454528653836\n",
            "[0.0001994594955173923]\n",
            "0.00019965238092738643\n",
            "[0.00019911256277124528]\n",
            "0.0001993822891578708\n",
            "[0.00019868908702766884]\n",
            "0.0001990353863067169\n",
            "[0.00019818939554994955]\n",
            "0.00019861194048993863\n",
            "[0.0001976138745072712]\n",
            "0.0001981122789824607\n",
            "[0.00019696296867622342]\n",
            "0.00019753678796517282\n",
            "[0.00019623718109701245]\n",
            "0.00019688591222645607\n",
            "[0.00019543707268464093]\n",
            "0.00019616015481841294\n",
            "[0.00019456326179535606]\n",
            "0.00019536007666806556\n",
            "[0.00019361642374870247]\n",
            "0.00019448629614382394\n",
            "[0.00019259729030554734]\n",
            "0.00019353948857755803\n",
            "[0.00019150664910248322]\n",
            "0.00019252038574264405\n",
            "[0.00019034534304304318]\n",
            "0.00019142977528838762\n",
            "[0.00018911426964620144]\n",
            "0.00019026850013126157\n",
            "[0.00018781438035266035]\n",
            "0.00018903745780342839\n",
            "[0.00018644667978946132]\n",
            "0.00018773759975905098\n",
            "[0.00018501222499348784]\n",
            "0.0001863699306389282\n",
            "[0.0001835121245944594]\n",
            "0.00018493550749402278\n",
            "[0.00018194753795805003]\n",
            "0.00018343543896848273\n",
            "[0.00018031967428979017]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abRZrhKwn_sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnAluRJEoBN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_lwlrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZW6wFEUviiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lwlrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "401UaESPWrI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "test_transforms = transforms_dict['test']\n",
        "\n",
        "test_dataset = FATTestDataset(test_df['fname'], x_test, test_transforms, tta=20)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "net.load_state_dict(torch.load('weight_best.pt'))\n",
        "all_outputs, all_fnames = [], []\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, fnames = data\n",
        "    preds = torch.sigmoid(net(images.cuda()).detach())\n",
        "    all_outputs.append(preds.cpu().numpy())\n",
        "    all_fnames.extend(fnames)\n",
        "\n",
        "test_preds = pd.DataFrame(data=np.concatenate(all_outputs), index=all_fnames, columns=map(str, range(num_classes)))\n",
        "test_preds = test_preds.groupby(level=0).mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWPIgORTWtzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADokxqLlWvDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti-PQPO2uNQC",
        "colab_type": "text"
      },
      "source": [
        "### 2. Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODeTKQbJwFuJ",
        "colab_type": "text"
      },
      "source": [
        "***Simple changes, significant improvement in lb***\n",
        "\n",
        "Now with different convolution architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjeG9zO3dKU6",
        "colab_type": "text"
      },
      "source": [
        "***Original***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcCNIj42060g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from psutil import cpu_count\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3lWLSN7xAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 520\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_bwTu3xCHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_JOBS = cpu_count()\n",
        "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
        "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
        "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jhnnjifxCD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UthfHLBOxCA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gdnVV-xB-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK4Xhj0IxB7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySDLo2fTxB4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK8cx8TbxTKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4t9AiIxTG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9s5PMk_xTEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dc941ZJxS_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_s03oyidDhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNM6N9X_dF24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU0ec8A59bpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqGEUePx3ARM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(65536, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024,80)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc_layers(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix4tKLxH3iTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 120\n",
        "    batch_size = 64\n",
        "    test_batch_size = 64\n",
        "    lr = 1e-3\n",
        "    eta_min = 1e-5\n",
        "    t_max = 10\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    model = CNN().cuda()\n",
        "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "#         for x_batch, y_batch in progress_bar(train_loader, parent=mb):\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q5b7UA6a3wqY",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S821wBNK3wqe",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpvM6BA-dSBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e_JqCpfdR9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFbhsmSHdR2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4v0mHvpSrC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclical_lr(stepsize, min_lr=7e-1, max_lr=7e-2):\n",
        "\n",
        "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
        "    scaler = lambda x: 1.\n",
        "\n",
        "    # Lambda function to calculate the LR\n",
        "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
        "\n",
        "    # Additional function to see where on the cycle we are\n",
        "    def relative(it, stepsize):\n",
        "        cycle = math.floor(1 + it / (2 * stepsize))\n",
        "        x = abs(it / stepsize - 2 * cycle + 1)\n",
        "        return max(0, (1 - x)) * scaler(cycle)\n",
        "\n",
        "    return lr_lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRa1FcYydRqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 64\n",
        "    test_batch_size = 64\n",
        "    lr_max = 7*10e-2\n",
        "    factor = 6\n",
        "    end_lr = lr_max\n",
        "    iter=0\n",
        "    total_logs = []\n",
        "    \n",
        "    #lr = 1e-3\n",
        "    #eta_min = 1e-5\n",
        "    #t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    model = Classifier(num_classes=num_classes).cuda()\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adamax(model.parameters(), lr=1.)\n",
        "    step_size = 4*len(train_loader)\n",
        "    clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
        "    #optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    #scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            clip_grad_norm_(model.parameters(), 5)\n",
        "            scheduler.step()\n",
        "            lr_sched_test = scheduler.get_lr()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        #scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey6hdbHzdRim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eatWK78dRRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0YvrYo3GNS",
        "colab_type": "text"
      },
      "source": [
        "***different approachs***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrDOLlznw5V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"list:\n",
        "  apply augmentation\n",
        "  cnn architecture\n",
        "  result of model\n",
        "  .div_(255)\n",
        "  img = img / 2 + 0.5     # unnormalize\n",
        "\n",
        "  \n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdnnHF_wLHoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "random_state = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVMnWnBwzTTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from psutil import cpu_count\n",
        "import random\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vmit45ThyA0E",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJwRjrv8yA0K",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBUtxLEeyA0M",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8tk1KBuHyA0O",
        "colab": {}
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "#train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "#train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_curated.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mY5rf36QyA0S",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LidAwl4SyA0W",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J7euOnyCyA0Y",
        "colab": {}
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6X5jNxOJyA0g",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros((len(train_curated), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_curated['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_CC3ZjDyA0l",
        "colab": {}
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    #x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrQ5UmeVz2cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 520\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp8JKf3fz08g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_JOBS = cpu_count()\n",
        "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
        "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
        "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2CHjkwmv5n2",
        "colab_type": "text"
      },
      "source": [
        "### Dataset and Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rn3WZkIZyA0o",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hR8vzLtiyA0r",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) # * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx #% len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpy6MF9vyoC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h1vK_AytyoKE",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yrk32OEsyoKJ",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=random_state)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83mWImPY1jtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYppofGmE21q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fat_dataset = train_dataset\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(fat_dataset)):\n",
        "  image, labels = fat_dataset[i]\n",
        "  print(i, image.shape, labels.shape)\n",
        "\n",
        "  ax = plt.subplot(1, 4, i+1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  img = image / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  \n",
        "  #plt.imshow(np.array(image).reshape((128,128, -1)).astype('uint8'))\n",
        "  \n",
        "  if i == 3:\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n_ZQ_NS2Foi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % train_df.labels[j] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GrsWQAAdftZ",
        "colab_type": "text"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56QaTttz_hBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS6MZx7s_0ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brightness = transforms.ColorJitter(brightness=0.5)\n",
        "\n",
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "\n",
        "transformed_sample = brightness(image)\n",
        "\n",
        "plt.imshow(transformed_sample )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRqHkhKF_4QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brightness = transforms.ColorJitter(brightness=0.5)\n",
        "\n",
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "\n",
        "transformed_sample = brightness(image)\n",
        "\n",
        "plt.imshow(transformed_sample )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqjGUyKc_65i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contrast = transforms.ColorJitter(contrast=1)\n",
        "\n",
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "\n",
        "transformed_sample = contrast(image)\n",
        "\n",
        "plt.imshow(transformed_sample )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeOUR3eQ_9PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hue = transforms.ColorJitter(hue=0.05)\n",
        "\n",
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "\n",
        "transformed_sample = hue(image)\n",
        "\n",
        "plt.imshow(transformed_sample )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK_eeIsjADGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "composed = transforms.Compose([brightness,\n",
        "                               contrast,\n",
        "                               hue])\n",
        "\n",
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "\n",
        "transformed_sample = composed (image)\n",
        "\n",
        "plt.imshow(transformed_sample )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6htQWARpP96C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIwe0P8cO14m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomRotation(10), transforms.ColorJitter(0.05, 0.05, 0.05)])\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2),\n",
        "        transforms.ColorJitter(contrast=0.2),\n",
        "        transforms.ColorJitter(hue=0.2),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2),#0.5\n",
        "        transforms.ColorJitter(contrast=0.2), # 1\n",
        "        transforms.ColorJitter(hue=0.2), #\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN1r6thl-9-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.642\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVjzwkla_FnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.639\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPhbp89NCHvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation to be applied\n",
        "\n",
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size\n",
        "\n",
        "desired_size=448\n",
        "\n",
        "ratio = float(desired_size)/max(old_size)\n",
        "\n",
        "new_size = (448, 448)\n",
        "\n",
        "im = old_im.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "\n",
        "new_im.paste(im, ((desired_size-new_size[0])//2,\n",
        "                    (desired_size-new_size[1])//2))\n",
        "new_im.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzNNDtlKCLL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Augmentation:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4QeSDI_M-lF",
        "colab_type": "text"
      },
      "source": [
        "***Increase model accuracy***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHWaDE-mqNJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://becominghuman.ai/data-augmentation-using-fastai-aefa88ca03f1\n",
        "#1st augmentation:\n",
        "transforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)] \n",
        "transforms_side_on  = transforms_basic + [RandomFlip()] \n",
        "transforms_top_down = transforms_basic + [RandomDihedral()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLLM6Ut4fXzx",
        "colab_type": "text"
      },
      "source": [
        "***Experiment list:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UJYil2unfaMP",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dMWYtD9afaMU",
        "colab": {}
      },
      "source": [
        "#2nd:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eVEwuiqSfaMX",
        "colab": {}
      },
      "source": [
        "#transform basic:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udxJpclShAJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#4th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJN1Ltv6kaDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrANS8cohML3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#both flip:\n",
        "#6th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64QXmwBVli5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#basic + flip: side_on no vertical flip\n",
        "#7th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OncoWyEsl8-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#basic + flip: side_on with vertical flip\n",
        "#7th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNurAxLmAgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#basic + flip: side_on both flip\n",
        "#7th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S_soiWlj74O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#7th:dihedral??\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ineVWzWGiiBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dihedral\n",
        "def dihedral(x, dih):\n",
        "    \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n",
        "    x = np.rot90(x, dih%4)\n",
        "    return x if dih<4 else np.fliplr(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub_VVm8Jij25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dihedral class:\n",
        "class Dihedral(object):\n",
        "  \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDgnY7xmxbAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXY5NQZTRlex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bka5v-hwRuoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "test_batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un5t03qkROPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_MZM3WPRgiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLTTjRohSAIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VazaK1fvSKFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPSwIuPSPiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[2].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzO1y6IqSppC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_dataset.mels[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw1Rwvz4TFvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.labels[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMWGyq9RTJVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mb_example = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psdqochkTSFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mb_example[0].size(), mb_example[1].size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XWKWwc3TUz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(0,4):\n",
        "    sub_plot = fig.add_subplot(1,4,i+1)\n",
        "    sub_plot.axis('Off')\n",
        "    plt.imshow(mb_example[0][i,0].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x34JCsoBTnyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQSNJunVOL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')        \n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-PjLxEdVl7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq3VvSAZXHD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LfDPw54XKyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGyhFwObZklG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_im = Image.fromarray(x_train[0], mode='RGB') \n",
        "desired_size = max(old_im.size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnB4tjtZsDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_size = (desired_size, desired_size)\n",
        "new_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGtttA-W-LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation to be applied\n",
        "\n",
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size\n",
        "\n",
        "desired_size=448\n",
        "\n",
        "ratio = float(desired_size)/max(old_size)\n",
        "\n",
        "new_size = (448, 448)\n",
        "\n",
        "im = old_im.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "\n",
        "new_im.paste(im, ((desired_size-new_size[0])//2,\n",
        "                    (desired_size-new_size[1])//2))\n",
        "new_im.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooEiujA4YKkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(new_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM2bQKeKX-QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(new_im).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwljpAPfVnPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')     \n",
        "time_dim, base_dim = image.size\n",
        "crop = random.randint(0, time_dim - base_dim)\n",
        "image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TzL0E_V0bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(image).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCsZUdOvWn99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Image\n",
        "\n",
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size\n",
        "\n",
        "new_size = (800, 800)\n",
        "new_im = Image.new(\"RGB\", new_size)   ## luckily, this is already black!\n",
        "new_im.paste(old_im, ((new_size[0]-old_size[0])/2,\n",
        "                      (new_size[1]-old_size[1])/2))\n",
        "\n",
        "new_im.show()\n",
        "# new_im.save('someimage.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzk4AtZRVEBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "time_dim, base_dim = image.size\n",
        "crop = random.randint(0, time_dim - base_dim)\n",
        "image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "image = self.transforms(image).div_(255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUzFIqazxa3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlYwSC7oxaw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPqd69JM36W",
        "colab_type": "text"
      },
      "source": [
        "***Changes: lr finder***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCmy4ugkM1yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_ft\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9lQ9pXH1h5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pretrained models:\n",
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wygwRmh61nwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pretrainedmodels\n",
        "print(pretrainedmodels.model_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-umZzHM1qkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to load a pretrained models\n",
        "model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
        "model_ft = pretrainedmodels.__dict__[model_name](num_classes=1000)\n",
        "#model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXnKbF-J-fPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpA9R-jA-wM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "model_ft.last_linear = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7oC-SOdEqLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "\n",
        "model_ft.last_linear = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=num_ftrs, out_features=1024, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=512, out_features=80, bias=True)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiI2wZ3SGBJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgPz2pJyAKxp",
        "colab_type": "code",
        "outputId": "89ded95a-a2e5-46d0-bb82-cbc1dce22dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-334326f8a9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmask_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeypoint_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/faster_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmisc_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_iou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_pyramid_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeaturePyramidNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: libcudart.so.9.0: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzlvwtgK7Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft.classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy1pGvd8MbSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as defined in the link:\n",
        "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OtydueIxiiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUSz8mScyVsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(511, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(127, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nVtMd4xidL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeyzYJM7xk9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 128\n",
        "    test_batch_size = 256\n",
        "    lr = 1e-3\n",
        "    eta_min = 1e-5\n",
        "    t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    #model = Classifier(num_classes=num_classes).cuda()\n",
        "    model = model_ft\n",
        "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmVih93Dxk5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yVDzyb-xk1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g215CpOVytIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
        "    batch_size = 256\n",
        "\n",
        "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_ft\n",
        "    model.load_state_dict(torch.load('weight_best.pt'))\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs, all_fnames = [], []\n",
        "\n",
        "    pb = progress_bar(test_loader)\n",
        "    for images, fnames in pb:\n",
        "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
        "        all_outputs.append(preds.cpu().numpy())\n",
        "        all_fnames.extend(fnames)\n",
        "\n",
        "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
        "                              index=all_fnames,\n",
        "                              columns=map(str, range(num_classes)))\n",
        "    test_preds = test_preds.groupby(level=0).mean()\n",
        "\n",
        "    return test_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwIX8CeyyBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK7pYQk_yt3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7isI9efo1z",
        "colab_type": "text"
      },
      "source": [
        "### ***Study of cnn architecture:***\n",
        "layers which works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-3BIGj6bZf",
        "colab_type": "code",
        "outputId": "c3da97f0-a201-41b0-d41e-214460f74464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install --upgrade torch torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.2.2.post3\n",
            "    Uninstalling torchvision-0.2.2.post3:\n",
            "      Successfully uninstalled torchvision-0.2.2.post3\n",
            "Successfully installed torchvision-0.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQTzn0jiNwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnext50_32x4d(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUWnry6IiPjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptbbCIySkOYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ipnhPoYka7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model_ft(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgI4rC3piFXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4spaemOwgBya",
        "colab": {}
      },
      "source": [
        "model = model_ft\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wKi5i1kgByf",
        "colab": {}
      },
      "source": [
        "#pretrained models:\n",
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jfps-nfQgByp",
        "colab": {}
      },
      "source": [
        "import pretrainedmodels\n",
        "print(pretrainedmodels.model_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iIj6V7QegByu",
        "colab": {}
      },
      "source": [
        "# to load a pretrained models\n",
        "model_name = 'se_resnet50' # could be fbresnet152 or inceptionresnetv2\n",
        "model_ft = pretrainedmodels.__dict__[model_name](num_classes=1000)\n",
        "#model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nexlebj6gByy",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sh3q6u60gBy3",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "model_ft.last_linear = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UcoVNe4NgBy5",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "\n",
        "model_ft.last_linear = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=num_ftrs, out_features=1024, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=512, out_features=80, bias=True)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NL7JJ5nsgBzK",
        "colab": {}
      },
      "source": [
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4azuK11QgBzS",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "onT2H7jHgBzh",
        "colab": {}
      },
      "source": [
        "model_ft.classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CYuIY7HEgBzo",
        "colab": {}
      },
      "source": [
        "# as defined in the link:\n",
        "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKyrqR9ngBzr",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dRxnbqLegBzv",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(511, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(127, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1r_86POgBz2",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsPBvNBqhNTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "model=Classifier(num_classes=num_classes)\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(64, 3, 128, 128).type(dtype)\n",
        "ans = model(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LnFJkivvfgXL",
        "colab": {}
      },
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVm6KzeZfgXQ",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWnlMr59fgXV",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_tbFS1WfgXZ",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[2].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7ichSMTfgXg",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_dataset.mels[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXcfiBewfgXl",
        "colab": {}
      },
      "source": [
        "train_dataset.labels[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2mr3Q_6fgXp",
        "colab": {}
      },
      "source": [
        "mb_example = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_rKhgVBfgXu",
        "colab": {}
      },
      "source": [
        "mb_example[0].size(), mb_example[1].size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGzcBrv-fgXz",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(0,4):\n",
        "    sub_plot = fig.add_subplot(1,4,i+1)\n",
        "    sub_plot.axis('Off')\n",
        "    plt.imshow(mb_example[0][i,0].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_fhfZwe4Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (images, labels) in enumerate(train_loader):\n",
        "  print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D1sWPd2jFpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model_ft(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1K6xYZSAIDF",
        "colab_type": "text"
      },
      "source": [
        "### lr_finder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4Xxy8mKVLM",
        "colab_type": "text"
      },
      "source": [
        "***OPTIMIZER?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbWiyzBEfipA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgQOuVqFfW9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'sample_data/'\n",
        "\n",
        "epochs = 6\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr_find_epochs = 2\n",
        "\n",
        "start_lr = 1e-7\n",
        "\n",
        "end_lr = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3L_zb1qhKQdr",
        "colab": {}
      },
      "source": [
        "def test(model, device, valid_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    with torch.no_grad():\n",
        "        for j, (data, target) in enumerate(valid_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            pred = torch.sigmoid(output)\n",
        "            valid_preds[j * test_batch_size: (j+1) * test_batch_size] = pred.cpu().numpy()\n",
        "            #avg_val_loss += test_loss.item() / len(valid_loader)\n",
        "            \n",
        "            test_losses.append(test_loss.item())\n",
        "            #pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            #correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader)\n",
        "    score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "    lwlrap = (score * weight).sum()\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, val_lwlrap: {:.6f}\\n'.format(\n",
        "        np.mean(test_losses), lwlrap))\n",
        "    \n",
        "    return np.mean(test_losses), lwlrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhLDN7_uYVml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"lwlrap\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsuVLEb_nlTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting different optimizers:\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX4C8pE_WeT8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj84Y9MHnxNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "import plotly.plotly as py\n",
        "import plotly.tools as tools\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objs as go\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmOOeoLVLncW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs\n",
        "!mkdir logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rfkbulDMhxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70rM7ao_MTd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_data/flowers_adadelta_20190518132751.pickle sample_data/flowers_adamax_20190518130807.pickle logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIkW23GMuG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_data/flowers_adadelta_20190518133250.pickle sample_data/flowers_rmsprop_20190518122839.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adadelta_20190518133749.pickle sample_data/flowers_rmsprop_20190518123332.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adagrad_20190518124322.pickle sample_data/flowers_rmsprop_20190518123826.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adagrad_20190518124816.pickle sample_data/flowers_adagrad_20190518125313.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adam_20190518131302.pickle sample_data/flowers_adam_20190518131757.pickle logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSTMVIVNUkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_data/flowers_adam_20190518132252.pickle sample_data/flowers_adamax_20190518125810.pickle sample_data/flowers_adamax_20190518130309.pickle logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRxOUFIUdFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objs as go\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBoa8wbgWVM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32gsOTZMZ0tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install notebook --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxs23bH6WgAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting different optimizers:\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Xs7Yt1N3M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_plots = {}\n",
        "for i, file in enumerate(os.listdir(\"logs/flowers_vanilla/\")):\n",
        "    opt = file.split(\"_\")[1]\n",
        "    \n",
        "    plots = pickle.load(open(os.path.join(\"logs\",\"flowers_vanilla\",file),\"rb\"))\n",
        "    \n",
        "    if opt == \"adam\" and not \"adam\" in loss_plots:\n",
        "        plots = [{\n",
        "            \"acc\":x['acc']/100.0,\n",
        "            \"loss\":x[\"loss\"],\n",
        "            \"val_loss\":x[\"val_loss\"],\n",
        "            #\"lwlrap\":valid_acc\n",
        "            \"lwlrap\":x[\"lwlrap\"]\n",
        "        } for x in plots]\n",
        "        \n",
        "        plots = plots[:6]\n",
        "\n",
        "    \n",
        "    if opt in loss_plots:\n",
        "        loss_plots[opt].append(plots)\n",
        "    else:\n",
        "        loss_plots[opt] = [plots]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yYaeuG5O1wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "traces = []\n",
        "metric = \"acc\"\n",
        "for key,val in loss_plots.items():\n",
        "    \n",
        "    x = list(np.arange(1,len(val[0])+1))\n",
        "    x_rev = x[::-1]\n",
        "        \n",
        "    metric_values = np.asarray([[epoch[metric] for epoch in run] for run in val])\n",
        "    \n",
        "    y_upper = list(np.amax(metric_values,axis=0))\n",
        "    y_lower = np.amin(metric_values,axis=0)\n",
        "    y_lower = list(y_lower[::-1])\n",
        "    \n",
        "    traces.append(go.Scatter(\n",
        "        x=x+x_rev,\n",
        "        y=y_upper+y_lower,\n",
        "        fill='tozerox',\n",
        "        #fillcolor='rgba(0,100,80,0.2)',\n",
        "        #line=dict(color='rgba(255,255,255,0)'),\n",
        "        showlegend=True,\n",
        "        name=key,\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3WVB8dAO29o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layout = go.Layout(\n",
        "    paper_bgcolor='rgb(255,255,255)',\n",
        "    plot_bgcolor='rgb(229,229,229)',\n",
        "    xaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        range=[1,6],\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"epoch\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        range=[0, 1],\n",
        "        title = \"accuracy\"\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D42YDjzkaXuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyo.iplot(traces, filename='sdjf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGQOIJGcO_xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = go.Figure(data=traces, layout=layout)\n",
        "iplot(fig, show_link=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFAu_0uBTZ0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traces = []\n",
        "metric = \"lwlrap\"\n",
        "for key,val in loss_plots.items():\n",
        "    \n",
        "    x = list(np.arange(1,len(val[0])+1))\n",
        "    x_rev = x[::-1]\n",
        "        \n",
        "    metric_values = np.asarray([[epoch[metric] for epoch in run] for run in val])\n",
        "    \n",
        "    y_upper = list(np.amax(metric_values,axis=0))\n",
        "    y_lower = np.amin(metric_values,axis=0)\n",
        "    y_lower = list(y_lower[::-1])\n",
        "    \n",
        "    traces.append(go.Scatter(\n",
        "        x=x+x_rev,\n",
        "        y=y_upper+y_lower,\n",
        "        fill='tozerox',\n",
        "        #fillcolor='rgba(0,100,80,0.2)',\n",
        "        #line=dict(color='rgba(255,255,255,0)'),\n",
        "        showlegend=True,\n",
        "        name=key,\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ObQrqoFTgTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layout = go.Layout(\n",
        "    paper_bgcolor='rgb(255,255,255)',\n",
        "    plot_bgcolor='rgb(229,229,229)',\n",
        "    xaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        range=[1,6],\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"epoch\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        range=[0, 1],\n",
        "        title = \"accuracy\"\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w2oCpNrUIai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "pyo.iplot(fig, filename='td_medium_lr_1_vanilla_validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe7_KMRdR9wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly\n",
        "plotly.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz_tyKKySeNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install plotly --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIz26h8tPNfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jupyter labextension list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcKSplL6nxK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"sample_data/flowers_lr_find_loss.pickle\",\"rb\") as file:\n",
        "    lr_find_loss = pickle.load(file)\n",
        "    #lr_find_loss = lr_find_loss.detach().numpy()\n",
        "    \n",
        "with open(\"sample_data/flowers_lr_find_lr.pickle\",\"rb\") as file:\n",
        "    lr_find_lr = pickle.load(file)\n",
        "    #lr_find_lr = lr_find_lr.detach().numpy()\n",
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        type='log',\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate [log]\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"loss\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=lr_find_lr,\n",
        "        y=lr_find_loss,\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "py.iplot(fig, filename='td_medium_lr_loss_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iew2sWYunxFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_loss:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d32MP0xTnxCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_losses = a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNZ7Xj-8p5Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_lr:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhfrZKdTp_uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz7jOc9JqLie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        type='log',\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate [log]\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"loss\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=lr_find_lr,\n",
        "        y=np.array(lr_find_losses),\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "py.iplot(fig, filename='td_medium_lr_loss_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnNuDMYmqTNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS6l1mULAa-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier(num_classes=num_classes).to(device)\n",
        "\n",
        "optimizer = Adam(params=model.parameters(), lr=start_lr, amsgrad=False)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVUDiGLFAu3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LR function lambda\n",
        "\n",
        "lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (lr_find_epochs * len(train_loader)))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgIQjM9NA8wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the experiment \n",
        "\n",
        "lr_find_loss = []\n",
        "lr_find_lr = []\n",
        "\n",
        "iter = 0\n",
        "\n",
        "smoothing = 0.05\n",
        "\n",
        "for i in range(lr_find_epochs):\n",
        "  print(\"epoch {}\".format(i))\n",
        "  for inputs, labels in train_loader:\n",
        "    \n",
        "    # Send to device\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Training mode and zero gradients\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Get outputs to calc loss\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update LR\n",
        "    scheduler.step()\n",
        "    lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "    lr_find_lr.append(lr_step)\n",
        "\n",
        "    # smooth the loss\n",
        "    if iter==0:\n",
        "      lr_find_loss.append(loss)\n",
        "    else:\n",
        "      loss = smoothing  * loss + (1 - smoothing) * lr_find_loss[-1]\n",
        "      lr_find_loss.append(loss)\n",
        "     \n",
        "    iter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA2leRz7BIGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(path,\"flowers_lr_find_lr.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_lr,file)\n",
        "    \n",
        "with open(os.path.join(path,\"flowers_lr_find_loss.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_loss,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM7Zp27gByv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"lr\")\n",
        "plt.xscale(\"log\")\n",
        "plt.plot(lr_find_lr, lr_find_loss)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36lR5moaB0fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OY9nCY_B1wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBzsOo7YCPNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_max = 5*10e-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0gWY0ZPCdVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclical_lr(stepsize, min_lr=5, max_lr=5e-1):\n",
        "\n",
        "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
        "    scaler = lambda x: 1.\n",
        "\n",
        "    # Lambda function to calculate the LR\n",
        "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
        "\n",
        "    # Additional function to see where on the cycle we are\n",
        "    def relative(it, stepsize):\n",
        "        cycle = math.floor(1 + it / (2 * stepsize))\n",
        "        x = abs(it / stepsize - 2 * cycle + 1)\n",
        "        return max(0, (1 - x)) * scaler(cycle)\n",
        "\n",
        "    return lr_lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNTkyVx5zIG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, valid_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            pred = torch.sigmoid(output)\n",
        "            \n",
        "            test_losses.append(test_loss.item())\n",
        "            #pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader)\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        np.mean(test_losses), correct, len(valid_loader),\n",
        "        100. * correct / len(valid_loader)))\n",
        "    \n",
        "    return np.mean(test_losses), correct / len(valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tXszjbcEW2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 47"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN1WvboVCerG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "\n",
        "factor = 6\n",
        "end_lr = lr_max\n",
        "iter=0\n",
        "total_logs = []\n",
        "\n",
        "\n",
        "\n",
        "# Do 3 sequential runs\n",
        "for run in tqdm_notebook(range(3)):\n",
        "    \n",
        "    # Instantiate the model  \n",
        "    model = Classifier(num_classes=num_classes).to(device)\n",
        "    \n",
        "    # Define the loss function\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    # Define the optimizer\n",
        "    optimizer = Adam(params=model.parameters(), lr=1., amsgrad=False)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=1.)\n",
        "    step_size = 4*len(train_loader)\n",
        "    clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
        "    \n",
        "    logs = []\n",
        "\n",
        "    #Train the model\n",
        "    iter = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        losses = []\n",
        "        accuracies = []\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Send data to GPU\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward propagation \n",
        "            outputs = model(images)   \n",
        "            \n",
        "            # Calculating loss with softmax to obtain cross entropy loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward propation\n",
        "            loss.backward()\n",
        "            \n",
        "            # Clip the gradients norm to avoid them becoming too large\n",
        "            clip_grad_norm_(model.parameters(), 5)\n",
        "            \n",
        "            # Update the LR\n",
        "            scheduler.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            lr_sched_test = scheduler.get_lr()\n",
        "\n",
        "            # Updating gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            iter += 1\n",
        "            \n",
        "            # Total number of labels\n",
        "            total = labels.size(0)\n",
        "\n",
        "            # Obtaining predictions from max value\n",
        "            #_, predicted = torch.max(outputs.data, 1)\n",
        "            predicted = outputs\n",
        "\n",
        "            # Calculate the number of correct answers\n",
        "            correct = (predicted == labels).sum().item()\n",
        "    \n",
        "            accuracies.append(correct/total)\n",
        "\n",
        "        print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "        valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "          \n",
        "        logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"val_acc\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "        })\n",
        "            \n",
        "        \n",
        "    with open(os.path.join(path,\"flowers_{}_{}.pickle\".format('sgd_clr',datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "        pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUywNsreNId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"val_acc\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mETEglY4HLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxTwcKr2jLtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ncullen93/torchsample.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDDVd-ajmwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "pip install -e git+https://github.com/ncullen93/torchsample.git#egg=torchsample\n",
        "pip install visdom\n",
        "pip install nibabel\n",
        "pip install h5py  # this will be removed in the formal version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxdiwiPisWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsample.transforms import RangeNormalize\n",
        "norm_01 = RangeNormalize(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhFdvCcSlvKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC8grH3Jl67s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_mnist = train_dataset.mels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKRwmytdmOXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouvvR206leVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Before Tform: ' , x_train_mnist[0].min(), ' - ', x_train_mnist[0].max())\n",
        "x_norm = norm_01(x_train_mnist[0])\n",
        "print('After Tform: ' , x_norm.min(), ' - ', x_norm.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KEBGVHyiych",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Before Tform: ' , x_train[0].min(), ' - ', x_train[0].max())\n",
        "x_norm = norm_01(x_train[0])\n",
        "print('After Tform: ' , x_norm.min(), ' - ', x_norm.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My39I0RFVjXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Loading Code used for these examples\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9JuNHlVxDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT9oCQBaVu4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flipping images with Numpy\n",
        "flipped_img = np.fliplr(img)\n",
        "plt.imshow(flipped_img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAneevAIV-Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 127\n",
        "WIDTH = 487"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edvPId4sWLXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDTOvjYdZT_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 148\n",
        "WIDHT = 448\n",
        "DEPTH = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TViGNtWWYpoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ADDED NOISE:\n",
        "noise = np.random.randint(5, size = (164, 278, 4), dtype = 'uint8')\n",
        "\n",
        "for i in range(WIDTH):\n",
        "  for j in range(HEIGHT):\n",
        "    for k in range(DEPTH):\n",
        "      if (img[i][j][k] != 255):\n",
        "        img[i][j][k] += noise[i][j][k]\n",
        "        \n",
        "plt.imshow(img)\n",
        "plt.show(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF7D88yZZO5H",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJhEOWuUYpkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuThQSKTYpf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qVxxC_4Jgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomDihedral(object):\n",
        "    \"\"\"\n",
        "    Rotates images by random multiples of 90 degrees and/or reflection.\n",
        "    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size):\n",
        "      assert isinstance(output_size, (int, tuple))\n",
        "      self.output_size = output_size\n",
        "      \n",
        "      self.rot_times = random.randint(0.3)\n",
        "      self.do_flip = random.random()<0.5\n",
        "      \n",
        "    def __call__(self, (image, label)):\n",
        "      image = np.rot90(image, self.rot_times)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw_tqsBP1dSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomDihedral(CoordTransform):\n",
        "\n",
        "    def set_state(self):\n",
        "        self.store.rot_times = random.randint(0,3)\n",
        "        self.store.do_flip = random.random()<0.5\n",
        "\n",
        "    def do_transform(self, x, is_y):\n",
        "        x = np.rot90(x, self.store.rot_times)\n",
        "        return np.fliplr(x).copy() if self.store.do_flip else x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z40ONXDD1fKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = random.randint(0, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yrM8e71kEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PkdIbDPaMpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.rot90(x_train[0], b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xhRFhoXZtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply dihedral:\n",
        "random.random()<0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URAnWttUtcr7",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')        \n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFZ4_8-O1ufP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = np.fliplr(x_train[0]).copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_neB5FRd05s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(c, mode='RGB')        \n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2lY0pEwji5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5GbmuSfWtorp",
        "colab": {}
      },
      "source": [
        "#7th:dihedral??\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FNxTxVketoru",
        "colab": {}
      },
      "source": [
        "#dihedral\n",
        "def dihedral(x, dih):\n",
        "    \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n",
        "    x = np.rot90(x, dih%4)\n",
        "    return x if dih<4 else np.fliplr(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBpGe3Mgtor0",
        "colab": {}
      },
      "source": [
        "#dihedral class:\n",
        "class Dihedral(object):\n",
        "  \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n",
        "  \n",
        "  \n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    self.output_size = output_size\n",
        "    \n",
        "  def __cal__(self, image, label):\n",
        "    image, target = image, label\n",
        "    \n",
        "    x = np.rot90(x, dih)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll3msy5Zjy_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2nd:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fmASw-4dIdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UI_RKT7QfgXF",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HC5i7DF2fgXJ",
        "colab": {}
      },
      "source": [
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL6JSw1NAKAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uq86TKwzAKQA",
        "colab": {}
      },
      "source": [
        "path = 'sample_data/'\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHifYhTEAKQE",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mVgH5xAMAKQG",
        "colab": {}
      },
      "source": [
        "def test(model, device, valid_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            pred = torch.sigmoid(output)\n",
        "            \n",
        "            test_losses.append(test_loss.item())\n",
        "            #pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader)\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        np.mean(test_losses), correct, len(valid_loader),\n",
        "        100. * correct / len(valid_loader)))\n",
        "    \n",
        "    return np.mean(test_losses), correct / len(valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y50DZKTPAKQL",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"val_acc\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5-2pvejAJ9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99yj7s3FAJ6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7mfs8NxI58S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykUljzU8I54K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'logs/flowers_vanilla/'\n",
        "\n",
        "epochs = 60\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr_find_epochs = 2\n",
        "\n",
        "start_lr = 1e-7\n",
        "\n",
        "end_lr = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDiX_DEeI8_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier(num_classes=num_classes).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adamax(model.parameters(), start_lr)\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYs8lAmTI88Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (lr_find_epochs * len(train_loader)))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4JRHallI85M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the experiment \n",
        "\n",
        "lr_find_loss = []\n",
        "lr_find_lr = []\n",
        "\n",
        "iter = 0\n",
        "\n",
        "smoothing = 0.05\n",
        "\n",
        "for i in range(lr_find_epochs):\n",
        "  print(\"epoch {}\".format(i))\n",
        "  for inputs, labels in train_loader:\n",
        "    \n",
        "    # Send to device\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Training mode and zero gradients\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Get outputs to calc loss\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update LR\n",
        "    scheduler.step()\n",
        "    lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "    lr_find_lr.append(lr_step)\n",
        "\n",
        "    # smooth the loss\n",
        "    if iter==0:\n",
        "      lr_find_loss.append(loss)\n",
        "    else:\n",
        "      loss = smoothing  * loss + (1 - smoothing) * lr_find_loss[-1]\n",
        "      lr_find_loss.append(loss)\n",
        "     \n",
        "    iter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXf44pASJB9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(path,\"flowers_lr_find_lr.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_lr,file)\n",
        "    \n",
        "with open(os.path.join(path,\"flowers_lr_find_loss.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_loss,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXzNfBnEJB56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"lr\")\n",
        "plt.xscale(\"log\")\n",
        "plt.plot(lr_find_lr, lr_find_loss)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxj4BR0pI81W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70BD8bpKI8yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8NHC72SJfTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d65j3eUwKOK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"logs/flowers_vanilla/flowers_lr_find_loss.pickle\",\"rb\") as file:\n",
        "    lr_find_loss = pickle.load(file)\n",
        "    \n",
        "with open(\"logs/flowers_vanilla/flowers_lr_find_lr.pickle\",\"rb\") as file:\n",
        "    lr_find_lr = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isP0S5SgKQfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUXEY4fTKotw",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_loss:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pAQSDHDKqtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(np.array(a)).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yo1DK3Y0Kotz",
        "colab": {}
      },
      "source": [
        "lr_find_loss = np.array(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqoXUFulOimQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_lr.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0_vQf--4Kot1",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_lr:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FmqaIkqKot3",
        "colab": {}
      },
      "source": [
        "lr_find_lr = np.array(lr_find_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYNVRbFHI50C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        type='log',\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate [log]\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"loss\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=lr_find_lr,\n",
        "        y=lr_find_loss,\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "iplot(fig, filename='td_medium_lr_loss_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fY9vSTdJK_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"logs/flowers_vanilla/flowers_lr_find_lr.pickle\",\"rb\") as file:\n",
        "    lr_find_lr = pickle.load(file)\n",
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"step\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=list(range(len(lr_find_lr))),\n",
        "        y=lr_find_lr,\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "py.iplot(fig, filename='td_medium_lr_step_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZQBID-xxKkf",
        "colab_type": "text"
      },
      "source": [
        "### EXP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1cW2hf8JHrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-9-z5uME3Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting data and creating dataset; dataloaders\n",
        "with open('data/mels_train_curated.pkl', 'rb') as curated:\n",
        "  x_train = pickle.load(curated)\n",
        "  \n",
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTbKSc0uE3I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_curated = pd.read_csv('data/train_curated.csv')\n",
        "train_curated.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCthm9bSE3HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('data/sample_submission.csv')\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnlGAEcXE3ER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMP_yIyE3Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvOz9VAtE3Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros((len(train_curated), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_curated['labels'].str.split(',')):\n",
        "  for label in row:\n",
        "    idx = labels.index(label)\n",
        "    y_train[i, idx] = 1\n",
        "    \n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYsaDFktE299",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btvx3nLCE278",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-jNLq4qE26Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_train[47])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24MlwGCPqaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGq0c5nVbl7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tktdp_wcdsU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "skimage.io.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ2_JvzGXFqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWBNjYY_E24D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class traindataset(Dataset):\n",
        "  def __init__(self, x_train, y_train, transforms=None):\n",
        "    self.images = x_train\n",
        "    self.labels = y_train\n",
        "    self.transforms = transforms\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    image = np.uint8(self.images[index])\n",
        "    label = self.labels[index]\n",
        "    sample = {'image': image, 'label':label}\n",
        "    \n",
        "    if self.transforms:\n",
        "      sample = self.transforms(sample)\n",
        "      \n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g33BekqOh2qj",
        "colab_type": "text"
      },
      "source": [
        "### Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPEca-ORh5RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\", \"sparseadam\", \"asgd\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "        elif key == \"sparseadam\":\n",
        "            optimizer = torch.optim.SparseAdam(model.parameters())\n",
        "        elif key == \"asgd\":\n",
        "            optimizer = torch.optim.ASGD(model.parameters())\n",
        "\n",
        "\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"lwlrap\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eikzu2kh6E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYzvhtE9h5_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SXgP1keh54j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7RGMgFah5Lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twRt2uWEh5GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ytQaa6rh4-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}