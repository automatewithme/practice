{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trail_10_augmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eHnoL6b4P2uw",
        "ywFnbu3eP5nW",
        "Ti-PQPO2uNQC",
        "O5P3LRRfB9Kd",
        "3GrsWQAAdftZ",
        "4S7isI9efo1z",
        "V1K6xYZSAIDF",
        "pZQBID-xxKkf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Haq2PI9sBZ4",
        "colab_type": "text"
      },
      "source": [
        "implementation:\n",
        "\n",
        "*   https://www.kaggle.com/daisukelab/cnn-2d-basic-solution-powered-by-fast-ai\n",
        "*   https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHnoL6b4P2uw",
        "colab_type": "text"
      },
      "source": [
        "### Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4fj8QJuPXUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799884&Signature=F%2Fad1sy%2BW8St76%2B8f3hMaIuYEpIiHa1VBPcFmcbPgITtIiSu4ZDmh65EuaDJn0pD1%2FdgfCzPRhXvpREZ9KYbCHqLCN%2FBI0SrL15waLFHyIKJoBy6oR6GqmWpUj4nj8vPHE1AnkuzaTYtPU6KZWSi%2BhBv%2FR9sNkH2kChcyyjBiE8iQEO7f2isrtNXlaDEgBDy3CWMri%2FZycWwZmif3m8%2Br5DsX5EnabMRJiH2fiDidpcu4irs%2B8YPKgticTKbZT4ryN2I5I6%2BgSoNJuGLErtomCRQztt6F4Vcm1q%2BOpkAiwf5Aub8v9%2BNeHpL6ZBcbAKt1H1gKaZ3xiV2Zt8EnTMgfA%3D%3D\" -O \"sample_submission.csv\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0mlUkNgPm3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799898&Signature=itj45RttdpUSnrbNk7ROVmQpBtkQKF%2Fn3vVS88UGduDi4u1KU7ZdKRt0CAfWYHDlmgc15KanVoEBELntnJDIePohCWdnFF5LEP18%2BBeJ9LuwQ3sDBJJEbRfwrAbcgbasyhGE%2Fw8qFakqsDVEHvaag0jDXUWg8Cg8thBMDERX6Enu%2FI4Obn18LvPlhkg5FhQfQsVcdXxdFKHx869eGq34TnYhlvuAKsOZo5LesF6FeAK3G80GHhVA9B78uSwEziLrhgagWXm%2Fp3wpg%2Fsnpu5TJed%2FJjLiwoguExOx%2Fcws9xWTubKrF4rgb6X5FD3bIV5b8H1rwyWg%2FU8v%2BDkDH4dxqQ%3D%3D\" -O \"train_curated.csv\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTXMdoKhPqb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799913&Signature=ZlFh6cVQTqy%2BPNv1uwmiZJLurcQnzng%2BX3lxN%2FLzGbIwm%2B5npT%2Bznr4kSV%2FGUdT3FA9qIXkX%2BkKE4nGkp4Ex8hi%2FLWF1mSr56DvCv8lrHH4d8HanHUVJH6hMIR8d40gejokfnEIF67ocNS02CZFKxRQYSetxjvJDAHNfQbsL1pdYpXMljPPr2a%2F6zjbXH%2B5VY5mIK669yTGiquXpsrLM%2Bnnas0o22ZZQGnkwL7hCWUcC7W48zSIMJUriNPWlQrjZyPJNs26O6XpibtqtQqbUg5j7SOGHQBpF7X8osQWDisnfpMe65MZbaiGtQ4nr5OAg%2FWdnrPbSIU6StrF2iSNBeg%3D%3D\" -O \"train_noisy.csv\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75LDMVcPs52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799927&Signature=J0YpYkbuS5khWnMdmZ8UIj7L41o8S5%2BmANIZJKJz5HIWj8s7d9M34m%2B6Tc6E3BjhGDefza2%2FWlCj1wJKX4ECVI5S%2B%2F%2FTJGniSWaJnHt6874peKSFRsyk%2FfOSaMsuyNpPWe%2FrmrBHZ%2FVj0HaZlhXlW5%2BLXfi9p7L%2F3zs1yy1Xu%2BQ5ZrEHDn3kQ1gbN1mJ03cXG0qA%2BUCQLlq0ZTi465fp%2BaJAqWTH7qnMmej%2BHt9zCmdl1VBj0wb04YDIjiLaTP%2BdS7tmqOMczjT1a9lZJeEKgwNSdGCWueHTseu0AKWywk6svh1Q0vo4qEoA21%2F0V%2FKi6I6CMAsKaZowVd2VxRsRfQ%3D%3D\" -O \"test.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doLUxbxlPyes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_curated.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799942&Signature=LVCIgYhouKvt3sMbZcmRZQz92zjnwvPzz%2BiQXHnatRXMp2bkXoBapAqSHtawEGG7m1JUG4dCDiAsG6A6jNoW8PaII7AYXsCJuIaQaMjAH%2FE6wFfy5h27xprzDwsZykE6q1Vtq3NxfjwGqqMXDCqtjy%2Fjsov4cbrCGXNzZwtHF%2BxKenJEidwX4VGchNFu57CgsjgHQU4aHAGisS0P8AEPahgjgKWs4OOQY4PGs06y9nOsZzzbWFjWf4W8X41loL%2BAmC41brArHoak0DzSsTdT33E7%2BKPDhMt4YkSx%2B8sDsEVtOkZJbARglHXOhE%2BaQC7G%2Fkm5mB8E0X03BK%2FAfo1Xtg%3D%3D\" -O \"train_curated.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNnA16iPy_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10700/371136/train_noisy.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799956&Signature=jyuoEtStXkt2fo1jBOxMVWmHmM03wkEcYA4a7jXDnp4w%2FXYomsje6uDv4rbeUl2UDpNbCHAwraU4zgTH9YxUVqmYrFBf9INd9Eqyq%2B8J4R%2F8PuPbx5yNLntlqPULq2iP4kn315DTkInPpGpACUgnhVZsdcGMAaHLYI8Gk4drcECT0NghIxTtqpJ6pQ3zBvDTKmwqi%2Fe8cqMvvH3fY21IBVHmnDqmMB0Cbeoo9D3Y7HMSyQvMGCmQ97Mve%2FI%2Bhirs7Qqed1ftzcnxFwpbr6ALZExZNVt7keVjlEIdVhP1%2B14HhsCIhBSYa8FUQjCpbzoniYTJm5Pd31wxXpRYViPQ2A%3D%3D\" -O \"train_noisy.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fJaLfzGynqy",
        "colab_type": "text"
      },
      "source": [
        "***Preprocessed data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bZWNGSWypWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-datasets/164278/379726/fat2019_prep_mels1.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558799978&Signature=EAt70QU2usekkPy74aSvqhN4f7o7pxx%2BHPUY5NgZ9m%2FxEsoOpQsV7R0lJLDoc%2BQ9eenQl8BN3ZF7sHHax07TCxE6zYU1pqLxi0F%2BAshQWT2Fswsi%2B5Lrdeb%2FVCeiBrknI5upPS3kYNgaGiLWbd76vu8SRnO092Wbvo9nKCqqJjSz0fSI7%2BVHPH8xb9MbtV1bkiYCkHwnZTOXJQNffAOHzC9aXIVu5wG0wWKly7iokVU2oKJE23a8QfE%2BjhRgbC3KHeMks0uPD95WtGdHYIW8JDrnejTEHNyApGq8JPS8dM2zq0wW1xteFotawF%2FLS32msixYHCJeCDTbfClvpYgkgA%3D%3D\" -O \"fat2019_prep_mels1.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywFnbu3eP5nW",
        "colab_type": "text"
      },
      "source": [
        "### Exploring dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0tOhnVcACC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test\n",
        "!mkdir train_curated\n",
        "!mkdir train_noisy\n",
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pokwjdG2zCjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq fat2019_prep_mels1.zip -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1Wq71PP43o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLZZ6nuWQMqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_curated.zip -d train_curated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpYGeV7mQMkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq train_noisy.zip -d train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK-JmCd_QMWx",
        "colab_type": "text"
      },
      "source": [
        "To apply deep learning technique, we first have to come up with a way to provide effective converse from audio data to any other form which will make it effective for deep learning technique for multilabeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l5HQ4X5SmxC",
        "colab_type": "text"
      },
      "source": [
        "Audio conversion to 2D\n",
        "Almost copyed from my repository: https://github.com/daisukelab/ml-sound-classifier\n",
        "\n",
        "Handle sampling rate 44.1kHz as is, no information loss.\n",
        "Size of each file will be 128 x L, L is audio seconds x 128; [128, 256] if sound is 2s long.\n",
        "Convert to Mel-spectrogram, not MFCC. We are handling general sound rather than human voice. https://en.wikipedia.org/wiki/Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PZG8p-dchS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv -t data test train_curated train_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPW_sIidU0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_submission.csv train_curated.csv train_noisy.csv data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFndQ6_MhLb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTCWqn31MKk",
        "colab_type": "text"
      },
      "source": [
        "## Testing different dL techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKoAfumiEzmB",
        "colab_type": "text"
      },
      "source": [
        "### End-2-End pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrDOLlznw5V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"list:\n",
        "  apply augmentation\n",
        "  cnn architecture\n",
        "  result of model\n",
        "  .div_(255)\n",
        "  img = img / 2 + 0.5     # unnormalize\n",
        "\n",
        "  \n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdnnHF_wLHoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "random_state = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVMnWnBwzTTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from psutil import cpu_count\n",
        "import random\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vmit45ThyA0E",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJwRjrv8yA0K",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBUtxLEeyA0M",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8tk1KBuHyA0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "950058f3-2ab5-4e2b-ad0e-c6bec83b2d88"
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>labels</th>\n",
              "      <th>singled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0006ae4e.wav</td>\n",
              "      <td>Bark</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0019ef41.wav</td>\n",
              "      <td>Raindrop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ec0ad.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0026c7cb.wav</td>\n",
              "      <td>Run</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0026f116.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname           labels singled\n",
              "0  0006ae4e.wav             Bark     NaN\n",
              "1  0019ef41.wav         Raindrop     NaN\n",
              "2  001ec0ad.wav  Finger_snapping     NaN\n",
              "3  0026c7cb.wav              Run     NaN\n",
              "4  0026f116.wav  Finger_snapping     NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mY5rf36QyA0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "c9524f57-0417-4971-e1b5-53eb50b94cb4"
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>Burping_and_eructation</th>\n",
              "      <th>Bus</th>\n",
              "      <th>Buzz</th>\n",
              "      <th>Car_passing_by</th>\n",
              "      <th>Cheering</th>\n",
              "      <th>Chewing_and_mastication</th>\n",
              "      <th>Child_speech_and_kid_speaking</th>\n",
              "      <th>Chink_and_clink</th>\n",
              "      <th>Chirp_and_tweet</th>\n",
              "      <th>Church_bell</th>\n",
              "      <th>Clapping</th>\n",
              "      <th>Computer_keyboard</th>\n",
              "      <th>Crackle</th>\n",
              "      <th>Cricket</th>\n",
              "      <th>Crowd</th>\n",
              "      <th>Cupboard_open_or_close</th>\n",
              "      <th>Cutlery_and_silverware</th>\n",
              "      <th>Dishes_and_pots_and_pans</th>\n",
              "      <th>Drawer_open_or_close</th>\n",
              "      <th>Drip</th>\n",
              "      <th>Electric_guitar</th>\n",
              "      <th>Fart</th>\n",
              "      <th>Female_singing</th>\n",
              "      <th>Female_speech_and_woman_speaking</th>\n",
              "      <th>Fill_(with_liquid)</th>\n",
              "      <th>Finger_snapping</th>\n",
              "      <th>Frying_(food)</th>\n",
              "      <th>Gasp</th>\n",
              "      <th>Glockenspiel</th>\n",
              "      <th>Gong</th>\n",
              "      <th>...</th>\n",
              "      <th>Harmonica</th>\n",
              "      <th>Hi-hat</th>\n",
              "      <th>Hiss</th>\n",
              "      <th>Keys_jangling</th>\n",
              "      <th>Knock</th>\n",
              "      <th>Male_singing</th>\n",
              "      <th>Male_speech_and_man_speaking</th>\n",
              "      <th>Marimba_and_xylophone</th>\n",
              "      <th>Mechanical_fan</th>\n",
              "      <th>Meow</th>\n",
              "      <th>Microwave_oven</th>\n",
              "      <th>Motorcycle</th>\n",
              "      <th>Printer</th>\n",
              "      <th>Purr</th>\n",
              "      <th>Race_car_and_auto_racing</th>\n",
              "      <th>Raindrop</th>\n",
              "      <th>Run</th>\n",
              "      <th>Scissors</th>\n",
              "      <th>Screaming</th>\n",
              "      <th>Shatter</th>\n",
              "      <th>Sigh</th>\n",
              "      <th>Sink_(filling_or_washing)</th>\n",
              "      <th>Skateboard</th>\n",
              "      <th>Slam</th>\n",
              "      <th>Sneeze</th>\n",
              "      <th>Squeak</th>\n",
              "      <th>Stream</th>\n",
              "      <th>Strum</th>\n",
              "      <th>Tap</th>\n",
              "      <th>Tick-tock</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom  ...  Yell  Zipper_(clothing)\n",
              "0  000ccb97.wav                                   0  ...     0                  0\n",
              "1  0012633b.wav                                   0  ...     0                  0\n",
              "2  001ed5f1.wav                                   0  ...     0                  0\n",
              "3  00294be0.wav                                   0  ...     0                  0\n",
              "4  003fde7a.wav                                   0  ...     0                  0\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LidAwl4SyA0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "65c28ae7-f677-4d44-996d-3befe91788a2"
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accelerating_and_revving_and_vroom',\n",
              " 'Accordion',\n",
              " 'Acoustic_guitar',\n",
              " 'Applause',\n",
              " 'Bark',\n",
              " 'Bass_drum',\n",
              " 'Bass_guitar',\n",
              " 'Bathtub_(filling_or_washing)',\n",
              " 'Bicycle_bell',\n",
              " 'Burping_and_eructation',\n",
              " 'Bus',\n",
              " 'Buzz',\n",
              " 'Car_passing_by',\n",
              " 'Cheering',\n",
              " 'Chewing_and_mastication',\n",
              " 'Child_speech_and_kid_speaking',\n",
              " 'Chink_and_clink',\n",
              " 'Chirp_and_tweet',\n",
              " 'Church_bell',\n",
              " 'Clapping',\n",
              " 'Computer_keyboard',\n",
              " 'Crackle',\n",
              " 'Cricket',\n",
              " 'Crowd',\n",
              " 'Cupboard_open_or_close',\n",
              " 'Cutlery_and_silverware',\n",
              " 'Dishes_and_pots_and_pans',\n",
              " 'Drawer_open_or_close',\n",
              " 'Drip',\n",
              " 'Electric_guitar',\n",
              " 'Fart',\n",
              " 'Female_singing',\n",
              " 'Female_speech_and_woman_speaking',\n",
              " 'Fill_(with_liquid)',\n",
              " 'Finger_snapping',\n",
              " 'Frying_(food)',\n",
              " 'Gasp',\n",
              " 'Glockenspiel',\n",
              " 'Gong',\n",
              " 'Gurgling',\n",
              " 'Harmonica',\n",
              " 'Hi-hat',\n",
              " 'Hiss',\n",
              " 'Keys_jangling',\n",
              " 'Knock',\n",
              " 'Male_singing',\n",
              " 'Male_speech_and_man_speaking',\n",
              " 'Marimba_and_xylophone',\n",
              " 'Mechanical_fan',\n",
              " 'Meow',\n",
              " 'Microwave_oven',\n",
              " 'Motorcycle',\n",
              " 'Printer',\n",
              " 'Purr',\n",
              " 'Race_car_and_auto_racing',\n",
              " 'Raindrop',\n",
              " 'Run',\n",
              " 'Scissors',\n",
              " 'Screaming',\n",
              " 'Shatter',\n",
              " 'Sigh',\n",
              " 'Sink_(filling_or_washing)',\n",
              " 'Skateboard',\n",
              " 'Slam',\n",
              " 'Sneeze',\n",
              " 'Squeak',\n",
              " 'Stream',\n",
              " 'Strum',\n",
              " 'Tap',\n",
              " 'Tick-tock',\n",
              " 'Toilet_flush',\n",
              " 'Traffic_noise_and_roadway_noise',\n",
              " 'Trickle_and_dribble',\n",
              " 'Walk_and_footsteps',\n",
              " 'Water_tap_and_faucet',\n",
              " 'Waves_and_surf',\n",
              " 'Whispering',\n",
              " 'Writing',\n",
              " 'Yell',\n",
              " 'Zipper_(clothing)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J7euOnyCyA0Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8563b56c-71aa-42f9-a20a-3397c279dd88"
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6X5jNxOJyA0g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c62c8ed-fcb4-43cd-9404-c9e38a544976"
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_CC3ZjDyA0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12f48b77-bd32-4be9-f338-361c8780bd81"
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8970, 1120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrQ5UmeVz2cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 520\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp8JKf3fz08g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_JOBS = cpu_count()\n",
        "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
        "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
        "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2CHjkwmv5n2",
        "colab_type": "text"
      },
      "source": [
        "### Dataset and Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rn3WZkIZyA0o",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hR8vzLtiyA0r",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpy6MF9vyoC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h1vK_AytyoKE",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yrk32OEsyoKJ",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83mWImPY1jtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "3f88a12a-2e71-4327-801c-eb1256595e99"
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f04e6bd97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACCCAYAAABIFgNQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2ie8zRT9rM3arM3aJ7z9c/aNr6/dn3TIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYppofGmE21q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "12e076a4-b073-45ee-fea4-d150b4d624f9"
      },
      "source": [
        "fat_dataset = train_dataset\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(fat_dataset)):\n",
        "  image, labels = fat_dataset[i]\n",
        "  print(i, image.shape, labels.shape)\n",
        "\n",
        "  ax = plt.subplot(1, 4, i+1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  img = image / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  \n",
        "  #plt.imshow(np.array(image).reshape((128,128, -1)).astype('uint8'))\n",
        "  \n",
        "  if i == 3:\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([3, 128, 128]) torch.Size([80])\n",
            "1 torch.Size([3, 128, 128]) torch.Size([80])\n",
            "2 torch.Size([3, 128, 128]) torch.Size([80])\n",
            "3 torch.Size([3, 128, 128]) torch.Size([80])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAByCAYAAAAVtwXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n_ZQ_NS2Foi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "57de98cb-84b1-4c12-daa5-562c0469d309"
      },
      "source": [
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % train_df.labels[j] for j in range(4)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " Bark Raindrop Finger_snapping   Run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arVLcIFLvjwy",
        "colab_type": "text"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3wPv2TrvdIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 80)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uioQvDk23sBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# the GPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "model = Net().to(device)\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRlaWAr22VhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(65536, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024,80)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc_layers(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lalRsaHv2jff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFCJ0OqL2bKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "model = CNN().to(device)\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "komjhr_GyA0v",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2vQrw9fhyA0z",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUnEKUXUyA02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        },
        "outputId": "05aad9c1-44d6-4c29-af3e-2520a2255463"
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.2)\n",
              "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (2): PReLU(num_parameters=1)\n",
              "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Dropout(p=0.1)\n",
              "    (5): Linear(in_features=128, out_features=80, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfj55S5jvm9r",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRAkJ5NQ5BhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "lr = 0.01\n",
        "\n",
        "net = Classifier(num_classes=num_classes).cuda()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adamax(params=net.parameters(), lr=lr)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8j8kMfi7soq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "d4215289-8568-4b05-b95d-9009db0f033a"
      },
      "source": [
        "import time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(30):  # loop over the dataset multiple times\n",
        "  \n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0\n",
        "    start_time = time.time()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.cuda())\n",
        "        loss = criterion(outputs, labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    avg_val_loss = 0\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "      with torch.no_grad():\n",
        "            preds = net(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "            avg_val_loss += loss.item() \n",
        "            \n",
        "    score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "    lwlrap = (score * weight).sum()\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(f'Epoch {epoch + 1} - avg_train_loss : {running_loss: .4f} avg_val_loss: {avg_val_loss:.4f} val_lwrap: {lwlrap:.6f} time: {elapsed:.0f}s')\n",
        "      \n",
        "    if lwlrap > best_lwlrap:\n",
        "      best_epoch = epoch + 1\n",
        "      best_lwlrap = lwlrap\n",
        "      torch.save(net.state_dict(), 'weight_best.pt')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss :  5.3492 avg_val_loss: 1.4439 val_lwrap: 0.470163 time: 52s\n",
            "Epoch 2 - avg_train_loss :  5.2606 avg_val_loss: 1.4303 val_lwrap: 0.472961 time: 51s\n",
            "Epoch 3 - avg_train_loss :  5.1661 avg_val_loss: 1.3992 val_lwrap: 0.475503 time: 51s\n",
            "Epoch 4 - avg_train_loss :  5.0952 avg_val_loss: 1.3959 val_lwrap: 0.482050 time: 51s\n",
            "Epoch 5 - avg_train_loss :  5.0782 avg_val_loss: 1.3797 val_lwrap: 0.488071 time: 51s\n",
            "Epoch 6 - avg_train_loss :  5.0035 avg_val_loss: 1.3666 val_lwrap: 0.501494 time: 51s\n",
            "Epoch 7 - avg_train_loss :  4.9430 avg_val_loss: 1.3720 val_lwrap: 0.489779 time: 51s\n",
            "Epoch 8 - avg_train_loss :  4.8601 avg_val_loss: 1.3639 val_lwrap: 0.502445 time: 51s\n",
            "Epoch 9 - avg_train_loss :  4.8287 avg_val_loss: 1.3419 val_lwrap: 0.522378 time: 51s\n",
            "Epoch 10 - avg_train_loss :  4.7573 avg_val_loss: 1.3231 val_lwrap: 0.525079 time: 51s\n",
            "Epoch 11 - avg_train_loss :  4.6838 avg_val_loss: 1.3406 val_lwrap: 0.526767 time: 51s\n",
            "Epoch 12 - avg_train_loss :  4.6086 avg_val_loss: 1.3271 val_lwrap: 0.516550 time: 51s\n",
            "Epoch 13 - avg_train_loss :  4.6251 avg_val_loss: 1.3458 val_lwrap: 0.522981 time: 51s\n",
            "Epoch 14 - avg_train_loss :  4.5671 avg_val_loss: 1.3306 val_lwrap: 0.534659 time: 51s\n",
            "Epoch 15 - avg_train_loss :  4.5825 avg_val_loss: 1.3257 val_lwrap: 0.531621 time: 51s\n",
            "Epoch 16 - avg_train_loss :  4.4591 avg_val_loss: 1.3235 val_lwrap: 0.521194 time: 51s\n",
            "Epoch 17 - avg_train_loss :  4.4317 avg_val_loss: 1.2975 val_lwrap: 0.539397 time: 51s\n",
            "Epoch 18 - avg_train_loss :  4.3507 avg_val_loss: 1.2998 val_lwrap: 0.543167 time: 51s\n",
            "Epoch 19 - avg_train_loss :  4.3040 avg_val_loss: 1.3037 val_lwrap: 0.539138 time: 51s\n",
            "Epoch 20 - avg_train_loss :  4.2443 avg_val_loss: 1.3116 val_lwrap: 0.545597 time: 51s\n",
            "Epoch 21 - avg_train_loss :  4.1983 avg_val_loss: 1.2830 val_lwrap: 0.548460 time: 51s\n",
            "Epoch 22 - avg_train_loss :  4.0562 avg_val_loss: 1.2660 val_lwrap: 0.558477 time: 51s\n",
            "Epoch 23 - avg_train_loss :  4.0974 avg_val_loss: 1.2908 val_lwrap: 0.557950 time: 51s\n",
            "Epoch 24 - avg_train_loss :  4.0487 avg_val_loss: 1.2595 val_lwrap: 0.567722 time: 51s\n",
            "Epoch 25 - avg_train_loss :  4.0006 avg_val_loss: 1.2587 val_lwrap: 0.555885 time: 51s\n",
            "Epoch 26 - avg_train_loss :  4.0075 avg_val_loss: 1.2936 val_lwrap: 0.554793 time: 51s\n",
            "Epoch 27 - avg_train_loss :  3.9545 avg_val_loss: 1.2192 val_lwrap: 0.577697 time: 51s\n",
            "Epoch 28 - avg_train_loss :  3.8289 avg_val_loss: 1.2369 val_lwrap: 0.568588 time: 51s\n",
            "Epoch 29 - avg_train_loss :  3.8310 avg_val_loss: 1.2675 val_lwrap: 0.570081 time: 51s\n",
            "Epoch 30 - avg_train_loss :  3.8173 avg_val_loss: 1.2882 val_lwrap: 0.563972 time: 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QYe1a4J_QGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d332869b-1566-4913-84cb-a69ef63e8616"
      },
      "source": [
        "best_lwlrap"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5639718514358507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8BXogJ1_Q-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e35731ad-4a6f-4cf4-b045-411b3a42b9b9"
      },
      "source": [
        "best_epoch"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dNjJzIM_tQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "test_transforms = transforms_dict['test']\n",
        "\n",
        "test_dataset = FATTestDataset(test_df['fname'], x_test, test_transforms, tta=20)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "net.load_state_dict(torch.load('weight_best.pt'))\n",
        "all_outputs, all_fnames = [], []\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, fnames = data\n",
        "    preds = torch.sigmoid(net(images.cuda()).detach())\n",
        "    all_outputs.append(preds.cpu().numpy())\n",
        "    all_fnames.extend(fnames)\n",
        "\n",
        "test_preds = pd.DataFrame(data=np.concatenate(all_outputs), index=all_fnames, columns=map(str, range(num_classes)))\n",
        "test_preds = test_preds.groupby(level=0).mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Ap4R5ODb2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6395996c-1710-431c-8674-5f5c4f62c226"
      },
      "source": [
        "test_preds.values.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1120, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4idIniveDffl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "485763ad-8b0c-4a1c-b57b-4259ff8d579a"
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1120, 81)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8an37nnJDhzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "7f0db2f3-bc86-42bf-a4a3-77a19535a5eb"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>Burping_and_eructation</th>\n",
              "      <th>Bus</th>\n",
              "      <th>Buzz</th>\n",
              "      <th>Car_passing_by</th>\n",
              "      <th>Cheering</th>\n",
              "      <th>Chewing_and_mastication</th>\n",
              "      <th>Child_speech_and_kid_speaking</th>\n",
              "      <th>Chink_and_clink</th>\n",
              "      <th>Chirp_and_tweet</th>\n",
              "      <th>Church_bell</th>\n",
              "      <th>Clapping</th>\n",
              "      <th>Computer_keyboard</th>\n",
              "      <th>Crackle</th>\n",
              "      <th>Cricket</th>\n",
              "      <th>Crowd</th>\n",
              "      <th>Cupboard_open_or_close</th>\n",
              "      <th>Cutlery_and_silverware</th>\n",
              "      <th>Dishes_and_pots_and_pans</th>\n",
              "      <th>Drawer_open_or_close</th>\n",
              "      <th>Drip</th>\n",
              "      <th>Electric_guitar</th>\n",
              "      <th>Fart</th>\n",
              "      <th>Female_singing</th>\n",
              "      <th>Female_speech_and_woman_speaking</th>\n",
              "      <th>Fill_(with_liquid)</th>\n",
              "      <th>Finger_snapping</th>\n",
              "      <th>Frying_(food)</th>\n",
              "      <th>Gasp</th>\n",
              "      <th>Glockenspiel</th>\n",
              "      <th>Gong</th>\n",
              "      <th>...</th>\n",
              "      <th>Harmonica</th>\n",
              "      <th>Hi-hat</th>\n",
              "      <th>Hiss</th>\n",
              "      <th>Keys_jangling</th>\n",
              "      <th>Knock</th>\n",
              "      <th>Male_singing</th>\n",
              "      <th>Male_speech_and_man_speaking</th>\n",
              "      <th>Marimba_and_xylophone</th>\n",
              "      <th>Mechanical_fan</th>\n",
              "      <th>Meow</th>\n",
              "      <th>Microwave_oven</th>\n",
              "      <th>Motorcycle</th>\n",
              "      <th>Printer</th>\n",
              "      <th>Purr</th>\n",
              "      <th>Race_car_and_auto_racing</th>\n",
              "      <th>Raindrop</th>\n",
              "      <th>Run</th>\n",
              "      <th>Scissors</th>\n",
              "      <th>Screaming</th>\n",
              "      <th>Shatter</th>\n",
              "      <th>Sigh</th>\n",
              "      <th>Sink_(filling_or_washing)</th>\n",
              "      <th>Skateboard</th>\n",
              "      <th>Slam</th>\n",
              "      <th>Sneeze</th>\n",
              "      <th>Squeak</th>\n",
              "      <th>Stream</th>\n",
              "      <th>Strum</th>\n",
              "      <th>Tap</th>\n",
              "      <th>Tick-tock</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  Accelerating_and_revving_and_vroom  ...  Yell  Zipper_(clothing)\n",
              "0  000ccb97.wav                                   0  ...     0                  0\n",
              "1  0012633b.wav                                   0  ...     0                  0\n",
              "2  001ed5f1.wav                                   0  ...     0                  0\n",
              "3  00294be0.wav                                   0  ...     0                  0\n",
              "4  003fde7a.wav                                   0  ...     0                  0\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAqkaQWbDu6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "fb6fbf48-5731-40fc-c3d7-97c4d89a5202"
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accelerating_and_revving_and_vroom',\n",
              " 'Accordion',\n",
              " 'Acoustic_guitar',\n",
              " 'Applause',\n",
              " 'Bark',\n",
              " 'Bass_drum',\n",
              " 'Bass_guitar',\n",
              " 'Bathtub_(filling_or_washing)',\n",
              " 'Bicycle_bell',\n",
              " 'Burping_and_eructation',\n",
              " 'Bus',\n",
              " 'Buzz',\n",
              " 'Car_passing_by',\n",
              " 'Cheering',\n",
              " 'Chewing_and_mastication',\n",
              " 'Child_speech_and_kid_speaking',\n",
              " 'Chink_and_clink',\n",
              " 'Chirp_and_tweet',\n",
              " 'Church_bell',\n",
              " 'Clapping',\n",
              " 'Computer_keyboard',\n",
              " 'Crackle',\n",
              " 'Cricket',\n",
              " 'Crowd',\n",
              " 'Cupboard_open_or_close',\n",
              " 'Cutlery_and_silverware',\n",
              " 'Dishes_and_pots_and_pans',\n",
              " 'Drawer_open_or_close',\n",
              " 'Drip',\n",
              " 'Electric_guitar',\n",
              " 'Fart',\n",
              " 'Female_singing',\n",
              " 'Female_speech_and_woman_speaking',\n",
              " 'Fill_(with_liquid)',\n",
              " 'Finger_snapping',\n",
              " 'Frying_(food)',\n",
              " 'Gasp',\n",
              " 'Glockenspiel',\n",
              " 'Gong',\n",
              " 'Gurgling',\n",
              " 'Harmonica',\n",
              " 'Hi-hat',\n",
              " 'Hiss',\n",
              " 'Keys_jangling',\n",
              " 'Knock',\n",
              " 'Male_singing',\n",
              " 'Male_speech_and_man_speaking',\n",
              " 'Marimba_and_xylophone',\n",
              " 'Mechanical_fan',\n",
              " 'Meow',\n",
              " 'Microwave_oven',\n",
              " 'Motorcycle',\n",
              " 'Printer',\n",
              " 'Purr',\n",
              " 'Race_car_and_auto_racing',\n",
              " 'Raindrop',\n",
              " 'Run',\n",
              " 'Scissors',\n",
              " 'Screaming',\n",
              " 'Shatter',\n",
              " 'Sigh',\n",
              " 'Sink_(filling_or_washing)',\n",
              " 'Skateboard',\n",
              " 'Slam',\n",
              " 'Sneeze',\n",
              " 'Squeak',\n",
              " 'Stream',\n",
              " 'Strum',\n",
              " 'Tap',\n",
              " 'Tick-tock',\n",
              " 'Toilet_flush',\n",
              " 'Traffic_noise_and_roadway_noise',\n",
              " 'Trickle_and_dribble',\n",
              " 'Walk_and_footsteps',\n",
              " 'Water_tap_and_faucet',\n",
              " 'Waves_and_surf',\n",
              " 'Whispering',\n",
              " 'Writing',\n",
              " 'Yell',\n",
              " 'Zipper_(clothing)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHVUiSjyDJdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "9376008f-8399-4e07-cac4-d15ff8232261"
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>Accelerating_and_revving_and_vroom</th>\n",
              "      <th>Accordion</th>\n",
              "      <th>Acoustic_guitar</th>\n",
              "      <th>Applause</th>\n",
              "      <th>Bark</th>\n",
              "      <th>Bass_drum</th>\n",
              "      <th>Bass_guitar</th>\n",
              "      <th>Bathtub_(filling_or_washing)</th>\n",
              "      <th>Bicycle_bell</th>\n",
              "      <th>Burping_and_eructation</th>\n",
              "      <th>Bus</th>\n",
              "      <th>Buzz</th>\n",
              "      <th>Car_passing_by</th>\n",
              "      <th>Cheering</th>\n",
              "      <th>Chewing_and_mastication</th>\n",
              "      <th>Child_speech_and_kid_speaking</th>\n",
              "      <th>Chink_and_clink</th>\n",
              "      <th>Chirp_and_tweet</th>\n",
              "      <th>Church_bell</th>\n",
              "      <th>Clapping</th>\n",
              "      <th>Computer_keyboard</th>\n",
              "      <th>Crackle</th>\n",
              "      <th>Cricket</th>\n",
              "      <th>Crowd</th>\n",
              "      <th>Cupboard_open_or_close</th>\n",
              "      <th>Cutlery_and_silverware</th>\n",
              "      <th>Dishes_and_pots_and_pans</th>\n",
              "      <th>Drawer_open_or_close</th>\n",
              "      <th>Drip</th>\n",
              "      <th>Electric_guitar</th>\n",
              "      <th>Fart</th>\n",
              "      <th>Female_singing</th>\n",
              "      <th>Female_speech_and_woman_speaking</th>\n",
              "      <th>Fill_(with_liquid)</th>\n",
              "      <th>Finger_snapping</th>\n",
              "      <th>Frying_(food)</th>\n",
              "      <th>Gasp</th>\n",
              "      <th>Glockenspiel</th>\n",
              "      <th>Gong</th>\n",
              "      <th>...</th>\n",
              "      <th>Harmonica</th>\n",
              "      <th>Hi-hat</th>\n",
              "      <th>Hiss</th>\n",
              "      <th>Keys_jangling</th>\n",
              "      <th>Knock</th>\n",
              "      <th>Male_singing</th>\n",
              "      <th>Male_speech_and_man_speaking</th>\n",
              "      <th>Marimba_and_xylophone</th>\n",
              "      <th>Mechanical_fan</th>\n",
              "      <th>Meow</th>\n",
              "      <th>Microwave_oven</th>\n",
              "      <th>Motorcycle</th>\n",
              "      <th>Printer</th>\n",
              "      <th>Purr</th>\n",
              "      <th>Race_car_and_auto_racing</th>\n",
              "      <th>Raindrop</th>\n",
              "      <th>Run</th>\n",
              "      <th>Scissors</th>\n",
              "      <th>Screaming</th>\n",
              "      <th>Shatter</th>\n",
              "      <th>Sigh</th>\n",
              "      <th>Sink_(filling_or_washing)</th>\n",
              "      <th>Skateboard</th>\n",
              "      <th>Slam</th>\n",
              "      <th>Sneeze</th>\n",
              "      <th>Squeak</th>\n",
              "      <th>Stream</th>\n",
              "      <th>Strum</th>\n",
              "      <th>Tap</th>\n",
              "      <th>Tick-tock</th>\n",
              "      <th>Toilet_flush</th>\n",
              "      <th>Traffic_noise_and_roadway_noise</th>\n",
              "      <th>Trickle_and_dribble</th>\n",
              "      <th>Walk_and_footsteps</th>\n",
              "      <th>Water_tap_and_faucet</th>\n",
              "      <th>Waves_and_surf</th>\n",
              "      <th>Whispering</th>\n",
              "      <th>Writing</th>\n",
              "      <th>Yell</th>\n",
              "      <th>Zipper_(clothing)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000ccb97.wav</td>\n",
              "      <td>6.129706e-07</td>\n",
              "      <td>1.039015e-09</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>6.444747e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000997</td>\n",
              "      <td>0.000465</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>2.854926e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>2.819746e-07</td>\n",
              "      <td>1.730269e-07</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.003510</td>\n",
              "      <td>5.480500e-07</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.007311</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>8.383200e-07</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.007075</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>2.321637e-06</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.012751</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.075570</td>\n",
              "      <td>0.001421</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>...</td>\n",
              "      <td>5.377774e-07</td>\n",
              "      <td>2.649976e-02</td>\n",
              "      <td>0.006108</td>\n",
              "      <td>0.152874</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.001707</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>7.613629e-08</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>2.805037e-07</td>\n",
              "      <td>0.003007</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.159553</td>\n",
              "      <td>4.122167e-07</td>\n",
              "      <td>0.010267</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.600396e-07</td>\n",
              "      <td>4.965114e-07</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>9.588343e-07</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>4.230570e-07</td>\n",
              "      <td>9.207371e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000472</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>5.284082e-07</td>\n",
              "      <td>0.004381</td>\n",
              "      <td>0.008132</td>\n",
              "      <td>2.397464e-06</td>\n",
              "      <td>0.000261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0012633b.wav</td>\n",
              "      <td>3.214606e-02</td>\n",
              "      <td>3.958427e-03</td>\n",
              "      <td>0.005501</td>\n",
              "      <td>4.767140e-03</td>\n",
              "      <td>0.005402</td>\n",
              "      <td>0.002711</td>\n",
              "      <td>0.013642</td>\n",
              "      <td>0.030567</td>\n",
              "      <td>0.003998</td>\n",
              "      <td>1.078878e-02</td>\n",
              "      <td>0.013211</td>\n",
              "      <td>0.221685</td>\n",
              "      <td>5.047799e-03</td>\n",
              "      <td>3.062654e-03</td>\n",
              "      <td>0.006418</td>\n",
              "      <td>0.037083</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.008136</td>\n",
              "      <td>9.025331e-03</td>\n",
              "      <td>0.008220</td>\n",
              "      <td>0.011785</td>\n",
              "      <td>0.032951</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>7.764182e-03</td>\n",
              "      <td>0.009887</td>\n",
              "      <td>0.001993</td>\n",
              "      <td>0.005768</td>\n",
              "      <td>0.020207</td>\n",
              "      <td>0.007387</td>\n",
              "      <td>9.653514e-04</td>\n",
              "      <td>0.011561</td>\n",
              "      <td>0.013480</td>\n",
              "      <td>0.012408</td>\n",
              "      <td>0.007355</td>\n",
              "      <td>0.019504</td>\n",
              "      <td>0.015033</td>\n",
              "      <td>0.012941</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>...</td>\n",
              "      <td>1.870302e-02</td>\n",
              "      <td>6.524274e-03</td>\n",
              "      <td>0.020764</td>\n",
              "      <td>0.004299</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>0.046184</td>\n",
              "      <td>0.018668</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>5.831969e-02</td>\n",
              "      <td>0.001490</td>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.014145</td>\n",
              "      <td>0.064798</td>\n",
              "      <td>8.665209e-03</td>\n",
              "      <td>0.009964</td>\n",
              "      <td>0.028967</td>\n",
              "      <td>0.004178</td>\n",
              "      <td>1.992414e-02</td>\n",
              "      <td>0.019843</td>\n",
              "      <td>0.016025</td>\n",
              "      <td>0.008269</td>\n",
              "      <td>1.055349e-02</td>\n",
              "      <td>1.418626e-02</td>\n",
              "      <td>0.014240</td>\n",
              "      <td>0.017341</td>\n",
              "      <td>0.003372</td>\n",
              "      <td>3.540333e-03</td>\n",
              "      <td>0.004076</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>8.470947e-03</td>\n",
              "      <td>2.751704e-02</td>\n",
              "      <td>0.010623</td>\n",
              "      <td>0.032947</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>2.793087e-02</td>\n",
              "      <td>0.036972</td>\n",
              "      <td>0.023301</td>\n",
              "      <td>8.745516e-03</td>\n",
              "      <td>0.097114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ed5f1.wav</td>\n",
              "      <td>2.350602e-04</td>\n",
              "      <td>1.928019e-04</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>1.526762e-03</td>\n",
              "      <td>0.003552</td>\n",
              "      <td>0.010597</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.002082</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>1.370211e-03</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>3.605146e-04</td>\n",
              "      <td>7.275805e-04</td>\n",
              "      <td>0.000780</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>1.513722e-04</td>\n",
              "      <td>0.023283</td>\n",
              "      <td>0.005666</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.114442e-03</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>0.008762</td>\n",
              "      <td>0.034958</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.772000e-04</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000399</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.005633</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000863</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>...</td>\n",
              "      <td>3.254157e-04</td>\n",
              "      <td>2.070866e-04</td>\n",
              "      <td>0.000995</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>3.369666e-04</td>\n",
              "      <td>0.014494</td>\n",
              "      <td>0.000393</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>1.303405e-04</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.036758</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>5.642852e-04</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.001926</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>1.812252e-03</td>\n",
              "      <td>6.991484e-02</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.023029</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>5.462515e-05</td>\n",
              "      <td>0.116018</td>\n",
              "      <td>0.002298</td>\n",
              "      <td>1.065065e-03</td>\n",
              "      <td>1.045919e-04</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.002882</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>3.966646e-05</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000696</td>\n",
              "      <td>2.509037e-04</td>\n",
              "      <td>0.002288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00294be0.wav</td>\n",
              "      <td>8.329202e-04</td>\n",
              "      <td>1.617301e-04</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>6.145051e-06</td>\n",
              "      <td>0.001044</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>8.721807e-03</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>6.679750e-04</td>\n",
              "      <td>1.415030e-06</td>\n",
              "      <td>0.069040</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>4.902340e-04</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.004133</td>\n",
              "      <td>6.849724e-06</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.002073</td>\n",
              "      <td>0.003358</td>\n",
              "      <td>3.043234e-07</td>\n",
              "      <td>0.009318</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>...</td>\n",
              "      <td>1.573252e-05</td>\n",
              "      <td>4.047106e-07</td>\n",
              "      <td>0.002215</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.003227</td>\n",
              "      <td>0.000619</td>\n",
              "      <td>0.000912</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.011656</td>\n",
              "      <td>8.025832e-02</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.008177</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.903260</td>\n",
              "      <td>2.443812e-05</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>0.001769</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>7.469081e-05</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.015439</td>\n",
              "      <td>0.003197</td>\n",
              "      <td>8.237210e-04</td>\n",
              "      <td>3.825970e-05</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>6.380883e-05</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>2.254221e-04</td>\n",
              "      <td>3.827822e-04</td>\n",
              "      <td>0.002967</td>\n",
              "      <td>0.019164</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>8.327834e-03</td>\n",
              "      <td>0.006581</td>\n",
              "      <td>0.004463</td>\n",
              "      <td>3.821973e-07</td>\n",
              "      <td>0.095836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003fde7a.wav</td>\n",
              "      <td>1.737082e-04</td>\n",
              "      <td>1.403598e-03</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>5.176684e-05</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.772030</td>\n",
              "      <td>1.303809e-04</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.004474</td>\n",
              "      <td>5.248077e-04</td>\n",
              "      <td>1.378326e-04</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.002780</td>\n",
              "      <td>0.006983</td>\n",
              "      <td>7.371412e-04</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000655</td>\n",
              "      <td>0.000912</td>\n",
              "      <td>0.001464</td>\n",
              "      <td>1.711114e-04</td>\n",
              "      <td>0.000965</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>1.416597e-03</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>0.000606</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.076887</td>\n",
              "      <td>0.001347</td>\n",
              "      <td>...</td>\n",
              "      <td>8.435236e-04</td>\n",
              "      <td>8.727239e-04</td>\n",
              "      <td>0.000461</td>\n",
              "      <td>0.004612</td>\n",
              "      <td>0.005147</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.001650</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>1.426340e-03</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>8.587138e-05</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001143</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>1.067055e-03</td>\n",
              "      <td>0.001260</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.001124</td>\n",
              "      <td>2.213690e-05</td>\n",
              "      <td>8.113031e-04</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.002172</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>1.170389e-02</td>\n",
              "      <td>0.000564</td>\n",
              "      <td>0.001434</td>\n",
              "      <td>2.394100e-04</td>\n",
              "      <td>1.005617e-03</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>8.460529e-05</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>9.520503e-05</td>\n",
              "      <td>0.000757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  ...  Zipper_(clothing)\n",
              "0  000ccb97.wav  ...           0.000261\n",
              "1  0012633b.wav  ...           0.097114\n",
              "2  001ed5f1.wav  ...           0.002288\n",
              "3  00294be0.wav  ...           0.095836\n",
              "4  003fde7a.wav  ...           0.000757\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7gpbpU_Zvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
        "    batch_size = 256\n",
        "\n",
        "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = Classifier(num_classes=num_classes)\n",
        "    model.load_state_dict(torch.load('weight_best.pt'))\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs, all_fnames = [], []\n",
        "\n",
        "    pb = progress_bar(test_loader)\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "        images, labels = data\n",
        "    for images, fnames in pb:\n",
        "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
        "        all_outputs.append(preds.cpu().numpy())\n",
        "        all_fnames.extend(fnames)\n",
        "\n",
        "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
        "                              index=all_fnames,\n",
        "                              columns=map(str, range(num_classes)))\n",
        "    test_preds = test_preds.groupby(level=0).mean()\n",
        "\n",
        "    return test_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGEL9P2Pgs9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 120\n",
        "batch_size = 128\n",
        "test_batch_size = 256\n",
        "lr = 1e-3\n",
        "eta_min = 1e-5\n",
        "t_max = 10\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "model = Classifier(num_classes=num_classes).cuda()\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "best_epoch = -1\n",
        "best_lwlrap = 0.\n",
        "mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in progress_bar(train_loader, parent=mb):\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hgC6GKCi8-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "35a23022-234e-48e1-80c3-a8e521515760"
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.cuda())\n",
        "        loss = criterion(outputs, labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 0:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 20))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,     1] loss: 0.035\n",
            "[1,    21] loss: 0.500\n",
            "[1,    41] loss: 0.101\n",
            "[1,    61] loss: 0.073\n",
            "[1,    81] loss: 0.072\n",
            "[1,   101] loss: 0.070\n",
            "[2,     1] loss: 0.004\n",
            "[2,    21] loss: 0.070\n",
            "[2,    41] loss: 0.069\n",
            "[2,    61] loss: 0.070\n",
            "[2,    81] loss: 0.069\n",
            "[2,   101] loss: 0.069\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yerTLd0uHazS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eacc4c6f-4f05-4876-ec2f-ffe5de57cd40"
      },
      "source": [
        "avg_val_loss = 0\n",
        "valid_preds = np.zeros((len(x_val), num_classes))\n",
        "for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = net(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "            \n",
        "score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "lwlrap = (score * weight).sum()\n",
        "        \n",
        "print(lwlrap)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.14496406814905954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx6aTfX6OUq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84bb4998-d1fe-429d-8657-6c1ceb8cc872"
      },
      "source": [
        "running_loss"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8217301890254021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEIUDteEOW-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNOfLIl6AesO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, data in enumerate(valid_loader, 0):\n",
        "  images, labels = data\n",
        "  print(i, images.shape, labels.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2YhjyVj_QMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(valid_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % train_df.labels[j] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HdhGBTp_X4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images.cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNAGHbo0_aXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = torch.sigmoid(outputs)\n",
        "#_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % train_df.labels[j]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEq9iyvh_xiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjFzcoKlOhKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETIvsNd9OhHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkmLf_LYOhDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OEPipRdOg_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wr99VOfSyA05",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 64\n",
        "    test_batch_size = 64\n",
        "    lr_max = 7*10e-2\n",
        "    factor = 6\n",
        "    end_lr = lr_max\n",
        "    iter=0\n",
        "    total_logs = []\n",
        "    \n",
        "    #lr = 1e-3\n",
        "    #eta_min = 1e-5\n",
        "    #t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    model = Classifier(num_classes=num_classes).cuda()\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adamax(model.parameters(), lr=1.)\n",
        "    step_size = 4*len(train_loader)\n",
        "    clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
        "    #optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    #scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            clip_grad_norm_(model.parameters(), 5)\n",
        "            scheduler.step()\n",
        "            lr_sched_test = scheduler.get_lr()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        #scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5eyKDWeVyA0-",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zYMqfqXQyA1E",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-xwjRKQE2tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy886k0-E2re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvJtc9DqE2pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUCVMemcE2nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdnQ8lBlE2le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM7-yqOlE2ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmZ0r4YKE2hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GonA-jB0E2fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAdmlfuUE2bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8lk6vu1E2L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovPWUJf9E2TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1cVG3B2E2P-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti-PQPO2uNQC",
        "colab_type": "text"
      },
      "source": [
        "### 2. Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODeTKQbJwFuJ",
        "colab_type": "text"
      },
      "source": [
        "***Simple changes, significant improvement in lb***\n",
        "\n",
        "Now with different convolution architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjeG9zO3dKU6",
        "colab_type": "text"
      },
      "source": [
        "***Original***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcCNIj42060g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from psutil import cpu_count\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3lWLSN7xAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 520\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_bwTu3xCHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_JOBS = cpu_count()\n",
        "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
        "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
        "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jhnnjifxCD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "    Args:\n",
        "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "    Returns:\n",
        "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "        classes.\n",
        "    \"\"\"\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "    # Only calculate precisions if there are some true classes.\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "    # Retrieval list of classes for this sample.\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "    # Which of these is a true label?\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "    # Num hits for every truncated retrieval list.\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "    Arguments:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "        of presence of that class in that sample.\n",
        "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "        test's real-valued score for each class for each sample.\n",
        "\n",
        "    Returns:\n",
        "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "        class.\n",
        "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "    \"\"\"\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    # Space to store a distinct precision value for each class on each sample.\n",
        "    # Only the classes that are true for each sample will be filled in.\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = (\n",
        "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                  truth[sample_num, :]))\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "            precision_at_hits)\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "    # a particular class.\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "    return per_class_lwlrap, weight_per_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UthfHLBOxCA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = Path('data')\n",
        "preprocessed_dir = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gdnVV-xB-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvs = {\n",
        "    'train_curated': dataset_dir / 'train_curated.csv',\n",
        "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
        "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
        "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
        "}\n",
        "\n",
        "dataset = {\n",
        "    'train_curated': dataset_dir / 'train_curated',\n",
        "    'train_noisy': dataset_dir / 'train_noisy',\n",
        "    'test': dataset_dir / 'test',\n",
        "}\n",
        "\n",
        "mels = {\n",
        "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
        "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
        "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK4Xhj0IxB7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_curated = pd.read_csv(csvs['train_curated'])\n",
        "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
        "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySDLo2fTxB4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(csvs['sample_submission'])\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK8cx8TbxTKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4t9AiIxTG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9s5PMk_xTEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
        "    for label in row:\n",
        "        idx = labels.index(label)\n",
        "        y_train[i, idx] = 1\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dc941ZJxS_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
        "    x_train = pickle.load(curated)\n",
        "    x_train.extend(pickle.load(noisy))\n",
        "\n",
        "with open(mels['test'], 'rb') as test:\n",
        "    x_test = pickle.load(test)\n",
        "    \n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_s03oyidDhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNM6N9X_dF24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU0ec8A59bpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqGEUePx3ARM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(65536, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024,80)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc_layers(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix4tKLxH3iTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 120\n",
        "    batch_size = 64\n",
        "    test_batch_size = 64\n",
        "    lr = 1e-3\n",
        "    eta_min = 1e-5\n",
        "    t_max = 10\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    model = CNN().cuda()\n",
        "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "#         for x_batch, y_batch in progress_bar(train_loader, parent=mb):\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q5b7UA6a3wqY",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S821wBNK3wqe",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpvM6BA-dSBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e_JqCpfdR9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFbhsmSHdR2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4v0mHvpSrC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclical_lr(stepsize, min_lr=7e-1, max_lr=7e-2):\n",
        "\n",
        "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
        "    scaler = lambda x: 1.\n",
        "\n",
        "    # Lambda function to calculate the LR\n",
        "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
        "\n",
        "    # Additional function to see where on the cycle we are\n",
        "    def relative(it, stepsize):\n",
        "        cycle = math.floor(1 + it / (2 * stepsize))\n",
        "        x = abs(it / stepsize - 2 * cycle + 1)\n",
        "        return max(0, (1 - x)) * scaler(cycle)\n",
        "\n",
        "    return lr_lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRa1FcYydRqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 64\n",
        "    test_batch_size = 64\n",
        "    lr_max = 7*10e-2\n",
        "    factor = 6\n",
        "    end_lr = lr_max\n",
        "    iter=0\n",
        "    total_logs = []\n",
        "    \n",
        "    #lr = 1e-3\n",
        "    #eta_min = 1e-5\n",
        "    #t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    model = Classifier(num_classes=num_classes).cuda()\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adamax(model.parameters(), lr=1.)\n",
        "    step_size = 4*len(train_loader)\n",
        "    clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
        "    #optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    #scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            clip_grad_norm_(model.parameters(), 5)\n",
        "            scheduler.step()\n",
        "            lr_sched_test = scheduler.get_lr()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        #scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey6hdbHzdRim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eatWK78dRRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5P3LRRfB9Kd",
        "colab_type": "text"
      },
      "source": [
        "## Different approachs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GrsWQAAdftZ",
        "colab_type": "text"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN1r6thl-9-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.642\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVjzwkla_FnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.639\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPhbp89NCHvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation to be applied\n",
        "\n",
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size\n",
        "\n",
        "desired_size=448\n",
        "\n",
        "ratio = float(desired_size)/max(old_size)\n",
        "\n",
        "new_size = (448, 448)\n",
        "\n",
        "im = old_im.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "\n",
        "new_im.paste(im, ((desired_size-new_size[0])//2,\n",
        "                    (desired_size-new_size[1])//2))\n",
        "new_im.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzNNDtlKCLL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Augmentation:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4QeSDI_M-lF",
        "colab_type": "text"
      },
      "source": [
        "***Increase model accuracy***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHWaDE-mqNJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://becominghuman.ai/data-augmentation-using-fastai-aefa88ca03f1\n",
        "#1st augmentation:\n",
        "transforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)] \n",
        "transforms_side_on  = transforms_basic + [RandomFlip()] \n",
        "transforms_top_down = transforms_basic + [RandomDihedral()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLLM6Ut4fXzx",
        "colab_type": "text"
      },
      "source": [
        "***Experiment list:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UJYil2unfaMP",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dMWYtD9afaMU",
        "colab": {}
      },
      "source": [
        "#2nd:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eVEwuiqSfaMX",
        "colab": {}
      },
      "source": [
        "#transform basic:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udxJpclShAJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#4th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJN1Ltv6kaDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrANS8cohML3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#both flip:\n",
        "#6th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64QXmwBVli5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#basic + flip: side_on no vertical flip\n",
        "#7th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OncoWyEsl8-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#basic + flip: side_on with vertical flip\n",
        "#7th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNurAxLmAgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#basic + flip: side_on both flip\n",
        "#7th:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S_soiWlj74O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#7th:dihedral??\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ineVWzWGiiBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dihedral\n",
        "def dihedral(x, dih):\n",
        "    \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n",
        "    x = np.rot90(x, dih%4)\n",
        "    return x if dih<4 else np.fliplr(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub_VVm8Jij25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dihedral class:\n",
        "class Dihedral(object):\n",
        "  \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDgnY7xmxbAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTrainDataset(Dataset):\n",
        "    def __init__(self, mels, labels, transforms):\n",
        "        super().__init__()\n",
        "        self.mels = mels\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.mels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # crop 1sec\n",
        "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXY5NQZTRlex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bka5v-hwRuoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "test_batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un5t03qkROPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_MZM3WPRgiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLTTjRohSAIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VazaK1fvSKFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPSwIuPSPiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[2].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzO1y6IqSppC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_dataset.mels[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw1Rwvz4TFvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.labels[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMWGyq9RTJVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mb_example = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psdqochkTSFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mb_example[0].size(), mb_example[1].size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XWKWwc3TUz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(0,4):\n",
        "    sub_plot = fig.add_subplot(1,4,i+1)\n",
        "    sub_plot.axis('Off')\n",
        "    plt.imshow(mb_example[0][i,0].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x34JCsoBTnyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQSNJunVOL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')        \n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-PjLxEdVl7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq3VvSAZXHD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LfDPw54XKyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGyhFwObZklG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_im = Image.fromarray(x_train[0], mode='RGB') \n",
        "desired_size = max(old_im.size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnB4tjtZsDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_size = (desired_size, desired_size)\n",
        "new_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGtttA-W-LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation to be applied\n",
        "\n",
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size\n",
        "\n",
        "desired_size=448\n",
        "\n",
        "ratio = float(desired_size)/max(old_size)\n",
        "\n",
        "new_size = (448, 448)\n",
        "\n",
        "im = old_im.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "\n",
        "new_im.paste(im, ((desired_size-new_size[0])//2,\n",
        "                    (desired_size-new_size[1])//2))\n",
        "new_im.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooEiujA4YKkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(new_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM2bQKeKX-QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(new_im).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwljpAPfVnPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')     \n",
        "time_dim, base_dim = image.size\n",
        "crop = random.randint(0, time_dim - base_dim)\n",
        "image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TzL0E_V0bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(image).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCsZUdOvWn99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Image\n",
        "\n",
        "old_im = Image.fromarray(x_train[0], mode='RGB')        \n",
        "old_size = old_im.size\n",
        "\n",
        "new_size = (800, 800)\n",
        "new_im = Image.new(\"RGB\", new_size)   ## luckily, this is already black!\n",
        "new_im.paste(old_im, ((new_size[0]-old_size[0])/2,\n",
        "                      (new_size[1]-old_size[1])/2))\n",
        "\n",
        "new_im.show()\n",
        "# new_im.save('someimage.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzk4AtZRVEBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
        "time_dim, base_dim = image.size\n",
        "crop = random.randint(0, time_dim - base_dim)\n",
        "image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "image = self.transforms(image).div_(255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUzFIqazxa3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FATTestDataset(Dataset):\n",
        "    def __init__(self, fnames, mels, transforms, tta=5):\n",
        "        super().__init__()\n",
        "        self.fnames = fnames\n",
        "        self.mels = mels\n",
        "        self.transforms = transforms\n",
        "        self.tta = tta\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.fnames) * self.tta\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        new_idx = idx % len(self.fnames)\n",
        "        \n",
        "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
        "        time_dim, base_dim = image.size\n",
        "        crop = random.randint(0, time_dim - base_dim)\n",
        "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
        "        image = self.transforms(image).div_(255)\n",
        "\n",
        "        fname = self.fnames[new_idx]\n",
        "        \n",
        "        return image, fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlYwSC7oxaw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPqd69JM36W",
        "colab_type": "text"
      },
      "source": [
        "***Changes: lr finder***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCmy4ugkM1yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_ft\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9lQ9pXH1h5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pretrained models:\n",
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wygwRmh61nwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pretrainedmodels\n",
        "print(pretrainedmodels.model_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-umZzHM1qkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to load a pretrained models\n",
        "model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
        "model_ft = pretrainedmodels.__dict__[model_name](num_classes=1000)\n",
        "#model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXnKbF-J-fPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpA9R-jA-wM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "model_ft.last_linear = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7oC-SOdEqLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "\n",
        "model_ft.last_linear = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=num_ftrs, out_features=1024, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=512, out_features=80, bias=True)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiI2wZ3SGBJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgPz2pJyAKxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzlvwtgK7Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft.classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy1pGvd8MbSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as defined in the link:\n",
        "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OtydueIxiiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUSz8mScyVsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(511, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(127, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nVtMd4xidL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeyzYJM7xk9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, train_transforms):\n",
        "    num_epochs = 118\n",
        "    batch_size = 128\n",
        "    test_batch_size = 256\n",
        "    lr = 1e-3\n",
        "    eta_min = 1e-5\n",
        "    t_max = 5\n",
        "    \n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "    \n",
        "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    #model = Classifier(num_classes=num_classes).cuda()\n",
        "    model = model_ft\n",
        "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "\n",
        "    best_epoch = -1\n",
        "    best_lwlrap = 0.\n",
        "    mb = master_bar(range(num_epochs))\n",
        "\n",
        "    for epoch in mb:\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            preds = model(x_batch.cuda())\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = np.zeros((len(x_val), num_classes))\n",
        "        avg_val_loss = 0.\n",
        "\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            preds = model(x_batch.cuda()).detach()\n",
        "            loss = criterion(preds, y_batch.cuda())\n",
        "\n",
        "            preds = torch.sigmoid(preds)\n",
        "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
        "\n",
        "            avg_val_loss += loss.item() / len(valid_loader)\n",
        "            \n",
        "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "        lwlrap = (score * weight).sum()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
        "    \n",
        "        if lwlrap > best_lwlrap:\n",
        "            best_epoch = epoch + 1\n",
        "            best_lwlrap = lwlrap\n",
        "            torch.save(model.state_dict(), 'weight_best.pt')\n",
        "            \n",
        "    return {\n",
        "        'best_epoch': best_epoch,\n",
        "        'best_lwlrap': best_lwlrap,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmVih93Dxk5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = train_model(x_train, y_train, transforms_dict['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yVDzyb-xk1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g215CpOVytIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
        "    batch_size = 256\n",
        "\n",
        "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_ft\n",
        "    model.load_state_dict(torch.load('weight_best.pt'))\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs, all_fnames = [], []\n",
        "\n",
        "    pb = progress_bar(test_loader)\n",
        "    for images, fnames in pb:\n",
        "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
        "        all_outputs.append(preds.cpu().numpy())\n",
        "        all_fnames.extend(fnames)\n",
        "\n",
        "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
        "                              index=all_fnames,\n",
        "                              columns=map(str, range(num_classes)))\n",
        "    test_preds = test_preds.groupby(level=0).mean()\n",
        "\n",
        "    return test_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwIX8CeyyBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK7pYQk_yt3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df[labels] = test_preds.values\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7isI9efo1z",
        "colab_type": "text"
      },
      "source": [
        "### ***Study of cnn architecture:***\n",
        "layers which works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQTzn0jiNwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet152()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUWnry6IiPjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptbbCIySkOYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ipnhPoYka7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model_ft(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgI4rC3piFXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4spaemOwgBya",
        "colab": {}
      },
      "source": [
        "model = model_ft\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wKi5i1kgByf",
        "colab": {}
      },
      "source": [
        "#pretrained models:\n",
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jfps-nfQgByp",
        "colab": {}
      },
      "source": [
        "import pretrainedmodels\n",
        "print(pretrainedmodels.model_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iIj6V7QegByu",
        "colab": {}
      },
      "source": [
        "# to load a pretrained models\n",
        "model_name = 'se_resnet50' # could be fbresnet152 or inceptionresnetv2\n",
        "model_ft = pretrainedmodels.__dict__[model_name](num_classes=1000)\n",
        "#model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nexlebj6gByy",
        "colab": {}
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sh3q6u60gBy3",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "model_ft.last_linear = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UcoVNe4NgBy5",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_ftrs = model_ft.last_linear.in_features\n",
        "\n",
        "model_ft.last_linear = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=num_ftrs, out_features=1024, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=512, out_features=80, bias=True)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NL7JJ5nsgBzK",
        "colab": {}
      },
      "source": [
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4azuK11QgBzS",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 80)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "onT2H7jHgBzh",
        "colab": {}
      },
      "source": [
        "model_ft.classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CYuIY7HEgBzo",
        "colab": {}
      },
      "source": [
        "# as defined in the link:\n",
        "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKyrqR9ngBzr",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dRxnbqLegBzv",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(511, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(127, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1r_86POgBz2",
        "colab": {}
      },
      "source": [
        "Classifier(num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsPBvNBqhNTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "model=Classifier(num_classes=num_classes)\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(64, 3, 128, 128).type(dtype)\n",
        "ans = model(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LnFJkivvfgXL",
        "colab": {}
      },
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVm6KzeZfgXQ",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWnlMr59fgXV",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_tbFS1WfgXZ",
        "colab": {}
      },
      "source": [
        "train_dataset.mels[2].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7ichSMTfgXg",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_dataset.mels[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXcfiBewfgXl",
        "colab": {}
      },
      "source": [
        "train_dataset.labels[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2mr3Q_6fgXp",
        "colab": {}
      },
      "source": [
        "mb_example = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_rKhgVBfgXu",
        "colab": {}
      },
      "source": [
        "mb_example[0].size(), mb_example[1].size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGzcBrv-fgXz",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(0,4):\n",
        "    sub_plot = fig.add_subplot(1,4,i+1)\n",
        "    sub_plot.axis('Off')\n",
        "    plt.imshow(mb_example[0][i,0].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_fhfZwe4Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (images, labels) in enumerate(train_loader):\n",
        "  print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D1sWPd2jFpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor # the CPU datatype\n",
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(64, 3, 128, 128).to(device)\n",
        "ans = model_ft(x)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "np.array_equal(np.array(ans.size()), np.array([64, 80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1K6xYZSAIDF",
        "colab_type": "text"
      },
      "source": [
        "### lr_finder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4Xxy8mKVLM",
        "colab_type": "text"
      },
      "source": [
        "***OPTIMIZER?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbWiyzBEfipA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgQOuVqFfW9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'sample_data/'\n",
        "\n",
        "epochs = 6\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr_find_epochs = 2\n",
        "\n",
        "start_lr = 1e-7\n",
        "\n",
        "end_lr = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3L_zb1qhKQdr",
        "colab": {}
      },
      "source": [
        "def test(model, device, valid_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    with torch.no_grad():\n",
        "        for j, (data, target) in enumerate(valid_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            pred = torch.sigmoid(output)\n",
        "            valid_preds[j * test_batch_size: (j+1) * test_batch_size] = pred.cpu().numpy()\n",
        "            #avg_val_loss += test_loss.item() / len(valid_loader)\n",
        "            \n",
        "            test_losses.append(test_loss.item())\n",
        "            #pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            #correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader)\n",
        "    score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
        "    lwlrap = (score * weight).sum()\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, val_lwlrap: {:.6f}\\n'.format(\n",
        "        np.mean(test_losses), lwlrap))\n",
        "    \n",
        "    return np.mean(test_losses), lwlrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhLDN7_uYVml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"lwlrap\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsuVLEb_nlTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting different optimizers:\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX4C8pE_WeT8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj84Y9MHnxNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "import plotly.plotly as py\n",
        "import plotly.tools as tools\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objs as go\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmOOeoLVLncW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs\n",
        "!mkdir logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rfkbulDMhxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70rM7ao_MTd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_data/flowers_adadelta_20190518132751.pickle sample_data/flowers_adamax_20190518130807.pickle logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIkW23GMuG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_data/flowers_adadelta_20190518133250.pickle sample_data/flowers_rmsprop_20190518122839.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adadelta_20190518133749.pickle sample_data/flowers_rmsprop_20190518123332.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adagrad_20190518124322.pickle sample_data/flowers_rmsprop_20190518123826.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adagrad_20190518124816.pickle sample_data/flowers_adagrad_20190518125313.pickle logs/flowers_vanilla\n",
        "!mv sample_data/flowers_adam_20190518131302.pickle sample_data/flowers_adam_20190518131757.pickle logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSTMVIVNUkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv sample_data/flowers_adam_20190518132252.pickle sample_data/flowers_adamax_20190518125810.pickle sample_data/flowers_adamax_20190518130309.pickle logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRxOUFIUdFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objs as go\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBoa8wbgWVM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32gsOTZMZ0tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install notebook --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxs23bH6WgAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting different optimizers:\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Xs7Yt1N3M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_plots = {}\n",
        "for i, file in enumerate(os.listdir(\"logs/flowers_vanilla/\")):\n",
        "    opt = file.split(\"_\")[1]\n",
        "    \n",
        "    plots = pickle.load(open(os.path.join(\"logs\",\"flowers_vanilla\",file),\"rb\"))\n",
        "    \n",
        "    if opt == \"adam\" and not \"adam\" in loss_plots:\n",
        "        plots = [{\n",
        "            \"acc\":x['acc']/100.0,\n",
        "            \"loss\":x[\"loss\"],\n",
        "            \"val_loss\":x[\"val_loss\"],\n",
        "            #\"lwlrap\":valid_acc\n",
        "            \"lwlrap\":x[\"lwlrap\"]\n",
        "        } for x in plots]\n",
        "        \n",
        "        plots = plots[:6]\n",
        "\n",
        "    \n",
        "    if opt in loss_plots:\n",
        "        loss_plots[opt].append(plots)\n",
        "    else:\n",
        "        loss_plots[opt] = [plots]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yYaeuG5O1wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "traces = []\n",
        "metric = \"acc\"\n",
        "for key,val in loss_plots.items():\n",
        "    \n",
        "    x = list(np.arange(1,len(val[0])+1))\n",
        "    x_rev = x[::-1]\n",
        "        \n",
        "    metric_values = np.asarray([[epoch[metric] for epoch in run] for run in val])\n",
        "    \n",
        "    y_upper = list(np.amax(metric_values,axis=0))\n",
        "    y_lower = np.amin(metric_values,axis=0)\n",
        "    y_lower = list(y_lower[::-1])\n",
        "    \n",
        "    traces.append(go.Scatter(\n",
        "        x=x+x_rev,\n",
        "        y=y_upper+y_lower,\n",
        "        fill='tozerox',\n",
        "        #fillcolor='rgba(0,100,80,0.2)',\n",
        "        #line=dict(color='rgba(255,255,255,0)'),\n",
        "        showlegend=True,\n",
        "        name=key,\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3WVB8dAO29o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layout = go.Layout(\n",
        "    paper_bgcolor='rgb(255,255,255)',\n",
        "    plot_bgcolor='rgb(229,229,229)',\n",
        "    xaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        range=[1,6],\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"epoch\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        range=[0, 1],\n",
        "        title = \"accuracy\"\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D42YDjzkaXuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyo.iplot(traces, filename='sdjf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGQOIJGcO_xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = go.Figure(data=traces, layout=layout)\n",
        "iplot(fig, show_link=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFAu_0uBTZ0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traces = []\n",
        "metric = \"lwlrap\"\n",
        "for key,val in loss_plots.items():\n",
        "    \n",
        "    x = list(np.arange(1,len(val[0])+1))\n",
        "    x_rev = x[::-1]\n",
        "        \n",
        "    metric_values = np.asarray([[epoch[metric] for epoch in run] for run in val])\n",
        "    \n",
        "    y_upper = list(np.amax(metric_values,axis=0))\n",
        "    y_lower = np.amin(metric_values,axis=0)\n",
        "    y_lower = list(y_lower[::-1])\n",
        "    \n",
        "    traces.append(go.Scatter(\n",
        "        x=x+x_rev,\n",
        "        y=y_upper+y_lower,\n",
        "        fill='tozerox',\n",
        "        #fillcolor='rgba(0,100,80,0.2)',\n",
        "        #line=dict(color='rgba(255,255,255,0)'),\n",
        "        showlegend=True,\n",
        "        name=key,\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ObQrqoFTgTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layout = go.Layout(\n",
        "    paper_bgcolor='rgb(255,255,255)',\n",
        "    plot_bgcolor='rgb(229,229,229)',\n",
        "    xaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        range=[1,6],\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"epoch\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        gridcolor='rgb(255,255,255)',\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        range=[0, 1],\n",
        "        title = \"accuracy\"\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w2oCpNrUIai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "pyo.iplot(fig, filename='td_medium_lr_1_vanilla_validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe7_KMRdR9wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly\n",
        "plotly.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz_tyKKySeNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install plotly --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIz26h8tPNfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jupyter labextension list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcKSplL6nxK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"sample_data/flowers_lr_find_loss.pickle\",\"rb\") as file:\n",
        "    lr_find_loss = pickle.load(file)\n",
        "    #lr_find_loss = lr_find_loss.detach().numpy()\n",
        "    \n",
        "with open(\"sample_data/flowers_lr_find_lr.pickle\",\"rb\") as file:\n",
        "    lr_find_lr = pickle.load(file)\n",
        "    #lr_find_lr = lr_find_lr.detach().numpy()\n",
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        type='log',\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate [log]\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"loss\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=lr_find_lr,\n",
        "        y=lr_find_loss,\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "py.iplot(fig, filename='td_medium_lr_loss_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iew2sWYunxFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_loss:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d32MP0xTnxCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_losses = a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNZ7Xj-8p5Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_lr:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhfrZKdTp_uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz7jOc9JqLie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        type='log',\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate [log]\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"loss\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=lr_find_lr,\n",
        "        y=np.array(lr_find_losses),\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "py.iplot(fig, filename='td_medium_lr_loss_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnNuDMYmqTNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS6l1mULAa-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier(num_classes=num_classes).to(device)\n",
        "\n",
        "optimizer = Adam(params=model.parameters(), lr=start_lr, amsgrad=False)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVUDiGLFAu3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LR function lambda\n",
        "\n",
        "lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (lr_find_epochs * len(train_loader)))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgIQjM9NA8wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the experiment \n",
        "\n",
        "lr_find_loss = []\n",
        "lr_find_lr = []\n",
        "\n",
        "iter = 0\n",
        "\n",
        "smoothing = 0.05\n",
        "\n",
        "for i in range(lr_find_epochs):\n",
        "  print(\"epoch {}\".format(i))\n",
        "  for inputs, labels in train_loader:\n",
        "    \n",
        "    # Send to device\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Training mode and zero gradients\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Get outputs to calc loss\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update LR\n",
        "    scheduler.step()\n",
        "    lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "    lr_find_lr.append(lr_step)\n",
        "\n",
        "    # smooth the loss\n",
        "    if iter==0:\n",
        "      lr_find_loss.append(loss)\n",
        "    else:\n",
        "      loss = smoothing  * loss + (1 - smoothing) * lr_find_loss[-1]\n",
        "      lr_find_loss.append(loss)\n",
        "     \n",
        "    iter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA2leRz7BIGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(path,\"flowers_lr_find_lr.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_lr,file)\n",
        "    \n",
        "with open(os.path.join(path,\"flowers_lr_find_loss.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_loss,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM7Zp27gByv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"lr\")\n",
        "plt.xscale(\"log\")\n",
        "plt.plot(lr_find_lr, lr_find_loss)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36lR5moaB0fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OY9nCY_B1wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBzsOo7YCPNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_max = 5*10e-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0gWY0ZPCdVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclical_lr(stepsize, min_lr=5, max_lr=5e-1):\n",
        "\n",
        "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
        "    scaler = lambda x: 1.\n",
        "\n",
        "    # Lambda function to calculate the LR\n",
        "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
        "\n",
        "    # Additional function to see where on the cycle we are\n",
        "    def relative(it, stepsize):\n",
        "        cycle = math.floor(1 + it / (2 * stepsize))\n",
        "        x = abs(it / stepsize - 2 * cycle + 1)\n",
        "        return max(0, (1 - x)) * scaler(cycle)\n",
        "\n",
        "    return lr_lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNTkyVx5zIG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, valid_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            pred = torch.sigmoid(output)\n",
        "            \n",
        "            test_losses.append(test_loss.item())\n",
        "            #pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader)\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        np.mean(test_losses), correct, len(valid_loader),\n",
        "        100. * correct / len(valid_loader)))\n",
        "    \n",
        "    return np.mean(test_losses), correct / len(valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tXszjbcEW2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 47"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN1WvboVCerG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "\n",
        "factor = 6\n",
        "end_lr = lr_max\n",
        "iter=0\n",
        "total_logs = []\n",
        "\n",
        "\n",
        "\n",
        "# Do 3 sequential runs\n",
        "for run in tqdm_notebook(range(3)):\n",
        "    \n",
        "    # Instantiate the model  \n",
        "    model = Classifier(num_classes=num_classes).to(device)\n",
        "    \n",
        "    # Define the loss function\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    # Define the optimizer\n",
        "    optimizer = Adam(params=model.parameters(), lr=1., amsgrad=False)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=1.)\n",
        "    step_size = 4*len(train_loader)\n",
        "    clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
        "    \n",
        "    logs = []\n",
        "\n",
        "    #Train the model\n",
        "    iter = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        losses = []\n",
        "        accuracies = []\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Send data to GPU\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward propagation \n",
        "            outputs = model(images)   \n",
        "            \n",
        "            # Calculating loss with softmax to obtain cross entropy loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward propation\n",
        "            loss.backward()\n",
        "            \n",
        "            # Clip the gradients norm to avoid them becoming too large\n",
        "            clip_grad_norm_(model.parameters(), 5)\n",
        "            \n",
        "            # Update the LR\n",
        "            scheduler.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            lr_sched_test = scheduler.get_lr()\n",
        "\n",
        "            # Updating gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            iter += 1\n",
        "            \n",
        "            # Total number of labels\n",
        "            total = labels.size(0)\n",
        "\n",
        "            # Obtaining predictions from max value\n",
        "            #_, predicted = torch.max(outputs.data, 1)\n",
        "            predicted = outputs\n",
        "\n",
        "            # Calculate the number of correct answers\n",
        "            correct = (predicted == labels).sum().item()\n",
        "    \n",
        "            accuracies.append(correct/total)\n",
        "\n",
        "        print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "        valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "          \n",
        "        logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"val_acc\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "        })\n",
        "            \n",
        "        \n",
        "    with open(os.path.join(path,\"flowers_{}_{}.pickle\".format('sgd_clr',datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "        pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUywNsreNId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"val_acc\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mETEglY4HLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxTwcKr2jLtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ncullen93/torchsample.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDDVd-ajmwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "pip install -e git+https://github.com/ncullen93/torchsample.git#egg=torchsample\n",
        "pip install visdom\n",
        "pip install nibabel\n",
        "pip install h5py  # this will be removed in the formal version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxdiwiPisWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsample.transforms import RangeNormalize\n",
        "norm_01 = RangeNormalize(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhFdvCcSlvKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC8grH3Jl67s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_mnist = train_dataset.mels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKRwmytdmOXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouvvR206leVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Before Tform: ' , x_train_mnist[0].min(), ' - ', x_train_mnist[0].max())\n",
        "x_norm = norm_01(x_train_mnist[0])\n",
        "print('After Tform: ' , x_norm.min(), ' - ', x_norm.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KEBGVHyiych",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Before Tform: ' , x_train[0].min(), ' - ', x_train[0].max())\n",
        "x_norm = norm_01(x_train[0])\n",
        "print('After Tform: ' , x_norm.min(), ' - ', x_norm.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My39I0RFVjXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Loading Code used for these examples\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9JuNHlVxDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT9oCQBaVu4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flipping images with Numpy\n",
        "flipped_img = np.fliplr(img)\n",
        "plt.imshow(flipped_img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAneevAIV-Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 127\n",
        "WIDTH = 487"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edvPId4sWLXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDTOvjYdZT_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 148\n",
        "WIDHT = 448\n",
        "DEPTH = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TViGNtWWYpoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ADDED NOISE:\n",
        "noise = np.random.randint(5, size = (164, 278, 4), dtype = 'uint8')\n",
        "\n",
        "for i in range(WIDTH):\n",
        "  for j in range(HEIGHT):\n",
        "    for k in range(DEPTH):\n",
        "      if (img[i][j][k] != 255):\n",
        "        img[i][j][k] += noise[i][j][k]\n",
        "        \n",
        "plt.imshow(img)\n",
        "plt.show(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF7D88yZZO5H",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJhEOWuUYpkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuThQSKTYpf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qVxxC_4Jgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomDihedral(object):\n",
        "    \"\"\"\n",
        "    Rotates images by random multiples of 90 degrees and/or reflection.\n",
        "    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size):\n",
        "      assert isinstance(output_size, (int, tuple))\n",
        "      self.output_size = output_size\n",
        "      \n",
        "      self.rot_times = random.randint(0.3)\n",
        "      self.do_flip = random.random()<0.5\n",
        "      \n",
        "    def __call__(self, (image, label)):\n",
        "      image = np.rot90(image, self.rot_times)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw_tqsBP1dSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomDihedral(CoordTransform):\n",
        "\n",
        "    def set_state(self):\n",
        "        self.store.rot_times = random.randint(0,3)\n",
        "        self.store.do_flip = random.random()<0.5\n",
        "\n",
        "    def do_transform(self, x, is_y):\n",
        "        x = np.rot90(x, self.store.rot_times)\n",
        "        return np.fliplr(x).copy() if self.store.do_flip else x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z40ONXDD1fKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = random.randint(0, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yrM8e71kEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PkdIbDPaMpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.rot90(x_train[0], b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xhRFhoXZtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply dihedral:\n",
        "random.random()<0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URAnWttUtcr7",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')        \n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFZ4_8-O1ufP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = np.fliplr(x_train[0]).copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_neB5FRd05s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(c, mode='RGB')        \n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2lY0pEwji5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5GbmuSfWtorp",
        "colab": {}
      },
      "source": [
        "#7th:dihedral??\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FNxTxVketoru",
        "colab": {}
      },
      "source": [
        "#dihedral\n",
        "def dihedral(x, dih):\n",
        "    \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n",
        "    x = np.rot90(x, dih%4)\n",
        "    return x if dih<4 else np.fliplr(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBpGe3Mgtor0",
        "colab": {}
      },
      "source": [
        "#dihedral class:\n",
        "class Dihedral(object):\n",
        "  \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n",
        "  \n",
        "  \n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    self.output_size = output_size\n",
        "    \n",
        "  def __cal__(self, image, label):\n",
        "    image, target = image, label\n",
        "    \n",
        "    x = np.rot90(x, dih)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll3msy5Zjy_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2nd:\n",
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fmASw-4dIdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_dict = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UI_RKT7QfgXF",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms_dict['train']\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "test_batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HC5i7DF2fgXJ",
        "colab": {}
      },
      "source": [
        "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
        "valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL6JSw1NAKAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uq86TKwzAKQA",
        "colab": {}
      },
      "source": [
        "path = 'sample_data/'\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHifYhTEAKQE",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mVgH5xAMAKQG",
        "colab": {}
      },
      "source": [
        "def test(model, device, valid_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    valid_preds = np.zeros((len(x_val), num_classes))\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            pred = torch.sigmoid(output)\n",
        "            \n",
        "            test_losses.append(test_loss.item())\n",
        "            #pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader)\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        np.mean(test_losses), correct, len(valid_loader),\n",
        "        100. * correct / len(valid_loader)))\n",
        "    \n",
        "    return np.mean(test_losses), correct / len(valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y50DZKTPAKQL",
        "colab": {}
      },
      "source": [
        "for key in [\"rmsprop\",\"adagrad\",\"adamax\",\"adam\",\"adadelta\"]:\n",
        "      \n",
        "    print(\"testing optimizer {}\".format(key))\n",
        "\n",
        "    total_logs = []\n",
        "    \n",
        "    # Do 3 runs each    \n",
        "    for run in tqdm_notebook(range(3)):\n",
        "        \n",
        "        print(\"doing run {} of 3\".format(run))\n",
        "        \n",
        "        # Instantiate the model\n",
        "        model = Classifier(num_classes=num_classes).cuda()\n",
        "        \n",
        "        # Define the loss function\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "    \n",
        "        # Define the optimizer\n",
        "        if key == \"adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "        elif key == \"adamax\":\n",
        "            optimizer = torch.optim.Adamax(model.parameters())\n",
        "        elif key == \"adagrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters())\n",
        "        elif key == \"adadelta\":\n",
        "            optimizer = torch.optim.Adadelta(model.parameters())\n",
        "        elif key == \"rmsprop\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters())\n",
        "            \n",
        "        \n",
        "        \n",
        "        logs = []\n",
        "\n",
        "        #Train the model\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "                # Send the data to the GPU\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Clear the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward propagation \n",
        "                outputs = model(images)      \n",
        "\n",
        "                # Calculating loss with softmax to obtain cross entropy loss\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward propation\n",
        "                loss.backward()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # Updating gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "                # Total number of labels\n",
        "                total = labels.size(0)\n",
        "\n",
        "                # Obtaining predictions from max value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                predicted = outputs\n",
        "                # Calculate the number of correct answers\n",
        "                correct = (predicted == labels).sum().item()\n",
        "    \n",
        "                accuracies.append(correct/total)\n",
        "\n",
        "            print(\"-- Epoch {}, average training loss: {:.4f}, average training accuracy: {:2f}\".format(epoch, np.mean(losses), np.mean(accuracies)))\n",
        "\n",
        "            valid_loss, valid_acc = test(model, device, valid_loader)\n",
        "            \n",
        "            logs.append({\n",
        "                'acc':np.mean(accuracies),\n",
        "                \"loss\":np.mean(losses),\n",
        "                \"val_acc\":valid_acc,\n",
        "                \"val_loss\":valid_loss\n",
        "            })\n",
        "            \n",
        "        \n",
        "        with open(os.path.join(path,\"flowers_{}_{}.pickle\".format(key,datetime.now().strftime('%Y%m%d%H%M%S') )),'wb') as file:\n",
        "            pickle.dump(logs,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5-2pvejAJ9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99yj7s3FAJ6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7mfs8NxI58S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs/flowers_vanilla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykUljzU8I54K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'logs/flowers_vanilla/'\n",
        "\n",
        "epochs = 60\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr_find_epochs = 2\n",
        "\n",
        "start_lr = 1e-7\n",
        "\n",
        "end_lr = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDiX_DEeI8_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier(num_classes=num_classes).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adamax(model.parameters(), start_lr)\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYs8lAmTI88Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (lr_find_epochs * len(train_loader)))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4JRHallI85M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the experiment \n",
        "\n",
        "lr_find_loss = []\n",
        "lr_find_lr = []\n",
        "\n",
        "iter = 0\n",
        "\n",
        "smoothing = 0.05\n",
        "\n",
        "for i in range(lr_find_epochs):\n",
        "  print(\"epoch {}\".format(i))\n",
        "  for inputs, labels in train_loader:\n",
        "    \n",
        "    # Send to device\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Training mode and zero gradients\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Get outputs to calc loss\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update LR\n",
        "    scheduler.step()\n",
        "    lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "    lr_find_lr.append(lr_step)\n",
        "\n",
        "    # smooth the loss\n",
        "    if iter==0:\n",
        "      lr_find_loss.append(loss)\n",
        "    else:\n",
        "      loss = smoothing  * loss + (1 - smoothing) * lr_find_loss[-1]\n",
        "      lr_find_loss.append(loss)\n",
        "     \n",
        "    iter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXf44pASJB9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(path,\"flowers_lr_find_lr.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_lr,file)\n",
        "    \n",
        "with open(os.path.join(path,\"flowers_lr_find_loss.pickle\"),'wb') as file:\n",
        "    pickle.dump(lr_find_loss,file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXzNfBnEJB56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"lr\")\n",
        "plt.xscale(\"log\")\n",
        "plt.plot(lr_find_lr, lr_find_loss)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxj4BR0pI81W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70BD8bpKI8yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.ylabel(\"lr\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.plot(range(len(lr_find_lr)), lr_find_lr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8NHC72SJfTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d65j3eUwKOK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"logs/flowers_vanilla/flowers_lr_find_loss.pickle\",\"rb\") as file:\n",
        "    lr_find_loss = pickle.load(file)\n",
        "    \n",
        "with open(\"logs/flowers_vanilla/flowers_lr_find_lr.pickle\",\"rb\") as file:\n",
        "    lr_find_lr = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isP0S5SgKQfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUXEY4fTKotw",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_loss:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pAQSDHDKqtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(np.array(a)).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yo1DK3Y0Kotz",
        "colab": {}
      },
      "source": [
        "lr_find_loss = np.array(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqoXUFulOimQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_lr.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0_vQf--4Kot1",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in lr_find_lr:\n",
        "  i = i.detach()\n",
        "  i = i.cpu().numpy()\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FmqaIkqKot3",
        "colab": {}
      },
      "source": [
        "lr_find_lr = np.array(lr_find_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYNVRbFHI50C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        type='log',\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate [log]\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"loss\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=lr_find_lr,\n",
        "        y=lr_find_loss,\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "iplot(fig, filename='td_medium_lr_loss_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fY9vSTdJK_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"logs/flowers_vanilla/flowers_lr_find_lr.pickle\",\"rb\") as file:\n",
        "    lr_find_lr = pickle.load(file)\n",
        " \n",
        "traces = []\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"step\"\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=True,\n",
        "        showline=False,\n",
        "        showticklabels=True,\n",
        "        tickcolor='rgb(127,127,127)',\n",
        "        ticks='outside',\n",
        "        zeroline=False,\n",
        "        title = \"learning rate\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "traces.append(go.Scatter(\n",
        "        x=list(range(len(lr_find_lr))),\n",
        "        y=lr_find_lr,\n",
        "        showlegend=False,\n",
        "        name=\"loss\",\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=traces, layout=layout)\n",
        "py.iplot(fig, filename='td_medium_lr_step_vanilla')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZQBID-xxKkf",
        "colab_type": "text"
      },
      "source": [
        "### EXP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1cW2hf8JHrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-9-z5uME3Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting data and creating dataset; dataloaders\n",
        "with open('data/mels_train_curated.pkl', 'rb') as curated:\n",
        "  x_train = pickle.load(curated)\n",
        "  \n",
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTbKSc0uE3I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_curated = pd.read_csv('data/train_curated.csv')\n",
        "train_curated.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCthm9bSE3HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('data/sample_submission.csv')\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnlGAEcXE3ER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = test_df.columns[1:].tolist()\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMP_yIyE3Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvOz9VAtE3Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros((len(train_curated), num_classes)).astype(int)\n",
        "for i, row in enumerate(train_curated['labels'].str.split(',')):\n",
        "  for label in row:\n",
        "    idx = labels.index(label)\n",
        "    y_train[i, idx] = 1\n",
        "    \n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYsaDFktE299",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btvx3nLCE278",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-jNLq4qE26Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_train[47])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24MlwGCPqaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGq0c5nVbl7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tktdp_wcdsU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "skimage.io.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ2_JvzGXFqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.fromarray(x_train[0], mode='RGB')\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWBNjYY_E24D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class traindataset(Dataset):\n",
        "  def __init__(self, x_train, y_train, transforms=None):\n",
        "    self.images = x_train\n",
        "    self.labels = y_train\n",
        "    self.transforms = transforms\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    image = np.uint8(self.images[index])\n",
        "    label = self.labels[index]\n",
        "    sample = {'image': image, 'label':label}\n",
        "    \n",
        "    if self.transforms:\n",
        "      sample = self.transforms(sample)\n",
        "      \n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}